# NLP'ye GiriÅŸ

DoÄŸal dil iÅŸlemenin (NLP) temel amacÄ±, doÄŸal dilden bilgi elde etmektir. DoÄŸal dil geniÅŸ bir terimdir ancak aÅŸaÄŸÄ±dakilerden herhangi birini kapsadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz:

- Metin (bir e-postada, blog gÃ¶nderisinde, kitapta, Tweette bulunanlar gibi)
- KonuÅŸma (bir doktorla yaptÄ±ÄŸÄ±nÄ±z konuÅŸma, telefonuna verdiÄŸiniz sesli komutlar)

Metin ve konuÅŸma ÅŸemsiyesi altÄ±nda yapmak isteyebileceÄŸiniz birÃ§ok farklÄ± ÅŸey var. Bir e-posta uygulamasÄ± oluÅŸturuyorsanÄ±z, spam olup olmadÄ±klarÄ±nÄ± (sÄ±nÄ±flandÄ±rma) gÃ¶rmek iÃ§in gelen e-postalarÄ± taramak isteyebilirsiniz.

MÃ¼ÅŸteri geri bildirim ÅŸikayetlerini analiz etmeye Ã§alÄ±ÅŸÄ±yorsanÄ±z, bunlarÄ±n iÅŸletmenizin hangi bÃ¶lÃ¼mÃ¼ iÃ§in olduÄŸunu keÅŸfetmek isteyebilirsiniz.

> ğŸ”‘ Not: Bu tÃ¼r verilerin her ikisine de genellikle diziler denir (bir cÃ¼mle, bir sÃ¶zcÃ¼k dizisidir). Bu nedenle, NLP problemlerinde karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z yaygÄ±n bir terime **seq2seq** denir, baÅŸka bir deyiÅŸle, bir dizideki bilgiyi baÅŸka bir dizi oluÅŸturmak iÃ§in bulmaktÄ±r (Ã¶rneÄŸin, bir konuÅŸma komutunu metin tabanlÄ± adÄ±mlar dizisine dÃ¶nÃ¼ÅŸtÃ¼rmek).

TensorFlow'da NLP ile pratik yapmak iÃ§in daha Ã¶nce kullandÄ±ÄŸÄ±mÄ±z adÄ±mlarÄ± bu sefer metin verileriyle uygulayacaÄŸÄ±z:

```
Metin -> sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n -> bir model oluÅŸturun -> modeli kalÄ±plarÄ± bulmak iÃ§in eÄŸitin -> kalÄ±plarÄ± kullanÄ±n (tahminlerde bulunun)
```

## Ä°Ã§erik: 

- Bir metin veri kÃ¼mesini indirme
- Metin verilerini gÃ¶rselleÅŸtirme
- Tokenization kullanarak metni sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rme
- BelirtilmiÅŸ metnimizi bir gÃ¶mmeye dÃ¶nÃ¼ÅŸtÃ¼rmek
- Bir metin veri kÃ¼mesini modelleme
  - Temel ile baÅŸlama (TF-IDF)
  - BirkaÃ§ derin Ã¶ÄŸrenme metin modeli oluÅŸturma
    - YoÄŸun, LSTM, GRU, Conv1D, AktarÄ±m Ã¶ÄŸrenimi
- Her bir modelimizin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma
- Modellerimizi bir toplulukta birleÅŸtirmek
- EÄŸitilmiÅŸ bir modeli kaydetme ve yÃ¼kleme
- En yanlÄ±ÅŸ tahminleri bulunma

---

EÄŸitime baÅŸlamadan Ã¶nce gerekli fonksiyonlarÄ± oluÅŸturalÄ±m.


```python
import zipfile
import datetime
import tensorflow as tf
import matplotlib.pyplot as plt
```


```python
def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback
```


```python
def plot_loss_curves(history):
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();
```


```python
def compare_historys(original_history, new_history, initial_epochs=5):

    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]

    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]

    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') 
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
```


```python
def unzip_data(filename):
  zip_ref = zipfile.ZipFile(filename, "r")
  zip_ref.extractall()
  zip_ref.close()
```


```python
def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"Saving TensorBoard log files to: {log_dir}")
  return tensorboard_callback
```

## Veri KÃ¼mesini Ä°ndirme

Bir metin veri kÃ¼mesi indirerek baÅŸlayalÄ±m. [Real or Not](https://www.kaggle.com/c/nlp-getting-started/data)'u kullanacaÄŸÄ±z. DoÄŸal afetler hakkÄ±nda metin tabanlÄ± Tweetler iÃ§eren Kaggle sitesinde bulunan veri seti.

**GerÃ§ek Tweetler** aslÄ±nda felaketlerle ilgilidir, Ã¶rneÄŸin:

```
Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano
```

**GerÃ§ek Olmayan Tweetler**, felaketlerle ilgili olmayan Tweetlerdir (her konuda olabilir), Ã¶rneÄŸin:

```
'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote
```


```python
# Download data (same as from Kaggle)
!wget "https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"

# Unzip data
unzip_data("nlp_getting_started.zip")
```

    --2021-08-22 07:09:20--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip
    Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 64.233.188.128, 64.233.189.128, ...
    Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 607343 (593K) [application/zip]
    Saving to: â€˜nlp_getting_started.zipâ€™
    
    nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.007s  
    
    2021-08-22 07:09:20 (87.6 MB/s) - â€˜nlp_getting_started.zipâ€™ saved [607343/607343]
    
    

`nlp_getting_started.zip` dosyasÄ±nda 3 farklÄ± csv belgesi vardÄ±r: Bunlar: 

- **sample_submission.csv** 
Modelinizin tahminlerini iÃ§eren Kaggle yarÄ±ÅŸmasÄ±na gÃ¶ndereceÄŸiniz dosyanÄ±n bir Ã¶rneÄŸi.
- **train.csv**
GerÃ§ek ve gerÃ§ek olmayan felaket Tweetlerinin eÄŸitim Ã¶rnekleri.
- **test.csv**
GerÃ§ek ve gerÃ§ek olmayan felaket Tweet Ã¶rneklerinin test edilmesi iÃ§in Ã¶rnekler.

<img src="https://boostlabs.com/wp-content/uploads/2019/09/10-types-of-data-visualization-1.jpg" />

## Bir Metin Veri KÃ¼mesini GÃ¶rselleÅŸtirme

Ã‡alÄ±ÅŸmak iÃ§in yeni bir veri kÃ¼mesi edindikten sonra, Ã¶nce ne yapmalÄ±sÄ±nÄ±z? KeÅŸfetmek mi? Kontrol etmek mi? DoÄŸrulak mÄ±? Hepsi doÄŸru :)

SloganÄ± hatÄ±rlayÄ±n: gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin.

Åu anda metin veri Ã¶rneklerimiz `.csv` dosyalarÄ± biÃ§imindedir. OnlarÄ± gÃ¶rsel hale getirmenin kolay bir yolu iÃ§in onlarÄ± pandas DataFrame'e Ã§evirelim.

> ğŸ“– Okuma: BirÃ§ok farklÄ± formatta metin veri setleriyle karÅŸÄ±laÅŸabilirsiniz. CSV dosyalarÄ±nÄ±n (Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey) yanÄ± sÄ±ra, muhtemelen `.txt` dosyalarÄ± ve `.json` dosyalarÄ±yla da karÅŸÄ±laÅŸacaksÄ±nÄ±z. Bu tÃ¼r dosyalarla Ã§alÄ±ÅŸmak iÃ§in RealPython'un aÅŸaÄŸÄ±daki iki makalesini okumanÄ±zÄ± tavsiye ederim:

- [Python'da Dosyalar NasÄ±l Okunur ve YazÄ±lÄ±r](https://realpython.com/read-write-files-python/)
- [Python'da JSON Verileriyle Ã‡alÄ±ÅŸmak](https://realpython.com/python-json/)


```python
# .csv dosyalarÄ±nÄ± pandas DataFrame'lerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
import pandas as pd
train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")
train_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Our Deeds are the Reason of this #earthquake M...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Forest fire near La Ronge Sask. Canada</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>All residents asked to 'shelter in place' are ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13,000 people receive #wildfires evacuation or...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just got sent this photo from Ruby #Alaska as ...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>



Ä°ndirdiÄŸimiz eÄŸitim verileri muhtemelen zaten karÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. Ama emin olmak iÃ§in tekrar karÄ±ÅŸtÄ±ralÄ±m.


```python
train_df_shuffled = train_df.sample(frac=1, random_state=42) 
train_df_shuffled.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2644</th>
      <td>3796</td>
      <td>destruction</td>
      <td>NaN</td>
      <td>So you have a new weapon that can cause un-ima...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2227</th>
      <td>3185</td>
      <td>deluge</td>
      <td>NaN</td>
      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5448</th>
      <td>7769</td>
      <td>police</td>
      <td>UK</td>
      <td>DT @georgegalloway: RT @Galloway4Mayor: Â‰Ã›ÃThe...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>132</th>
      <td>191</td>
      <td>aftershock</td>
      <td>NaN</td>
      <td>Aftershock back to school kick off was great. ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6845</th>
      <td>9810</td>
      <td>trauma</td>
      <td>Montgomery County, MD</td>
      <td>in response to trauma Children of Addicts deve...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



EÄŸitim verilerinin nasÄ±l bir `"target"` sÃ¼tunu olduÄŸuna dikkat edin.

`"target"` sÃ¼tununun deÄŸerini tahmin etmek iÃ§in eÄŸitim veri kÃ¼mesinin `"text"` sÃ¼tununda kalÄ±plarÄ± (Ã¶rneÄŸin farklÄ± kelime kombinasyonlarÄ±) bulmak iÃ§in kod yazacaÄŸÄ±z. Test veri kÃ¼mesinin bir `"target"` sÃ¼tunu yok.

```
Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)
```


```python
# Test verilerinin bir hedefi yok (tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ÅŸey bu)
test_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>keyword</th>
      <th>location</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Just happened a terrible car crash</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Heard about #earthquake is different cities, s...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>there is a forest fire at spot pond, geese are...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Apocalypse lighting. #Spokane #wildfires</td>
    </tr>
    <tr>
      <th>4</th>
      <td>11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>
    </tr>
  </tbody>
</table>
</div>



Her hedeften kaÃ§ tane Ã¶rneÄŸimiz olduÄŸunu kontrol edelim.


```python
# Her sÄ±nÄ±ftan kaÃ§ Ã¶rnek var?
train_df.target.value_counts()
```




    0    4342
    1    3271
    Name: target, dtype: int64



Ä°ki sÄ±nÄ±f deÄŸeri olduÄŸundan, `binary_classification` problemiyle uÄŸraÅŸacaÄŸÄ±z gibi duruyor. Veri setimizi incelediÄŸimizde dengeli bir daÄŸÄ±lÄ±m gÃ¶rÃ¼yoruz. %60 olumsuz, %40 olumlu sÄ±nÄ±f iÃ§eriyor.

- 1: gerÃ§ek bir felaket twet'i
- 0: gerÃ§ek olmayan bir felaket twet'i

Peki elimizde ki toplam Ã¶rnek sayÄ±sÄ± kaÃ§?


```python
print(f"Total training samples: {len(train_df)}")
print(f"Total test samples: {len(test_df)}")
print(f"Total samples: {len(train_df) + len(test_df)}")
```

    Total training samples: 7613
    Total test samples: 3263
    Total samples: 10876
    

Pekala, yeterli miktarda eÄŸitim ve test verisine sahibiz gibi gÃ¶rÃ¼nÃ¼yor. GÃ¶rselleÅŸtirme zamanÄ±, hadi rastgele metin Ã¶rneklerini gÃ¶rselleÅŸtirmek iÃ§in bazÄ± kodlar yazalÄ±m.

> **ğŸ¤” Soru:** Rastgele Ã¶rnekleri neden gÃ¶rselleÅŸtirelim? Ã–rnekleri sÄ±rayla gÃ¶rselleÅŸtirebilirsiniz, ancak bu yalnÄ±zca belirli bir veri alt kÃ¼mesini gÃ¶rmenize neden olabilir. Ãœzerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z farklÄ± veri tÃ¼rleri hakkÄ±nda bir fikir edinmek iÃ§in Ã¶nemli miktarda (100+) rastgele Ã¶rneÄŸi gÃ¶rselleÅŸtirmek daha iyidir. Makine Ã¶ÄŸreniminde rastgeleliÄŸin gÃ¼cÃ¼nÃ¼ asla hafife almayÄ±n.


```python
import random
random_index = random.randint(0, len(train_df)-5) 
for row in train_df_shuffled[["text", "target"]][random_index:random_index+5].itertuples():
  _, text, target = row
  print(f"Target: {target}", "(real disaster)" if target > 0 else "(not real disaster)")
  print(f"Text:\n{text}\n")
  print("---\n")
```

    Target: 0 (not real disaster)
    Text:
    @QuotesTTG Save the panicking for when you get to Helios. ;)
    
    ---
    
    Target: 0 (not real disaster)
    Text:
    Patience Jonathan On The Move To Hijack APC In BayelsaÃ¥ÃŠState http://t.co/Vh8QtbyPZt
    
    ---
    
    Target: 0 (not real disaster)
    Text:
    Ali you flew planes and ran into burning buildings why are you making soup for that man child?! #BooRadleyVanCullen
    
    ---
    
    Target: 0 (not real disaster)
    Text:
    @ACOUSTICMALOLEY no he was blazing it
    
    ---
    
    Target: 1 (real disaster)
    Text:
    National Briefing | West: California: Spring Oil Spill Estimate Grows: Documents released on Wednesday d... http://t.co/hTxAi05y7B (NYT)
    
    ---
    
    

## Verileri EÄŸitim ve DoÄŸrulama KÃ¼melerine AyÄ±rÄ±n

Test setinde etiket olmadÄ±ÄŸÄ±ndan ve eÄŸitilmiÅŸ modellerimizi deÄŸerlendirmek iÃ§in bir yola ihtiyacÄ±mÄ±z olduÄŸundan, eÄŸitim verilerinden bazÄ±larÄ±nÄ± ayÄ±racaÄŸÄ±z ve bir doÄŸrulama seti oluÅŸturacaÄŸÄ±z.

Modelimiz eÄŸitildiÄŸinde (Tweet Ã¶rneklerindeki kalÄ±plarÄ± denediÄŸinde), yalnÄ±zca eÄŸitim kÃ¼mesindeki verileri gÃ¶rÃ¼r ve doÄŸrulama kÃ¼mesini kullanarak gÃ¶rÃ¼nmeyen veriler Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶rebiliriz.

Pandas Series veri tÃ¼rlerinden bÃ¶lmelerimizi daha sonra kullanÄ±m kolaylÄ±ÄŸÄ± iÃ§in string listelerine (metin iÃ§in) ve ints listelerine (etiketler iÃ§in) dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz.

EÄŸitim veri setimizi bÃ¶lmek ve bir doÄŸrulama veri seti oluÅŸturmak iÃ§in Scikit-Learn'in `train_test_split()` yÃ¶ntemini kullanacaÄŸÄ±z ve eÄŸitim Ã¶rneklerinin %10'unu doÄŸrulama setine ayÄ±racaÄŸÄ±z.


```python
from sklearn.model_selection import train_test_split

# EÄŸitim verilerini eÄŸitim ve doÄŸrulama kÃ¼melerine bÃ¶lmek iÃ§in train_test_split kullan
train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled["text"].to_numpy(),
                                                                            train_df_shuffled["target"].to_numpy(),
                                                                            test_size=0.1, # Ã¶rneklerin %10'unu doÄŸrulama setine ayÄ±r
                                                                            random_state=42) # tekrarlanabilirlik iÃ§in rastgele durum
```


```python
# UzunluklarÄ± kontrol edin
len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)
```




    (6851, 6851, 762, 762)




```python
# Ä°lk 10 eÄŸitim cÃ¼mlesini ve etiketlerini gÃ¶rÃ¼ntÃ¼leyin
train_sentences[:10], train_labels[:10]
```




    (array(['@mogacola @zamtriossu i screamed after hitting tweet',
            'Imagine getting flattened by Kurt Zouma',
            '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',
            "@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet",
            'Somehow find you and I collide http://t.co/Ee8RpOahPk',
            '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',
            'destroy the free fandom honestly',
            'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',
            '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',
            'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],
           dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))



## Metni SayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rme

Tweetler ve etiketler iÃ§eren bir eÄŸitim setimiz ve bir doÄŸrulama setimiz var. Etiketlerimiz sayÄ±sal (0 ve 1) biÃ§imindedir, ancak Tweetlerimiz dize biÃ§imindedir.

> ğŸ¤” Soru: Metin verilerimizle bir makine Ã¶ÄŸrenmesi algoritmasÄ± kullanabilmemiz iÃ§in sizce ne yapmamÄ±z gerekiyor?

"SayÄ±ya Ã§evir" gibi bir cevap verdiyseniz, haklÄ±sÄ±nÄ±z. Bir makine Ã¶ÄŸrenimi algoritmasÄ±, girdilerinin sayÄ±sal biÃ§imde olmasÄ±nÄ± gerektirir.

NLP'de metni sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in iki ana kavram vardÄ±r:

- **Tokenization**<br>
Kelimeden veya karakterden veya alt kelimeden sayÄ±sal bir deÄŸere dÃ¼z bir eÅŸleme. ÃœÃ§ ana tokenizasyon seviyesi vardÄ±r:
  1. Kelime dÃ¼zeyinde simgeleÅŸtirmeyi "I love TensorFlow" cÃ¼mlesiyle kullanmak, "I"nin 0, "love"  1 ve "TensorFlow"un 2 olmasÄ±na neden olabilir. Bu durumda, bir dizideki her sÃ¶zcÃ¼k tek bir simge olarak kabul edilir.
  2. A-Z harflerini 1-26 deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rmek gibi karakter dÃ¼zeyinde simgeleÅŸtirme. Bu durumda, bir dizideki her karakter tek bir simge olarak kabul edilir.
  3. Alt sÃ¶zcÃ¼k belirleme, sÃ¶zcÃ¼k dÃ¼zeyinde ve karakter dÃ¼zeyinde simgeleÅŸtirme arasÄ±ndadÄ±r. Tek tek kelimeleri daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rmayÄ± ve ardÄ±ndan bu daha kÃ¼Ã§Ã¼k parÃ§alarÄ± sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmeyi iÃ§erir. Ã–rneÄŸin, "my favorite food is pineapple pizza", "my, favor, rite, fo, oo, od, is, pin, ine, app, le, piz, za" olabilir. Bunu yaptÄ±ktan sonra, bu alt kelimeler daha sonra sayÄ±sal bir deÄŸere eÅŸlenir. Bu durumda, her kelime birden fazla belirteÃ§ olarak kabul edilebilir.

- **Embedding**<br>
Embed, Ã¶ÄŸrenilebilen doÄŸal dilin bir temsilidir. Temsil, bir Ã¶zellik vektÃ¶rÃ¼ ÅŸeklinde gelir. Ã–rneÄŸin, "dance" kelimesi 5 boyutlu vektÃ¶r [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112] ile temsil edilebilir. Burada not etmek Ã¶nemlidir, Ã¶zellik vektÃ¶rÃ¼nÃ¼n boyutu ayarlanabilir. Embed kullanmanÄ±n iki yolu vardÄ±r:
  1. Kendi embed iÅŸleminizi oluÅŸturun - Metniniz sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ÄŸÃ¼nde (embed iÃ§in gereklidir), onlarÄ± bir embed  katmanÄ±na (tf.keras.layers.Embedding gibi) koyabilirsiniz ve model eÄŸitimi sÄ±rasÄ±nda bir embed gÃ¶sterimi Ã¶ÄŸrenilecektir.
  2. Ã–nceden Ã¶ÄŸrenilmiÅŸ bir yerleÅŸtirmeyi yeniden kullanÄ±n - Ã‡evrimiÃ§i olarak Ã¶nceden eÄŸitilmiÅŸ birÃ§ok yerleÅŸtirme mevcuttur. Bu Ã¶nceden eÄŸitilmiÅŸ yerleÅŸtirmeler genellikle bÃ¼yÃ¼k metin kÃ¼tlelerinde (tÃ¼m Wikipedia'da olduÄŸu gibi) Ã¶ÄŸrenilmiÅŸtir ve bu nedenle doÄŸal dilin iyi bir temel temsiline sahiptir. Modelinizi baÅŸlatmak ve kendi Ã¶zel gÃ¶revinize gÃ¶re ince ayar yapmak iÃ§in Ã¶nceden eÄŸitilmiÅŸ bir yerleÅŸtirme kullanabilirsiniz.

> Soru: Hangi dÃ¼zeyde belirteÃ§ kullanmalÄ±yÄ±m? Hangi embedi  seÃ§meliyim?

Sorununuza baÄŸlÄ±. Karakter dÃ¼zeyinde tokenization/embed ve sÃ¶zcÃ¼k dÃ¼zeyinde word-level-tokenization/embed deneyebilir ve hangisinin en iyi performansÄ± gÃ¶sterdiÄŸini gÃ¶rebilirsiniz. BunlarÄ± istiflemeyi bile deneyebilirsiniz (Ã¶rneÄŸin, embed katmanlarÄ±nÄ±zÄ±n Ã§Ä±ktÄ±larÄ±nÄ± tf.keras.layers.concatenate kullanarak birleÅŸtirmek).

Ã–nceden eÄŸitilmiÅŸ sÃ¶zcÃ¼k yerleÅŸtirmeleri arÄ±yorsanÄ±z, Word2vec yerleÅŸtirmeleri, GloVe yerleÅŸtirmeleri ve TensorFlow Hub'da bulunan seÃ§eneklerin Ã§oÄŸu, baÅŸlamak iÃ§in harika yerlerdir.

> ğŸ”‘ Not: Ã–nceden eÄŸitilmiÅŸ bir bilgisayarlÄ± gÃ¶rÃ¼ modelini aramaya benzer ÅŸekilde, probleminiz iÃ§in kullanmak Ã¼zere Ã¶nceden eÄŸitilmiÅŸ sÃ¶zcÃ¼k yerleÅŸtirmelerini arayabilirsiniz. "TensorFlow'da Ã¶nceden eÄŸitilmiÅŸ kelime yerleÅŸtirmelerini kullan" gibi bir ÅŸey aramayÄ± deneyin.

### Metin VektÃ¶rleÅŸtirme

Ä°lk Ã¶nce tokenizasyon (kelimelerimizi sayÄ±larla eÅŸleÅŸtirme) alÄ±ÅŸtÄ±rmasÄ± yapacaÄŸÄ±z. SÃ¶zlerimizi simgeleÅŸtirmek iÃ§in, yararlÄ± Ã¶niÅŸleme katmanÄ± `tf.keras.layers.experimental.preprocessing.TextVectorization` kullanacaÄŸÄ±z.

TextVectorization katmanÄ± aÅŸaÄŸÄ±daki parametreleri alÄ±r:
- **max_tokens**<br>
Kelime daÄŸarcÄ±ÄŸÄ±nÄ±zdaki maksimum kelime sayÄ±sÄ± (Ã¶rneÄŸin, metninizdeki 20000 veya benzersiz kelime sayÄ±sÄ±), OOV (kelime dÄ±ÅŸÄ±) belirteÃ§leri iÃ§in bir deÄŸer iÃ§erir.
- **standardize**<br>
Metni standartlaÅŸtÄ±rma yÃ¶ntemi. VarsayÄ±lan, metni alÃ§altan ve tÃ¼m noktalama iÅŸaretlerini kaldÄ±ran "`lower_and_strip_punctuation`"dÄ±r.
- **split**<br>
Metin nasÄ±l bÃ¶lÃ¼nÃ¼r, varsayÄ±lan olarak boÅŸluklara bÃ¶lÃ¼nen "split"tir.
- **ngrams**<br>
BelirteÃ§ baÅŸÄ±na kaÃ§ sÃ¶zcÃ¼k iÃ§erecek, Ã¶rneÄŸin, ngrams=2 belirteÃ§leri 2'lik sÃ¼rekli dizilere bÃ¶ler.
- **output_mode**<br>
BelirteÃ§ler nasÄ±l Ã§Ä±karÄ±lÄ±r, "int" (tamsayÄ± eÅŸleme), "binary" (tek-sÄ±cak kodlama), "count" veya "tf-idf" olabilir. 
- **output_sequence_length**<br>
Ã‡Ä±ktÄ± iÃ§in belirtilmiÅŸ dizinin uzunluÄŸu. Ã–rneÄŸin, Ã§Ä±ktÄ±_dizi_uzunluk=150 ise, tÃ¼m belirteÃ§li diziler 150 belirteÃ§ uzunluÄŸunda olacaktÄ±r.
- **pad_to_max_tokens**<br>
True (varsayÄ±lan) ise, sÃ¶zlÃ¼kteki benzersiz jeton sayÄ±sÄ± max_tokens'den az olsa bile Ã§Ä±ktÄ± Ã¶zelliÄŸi ekseni max_tokens olarak doldurulur.


```python
import tensorflow as tf
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

text_vectorizer = TextVectorization(max_tokens=None,
                                    standardize="lower_and_strip_punctuation",
                                    split="whitespace", 
                                    ngrams=None, 
                                    output_mode="int",
                                    output_sequence_length=None,
                                    pad_to_max_tokens=False)
```

Bir TextVectorization nesnesini varsayÄ±lan ayarlarla baÅŸlattÄ±k, ancak bunu kendi kullanÄ±m durumumuz iÃ§in biraz Ã¶zelleÅŸtirelim. Ã–zellikle `max_tokens` ve `output_sequence_length` iÃ§in deÄŸerler belirleyelim.

`max_tokens` (kelimelerdeki kelime sayÄ±sÄ±) iÃ§in 10.000'in katlarÄ± (10.000, 20.000, 30.000) veya metninizdeki tam benzersiz kelime sayÄ±sÄ± (Ã¶r. 32.179) ortak deÄŸerlerdir. KullanÄ±m durumumuz iÃ§in 10.000 kullanacaÄŸÄ±z.

Ve `output_sequence_length` iÃ§in, eÄŸitim setindeki Tweet baÅŸÄ±na ortalama jeton sayÄ±sÄ±nÄ± kullanacaÄŸÄ±z. Ama Ã¶nce onu bulmamÄ±z gerekecek.


```python
# EÄŸitim Tweetlerinde ortalama jeton (kelime) sayÄ±sÄ±nÄ± bulma
round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))
```




    15



Åimdi Ã¶zel parametrelerimizi kullanarak baÅŸka bir TextVectorization nesnesi oluÅŸturalÄ±m.


```python
# Metin vektÃ¶rleÅŸtirme deÄŸiÅŸkenlerini ayarlayÄ±n
max_vocab_length = 10000 # kelime daÄŸarcÄ±ÄŸÄ±mÄ±zda bulunmasÄ± gereken maksimum kelime sayÄ±sÄ±
max_length = 15 # dizilerimiz maksimum uzunluk olacaktÄ±r (Ã¶r. modelimiz bir Tweetten kaÃ§ kelime gÃ¶rÃ¼yor?)

text_vectorizer = TextVectorization(max_tokens=max_vocab_length,
                                    output_mode="int",
                                    output_sequence_length=max_length)
```

GÃ¼zel! `TextVectorization` Ã¶rneÄŸimizi text_vectorizer verilerimizle eÅŸleÅŸtirmek iÃ§in, eÄŸitim metnimizi iletirken `adapt()` yÃ¶ntemini Ã§aÄŸÄ±rabiliriz.


```python
# Metin vektÃ¶rleÅŸtiriciyi eÄŸitim metnine fit etme
text_vectorizer.adapt(train_sentences)
```

EÄŸitim verileri eÅŸlendi! Text_vectorizer'Ä±mÄ±zÄ± Ã¶zel bir cÃ¼mle Ã¼zerinde deneyelim (eÄŸitim verilerinde gÃ¶rebileceÄŸinize benzer bir cÃ¼mle).


```python
# Ã–rnek cÃ¼mle oluÅŸtur ve onu belirt
sample_sentence = "There's a flood in my street!"
text_vectorizer([sample_sentence])
```




    <tf.Tensor: shape=(1, 15), dtype=int64, numpy=
    array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,
              0,   0]])>



Harika, gÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re metnimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmenin bir yolu var (bu durumda, kelime dÃ¼zeyinde simgeleÅŸtirme). DÃ¶ndÃ¼rÃ¼len tensÃ¶rÃ¼n sonundaki 0'lara dikkat edin, bunun nedeni output_sequence_length=15 olarak ayarlamÄ±ÅŸ olmamÄ±zdÄ±r, yani text_vectorizer'a ilettiÄŸimiz dizinin boyutu ne olursa olsun, her zaman 15 uzunluÄŸunda bir dizi dÃ¶ndÃ¼rÃ¼r.

BirkaÃ§ rastgele cÃ¼mle Ã¼zerinde text_vectorizer'Ä±mÄ±zÄ± denemeye ne dersiniz?


```python
random_sentence = random.choice(train_sentences)
print(f"Original text:\n{random_sentence}\
      \n\nVectorized version:")
text_vectorizer([random_sentence])
```

    Original text:
    Quirk Injury Law's News is out! http://t.co/HxVIhDuShP Stories via @dantmatrafajlo      
    
    Vectorized version:
    




    <tf.Tensor: shape=(1, 15), dtype=int64, numpy=
    array([[9416,  345, 2068,   58,    9,   36,    1, 1172,   49,    1,    0,
               0,    0,    0,    0]])>



Ä°yi gÃ¶rÃ¼nÃ¼yor! Son olarak, `get_vocabulary()` yÃ¶ntemini kullanarak sÃ¶zlÃ¼ÄŸÃ¼mÃ¼zdeki benzersiz belirteÃ§leri kontrol edebiliriz.


```python
# Kelime daÄŸarcÄ±ÄŸÄ±ndaki benzersiz kelimeleri alÄ±n
words_in_vocab = text_vectorizer.get_vocabulary()
top_5_words = words_in_vocab[:5]
bottom_5_words = words_in_vocab[-5:] 
print(f"Number of words in vocab: {len(words_in_vocab)}")
print(f"Top 5 most common words: {top_5_words}") 
print(f"Bottom 5 least common words: {bottom_5_words}")
```

    Number of words in vocab: 10000
    Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']
    Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']
    

GÃ¶mme KatmanÄ± Kullanarak GÃ¶mme OluÅŸturma
Metnimizi sayÄ±larla eÅŸleÅŸtirmenin bir yolu var. Bir adÄ±m daha ileri gidip bu sayÄ±larÄ± bir gÃ¶mme haline getirmeye ne dersiniz?

Bir gÃ¶mmenin gÃ¼Ã§lÃ¼ yanÄ±, eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrenilebilmesidir. Bu, yalnÄ±zca statik olmaktan ziyade (Ã¶rneÄŸin 1 = I, 2 = love, 3 = TensorFlow), bir kelimenin sayÄ±sal gÃ¶steriminin, bir model veri Ã¶rneklerinden geÃ§erken geliÅŸtirilebileceÄŸi anlamÄ±na gelir.

`tf.keras.layers.Embedding` katmanÄ±nÄ± kullanarak bir kelimenin gÃ¶mÃ¼lmesinin nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ gÃ¶rebiliriz.

Burada ilgilendiÄŸimiz ana parametreler ÅŸunlardÄ±r:

- **input_dim** <br>
SÃ¶zlÃ¼ÄŸÃ¼n boyutu 
- **output_dim**<br>
Ã‡Ä±ktÄ± gÃ¶mme vektÃ¶rÃ¼nÃ¼n boyutu, Ã¶rneÄŸin 100 deÄŸeri, her kelime iÃ§in 100 boyutunda bir Ã¶zellik vektÃ¶rÃ¼ verir.
- **embeddings_initializer**<br>
GÃ¶mme matrisi nasÄ±l baÅŸlatÄ±lÄ±r, varsayÄ±lan deÄŸer, tek tip daÄŸÄ±lÄ±mla gÃ¶mme matrisini rastgele baÅŸlatan "tek biÃ§imli"dir. Bu, Ã¶nceden Ã¶ÄŸrenilmiÅŸ yerleÅŸtirmeleri kullanmak iÃ§in deÄŸiÅŸtirilebilir.
- **input_length**<br> GÃ¶mme katmanÄ±na geÃ§irilen dizilerin uzunluÄŸu.

BunlarÄ± bilerek bir gÃ¶mme katmanÄ± yapalÄ±m.


```python
from tensorflow.keras import layers

embedding = layers.Embedding(input_dim=max_vocab_length,
                             output_dim=128, 
                             embeddings_initializer="uniform",
                             input_length=max_length) 

embedding
```




    <keras.layers.embeddings.Embedding at 0x7f5bf062d050>



MÃ¼kemmel, TensoFlow katmanÄ±nÄ±n nasÄ±l gÃ¶mÃ¼ldÃ¼ÄŸÃ¼nÃ¼ fark ettiniz mi? Bu Ã¶nemlidir Ã§Ã¼nkÃ¼ onu bir modelin parÃ§asÄ± olarak kullanabiliriz, yani parametreleri (kelime temsilleri) model Ã¶ÄŸrendikÃ§e gÃ¼ncellenebilir ve geliÅŸtirilebilir.

Ã–rnek bir cÃ¼mle Ã¼zerinde deneyelim mi?


```python
random_sentence = random.choice(train_sentences)
print(f"Original text:\n{random_sentence}\
      \n\nEmbedded version:")

sample_embed = embedding(text_vectorizer([random_sentence]))
sample_embed
```

    Original text:
    Anyone wanna come over and watch Twister with me? #toosoon :-)      
    
    Embedded version:
    




    <tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=
    array([[[-2.67661568e-02,  3.09980996e-02,  9.19399410e-03, ...,
             -1.61751285e-02,  2.21572071e-03, -7.00148195e-03],
            [-4.41038385e-02, -4.84013557e-03,  2.72500776e-02, ...,
             -1.73950568e-02, -2.18516830e-02, -9.85272974e-03],
            [-1.61503777e-02, -3.82886529e-02,  2.60415785e-02, ...,
             -3.55404019e-02,  8.02986324e-05, -7.18279928e-03],
            ...,
            [-3.36676128e-02, -6.04265928e-03, -5.23805618e-04, ...,
             -4.41053882e-02,  1.10260025e-02,  1.55389644e-02],
            [-3.36676128e-02, -6.04265928e-03, -5.23805618e-04, ...,
             -4.41053882e-02,  1.10260025e-02,  1.55389644e-02],
            [-3.36676128e-02, -6.04265928e-03, -5.23805618e-04, ...,
             -4.41053882e-02,  1.10260025e-02,  1.55389644e-02]]],
          dtype=float32)>



CÃ¼mledeki her belirteÃ§, 128 uzunlukta bir Ã¶zellik vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.


```python
sample_embed[0][0]
```




    <tf.Tensor: shape=(128,), dtype=float32, numpy=
    array([-2.6766157e-02,  3.0998100e-02,  9.1939941e-03,  1.1298049e-02,
            1.9281853e-02,  1.2828600e-02,  2.7620319e-02, -4.6756484e-02,
           -4.7940601e-02, -9.4258562e-03,  8.8882931e-03,  9.9281296e-03,
           -1.1045527e-02,  2.3107305e-03,  1.1442937e-02, -2.6214374e-02,
            1.9464921e-02,  9.2443340e-03, -1.1554696e-02,  1.6496528e-02,
            1.1290133e-02,  1.7679345e-02,  4.1412916e-02,  8.3859339e-03,
           -2.3221433e-02, -1.5267409e-02,  6.1252825e-03, -2.3301685e-02,
            8.3223693e-03,  3.4590412e-02, -1.8654786e-02,  2.2479955e-02,
            2.3416769e-02, -1.4507163e-02, -3.3194818e-02,  1.5210751e-02,
            1.2733910e-02, -4.2662036e-02, -3.1142402e-02,  2.9466037e-02,
           -1.3123263e-02,  2.6843850e-02,  2.1498416e-02,  4.5063887e-02,
           -3.6920715e-02,  1.0851800e-02,  8.6697713e-03,  4.7077391e-02,
            3.5928216e-02, -4.7313895e-02,  1.0041595e-03,  1.1565756e-02,
           -6.1505325e-03,  3.5577092e-02,  3.0785192e-02, -1.0508526e-02,
            2.8408121e-02,  2.3087058e-02,  4.5386180e-03,  5.6251884e-03,
            1.3862085e-02,  2.7922798e-02,  3.3377770e-02,  4.2726230e-02,
           -9.0640187e-03,  5.7292096e-03, -1.4854670e-02,  1.6860548e-02,
            2.0201530e-02, -4.1249715e-02, -2.0793175e-02,  3.2375220e-02,
           -3.9839089e-02, -4.9911141e-03, -7.8412518e-03,  2.9475693e-02,
           -3.2879878e-02,  2.2757497e-02,  9.1821551e-03, -3.9630160e-03,
            1.7598383e-03,  6.4185746e-03,  3.9488077e-07,  3.5669398e-02,
            2.0191576e-02,  4.4047508e-02,  2.1852169e-02, -4.9949538e-02,
            2.9918279e-02,  1.1461068e-02, -4.4214189e-02, -4.5909584e-02,
           -1.4579408e-03, -3.6948562e-02, -3.2227956e-02,  2.8313946e-02,
           -9.3356520e-04,  7.1534142e-03,  1.9067053e-02, -2.5455356e-02,
           -1.3002217e-02,  3.1422488e-03, -4.7948360e-02, -2.8451920e-02,
           -4.4162154e-02, -6.4193085e-04,  2.4962079e-02, -3.2402515e-02,
            6.5453053e-03, -6.9365017e-03,  1.5323464e-02,  1.9762184e-02,
            3.9757859e-02,  4.8979964e-02,  4.1511167e-02, -2.3521185e-03,
           -4.2080723e-02, -1.8117238e-02,  4.2290125e-02, -3.8343213e-02,
            2.6690889e-02,  1.0297049e-02,  3.5892416e-02, -2.7472233e-02,
           -2.4868632e-02, -1.6175129e-02,  2.2157207e-03, -7.0014820e-03],
          dtype=float32)>



ğŸ”‘ Not: Ã–nceki iki kavram (tokenization ve embedding) birÃ§ok NLP gÃ¶revinin temelidir. Bu nedenle, herhangi bir ÅŸeyden emin deÄŸilseniz, anlayÄ±ÅŸÄ±nÄ±za daha fazla yardÄ±mcÄ± olmak iÃ§in kendi deneylerinizi araÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan ve yÃ¼rÃ¼ttÃ¼ÄŸÃ¼nÃ¼zden emin olun.

## Bir Metin Veri KÃ¼mesini Modelleme

Girdilerinizi ve Ã§Ä±ktÄ±larÄ±nÄ±zÄ± hazÄ±rladÄ±ktan sonra, aradaki boÅŸluÄŸu kapatmak iÃ§in hangi makine Ã¶ÄŸrenimi modelinin oluÅŸturulacaÄŸÄ±nÄ± bulmak meselesidir.

ArtÄ±k metin verilerimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmenin bir yolu olduÄŸuna gÃ¶re, onu modellemek iÃ§in makine Ã¶ÄŸrenimi modelleri oluÅŸturmaya baÅŸlayabiliriz.

Bol bol pratik yapmak iÃ§in, her biri kendi deneyi olan bir dizi farklÄ± model oluÅŸturacaÄŸÄ±z. Daha sonra her modelin sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z ve hangisinin en iyi performansÄ± gÃ¶sterdiÄŸini gÃ¶receÄŸiz.

Daha spesifik olarak, aÅŸaÄŸÄ±dakileri inÅŸa edeceÄŸiz:

- Model 0: Naive Bayes (temel)
- Model 1: Ä°leri beslemeli sinir aÄŸÄ± (yoÄŸun model)
- Model 2: LSTM modeli
- Model 3: GRU modeli
- Model 4: Ã‡ift YÃ¶nlÃ¼-LSTM modeli
- Model 5: 1B EvriÅŸimli Sinir AÄŸÄ±
- Model 6: TensorFlow Hub Ã–nceden EÄŸitilmiÅŸ Ã–zellik Ã‡Ä±karÄ±cÄ± (feature extraction)
- Model 7: EÄŸitim verilerinin %10 ile model 6'nÄ±n aynÄ±sÄ± 

Model 0, diÄŸer daha derin modellerin birbirini yenmesini bekleyeceÄŸimiz bir temel elde etmek iÃ§in en basit olanÄ±dÄ±r.

Her deney aÅŸaÄŸÄ±daki adÄ±mlardan geÃ§ecektir:

- Modeli oluÅŸturun
- Modeli eÄŸit
- Modelle tahminler yapÄ±n
- Daha sonra karÅŸÄ±laÅŸtÄ±rma iÃ§in tahmin deÄŸerlendirme metriklerini takip edin

### Model 0: Temel oluÅŸturma

TÃ¼m makine Ã¶ÄŸrenimi modelleme deneylerinde olduÄŸu gibi, bir temel model oluÅŸturmak Ã¶nemlidir, bÃ¶ylece gelecekteki deneyler iÃ§in Ã¼zerine inÅŸa edebileceÄŸiniz bir kÄ±yaslama elde edersiniz.

Temel Ã§izgimizi oluÅŸturmak iÃ§in, kelimelerimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in TF-IDF (terim frekansÄ±-ters belge frekansÄ±) formÃ¼lÃ¼nÃ¼ kullanarak bir Scikit-Learn Pipeline oluÅŸturacaÄŸÄ±z ve ardÄ±ndan bunlarÄ± Multinomial Naive Bayes algoritmasÄ± ile modelleyeceÄŸiz. Bu, Scikit-Learn makine Ã¶ÄŸrenimi haritasÄ±na baÅŸvurularak seÃ§ildi.

ğŸ“– TD-IDF algoritmasÄ± hakkÄ±nda okunmasÄ± gereken bir makale: https://www.onely.com/blog/what-is-tf-idf/


```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

model_0 = Pipeline([
                    ("tfidf", TfidfVectorizer()),# tfidf kullanarak kelimeleri sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
                    ("clf", MultinomialNB()) # metni modelle
])

model_0.fit(train_sentences, train_labels)
```




    Pipeline(memory=None,
             steps=[('tfidf',
                     TfidfVectorizer(analyzer='word', binary=False,
                                     decode_error='strict',
                                     dtype=<class 'numpy.float64'>,
                                     encoding='utf-8', input='content',
                                     lowercase=True, max_df=1.0, max_features=None,
                                     min_df=1, ngram_range=(1, 1), norm='l2',
                                     preprocessor=None, smooth_idf=True,
                                     stop_words=None, strip_accents=None,
                                     sublinear_tf=False,
                                     token_pattern='(?u)\\b\\w\\w+\\b',
                                     tokenizer=None, use_idf=True,
                                     vocabulary=None)),
                    ('clf',
                     MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],
             verbose=False)



`Multinomial Naive Bayes` gibi sÄ±ÄŸ bir model kullanmanÄ±n yararÄ±, eÄŸitimin Ã§ok hÄ±zlÄ± olmasÄ±dÄ±r. Modelimizi deÄŸerlendirelim ve temel metriÄŸimizi bulalÄ±m.


```python
baseline_score = model_0.score(val_sentences, val_labels)
print(f"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%")
```

    Our baseline model achieves an accuracy of: 79.27%
    

Temel modelimiz ile bazÄ± tahminler yapmaya ne dersiniz?


```python
baseline_preds = model_0.predict(val_sentences)
baseline_preds[:20]
```




    array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])



### Model Deneylerimiz Ä°Ã§in Bir DeÄŸerlendirme Fonksiyonu OluÅŸturma

BunlarÄ± olduÄŸu gibi deÄŸerlendirebiliriz, ancak ileride birkaÃ§ modeli aynÄ± ÅŸekilde deÄŸerlendireceÄŸimiz iÃ§in, bir dizi tahmin ve kesinlik etiketi alan ve aÅŸaÄŸÄ±dakileri hesaplayan bir yardÄ±mcÄ± fonksiyon oluÅŸturalÄ±m:

- Accuracy
- Precision
- Recall
- F1-score

ğŸ”‘ Not: Bir sÄ±nÄ±flandÄ±rma sorunuyla uÄŸraÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in yukarÄ±daki metrikler en uygun olanlardÄ±r. Bir regresyon problemi ile Ã§alÄ±ÅŸÄ±yor olsaydÄ±k, MAE (ortalama mutlak hata) gibi diÄŸer metrikler daha iyi bir seÃ§im olurdu.


```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def calculate_results(y_true, y_pred):
  model_accuracy = accuracy_score(y_true, y_pred) * 100

  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average="weighted")
  model_results = {"accuracy": model_accuracy,
                  "precision": model_precision,
                  "recall": model_recall,
                  "f1": model_f1}
  return model_results

baseline_results = calculate_results(y_true=val_labels,
                                     y_pred=baseline_preds)
baseline_results
```




    {'accuracy': 79.26509186351706,
     'f1': 0.7862189758049549,
     'precision': 0.8111390004213173,
     'recall': 0.7926509186351706}



### Model 1: Basit Bir YoÄŸun (Dense) Model

Ä°nÅŸa edeceÄŸimiz ilk derin model, tek katmanlÄ± yoÄŸun bir modeldir. AslÄ±nda, zar zor tek bir katmana sahip olacak.

Metnimizi ve etiketlerimizi girdi olarak alacak, metni simgeleÅŸtirecek, bir gÃ¶mme oluÅŸturacak, gÃ¶mmenin ortalamasÄ±nÄ± bulacak (KÃ¼resel Ortalama HavuzlamayÄ± kullanarak) ve ardÄ±ndan ortalamayÄ± bir Ã§Ä±ktÄ± birimi ve bir sigmoid etkinleÅŸtirme iÅŸleviyle tam baÄŸlantÄ±lÄ± bir katmandan geÃ§irecektir.

Ã–nceki cÃ¼mle kulaÄŸa aÄŸÄ±z dolusu gibi geliyorsa, onu kodladÄ±ÄŸÄ±mÄ±zda mantÄ±klÄ± olacaktÄ±r (ÅŸÃ¼pheniz varsa, kodlayÄ±n).


```python
# TensorBoard gÃ¼nlÃ¼klerini kaydetmek iÃ§in dizin oluÅŸturun
SAVE_DIR = "model_logs"
```

Åimdi kullanÄ±ma hazÄ±r bir TensorBoard geri Ã§aÄŸÄ±rma iÅŸlevimiz var, hadi ilk derin modelimizi oluÅŸturalÄ±m.


```python
from tensorflow.keras import layers

# girdiler 1 boyutlu dizelerdir
inputs = layers.Input(shape=(1,), dtype="string")

# giriÅŸ metnini sayÄ±lara Ã§evirin
x = text_vectorizer(inputs) 

# numaralandÄ±rÄ±lmÄ±ÅŸ sayÄ±larÄ±n bir gÃ¶mÃ¼lmesini oluÅŸturun
x = embedding(x) 

# gÃ¶mmenin boyutunu azaltÄ±n (modeli bu katman olmadan Ã§alÄ±ÅŸtÄ±rmayÄ± deneyin ve ne olduÄŸunu gÃ¶rÃ¼n)
x = layers.GlobalAveragePooling1D()(x)

# Ã§Ä±ktÄ± katmanÄ±nÄ± oluÅŸturun, ikili Ã§Ä±ktÄ±lar isteyin, bu nedenle sigmoid aktivasyonunu kullanÄ±n
outputs = layers.Dense(1, activation="sigmoid")(x) 

# modeli oluÅŸturun
model_1 = tf.keras.Model(inputs, outputs, name="model_1_dense") 
```

Ä°yi gÃ¶rÃ¼nÃ¼yor. Modelimiz girdi olarak 1 boyutlu bir dize alÄ±r (bizim durumumuzda bir Tweet), ardÄ±ndan text_vectorizer kullanarak dizeyi belirtir ve gÃ¶mmeyi kullanarak bir gÃ¶mme oluÅŸturur.

Daha sonra (isteÄŸe baÄŸlÄ± olarak) Ã§Ä±ktÄ± katmanÄ±na ilettiÄŸimiz tensÃ¶rÃ¼n boyutsallÄ±ÄŸÄ±nÄ± azaltmak iÃ§in gÃ¶mme katmanÄ±nÄ±n Ã§Ä±ktÄ±larÄ±nÄ± havuzlarÄ±z.

Son olarak, havuzlama katmanÄ±nÄ±n Ã§Ä±ktÄ±sÄ±nÄ± sigmoid aktivasyonu ile yoÄŸun bir katmana geÃ§iriyoruz (sorunumuz ikili sÄ±nÄ±flandÄ±rma olduÄŸu iÃ§in sigmoid kullanÄ±yoruz).

Modelimizi verilerle fit etmeden Ã¶nce onu derlememiz gerekiyor. Ä°kili sÄ±nÄ±flandÄ±rma ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, kayÄ±p fonksiyonumuz ve Adam optimize edici olarak "`binary_crossentropy`" kullanacaÄŸÄ±z.


```python
model_1.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

# model derlendi. Ã–zetine gÃ¶z atalÄ±m
model_1.summary()
```

    Model: "model_1_dense"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_1 (InputLayer)         [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization_1 (TextVe (None, 15)                0         
    _________________________________________________________________
    embedding (Embedding)        (None, 15, 128)           1280000   
    _________________________________________________________________
    global_average_pooling1d (Gl (None, 128)               0         
    _________________________________________________________________
    dense (Dense)                (None, 1)                 129       
    =================================================================
    Total params: 1,280,129
    Trainable params: 1,280,129
    Non-trainable params: 0
    _________________________________________________________________
    

EÄŸitilebilir parametrelerin Ã§oÄŸu, gÃ¶mme katmanÄ±nda bulunur. 10.000 (input_dim=10000) boyutunda bir sÃ¶zcÃ¼k daÄŸarcÄ±ÄŸÄ± iÃ§in 128 boyutunda (output_dim=128) bir yerleÅŸtirme oluÅŸturduÄŸumuzu, dolayÄ±sÄ±yla 1.280.000 eÄŸitilebilir parametre oluÅŸturduÄŸumuzu hatÄ±rlayÄ±n.

Pekala, modelimiz derlendi, 5 epoch kullanarak eÄŸitim verilerimize fit edelim. Modelimizin eÄŸitim Ã¶lÃ§Ã¼mlerinin log'lara kaydedildiÄŸinden emin olmak iÃ§in TensorBoard geri Ã§aÄŸÄ±rma iÅŸlevimizi de ileteceÄŸiz.


```python
model_1_history = model_1.fit(
    train_sentences, 
    train_labels,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, 
                                           experiment_name="simple_dense_model")])
```

    Saving TensorBoard log files to: model_logs/simple_dense_model/20210822-070929
    Epoch 1/5
    215/215 [==============================] - 5s 9ms/step - loss: 0.6113 - accuracy: 0.6904 - val_loss: 0.5373 - val_accuracy: 0.7559
    Epoch 2/5
    215/215 [==============================] - 1s 6ms/step - loss: 0.4417 - accuracy: 0.8187 - val_loss: 0.4700 - val_accuracy: 0.7887
    Epoch 3/5
    215/215 [==============================] - 1s 6ms/step - loss: 0.3467 - accuracy: 0.8619 - val_loss: 0.4552 - val_accuracy: 0.7979
    Epoch 4/5
    215/215 [==============================] - 1s 6ms/step - loss: 0.2842 - accuracy: 0.8914 - val_loss: 0.4623 - val_accuracy: 0.7913
    Epoch 5/5
    215/215 [==============================] - 1s 6ms/step - loss: 0.2373 - accuracy: 0.9113 - val_loss: 0.4754 - val_accuracy: 0.7848
    

GÃ¼zel! Bu kadar basit bir model kullandÄ±ÄŸÄ±mÄ±z iÃ§in her epoch Ã§ok hÄ±zlÄ± iÅŸliyor. Modelimizin doÄŸrulama setindeki performansÄ±nÄ± kontrol edelim.


```python
model_1.evaluate(val_sentences, val_labels)
```

    24/24 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7848
    




    [0.4753652513027191, 0.7847769260406494]



Ve modelimizin eÄŸitim loglarÄ±nÄ± TensorBoard ile takip ettiÄŸimize gÃ¶re, onlarÄ± gÃ¶rselleÅŸtirmeye ne dersiniz? Bunu, TensorBoard log dosyalarÄ±mÄ±zÄ± (model_logs dizininde bulunur) TensorBoard.dev'e yÃ¼kleyerek yapabiliriz.

ğŸ”‘ Not: TensorBoard.dev'e yÃ¼klediÄŸiniz her ÅŸeyin herkese aÃ§Ä±k hale geleceÄŸini unutmayÄ±n. PaylaÅŸmak istemediÄŸiniz antrenman kayÄ±tlarÄ± varsa yÃ¼klemeyin.


```python
# !tensorboard dev upload --logdir ./model_logs \
#   --name "First deep model on text data" \
#   --description "Trying a dense model with an embedding layer" \
#   --one_shot # exits the uploader when upload has finished
```

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tensorboard-dense-model-training-curves.png" />

GÃ¼zel! Bunlar bazÄ± renkli eÄŸitim eÄŸrileri. Modelin fazla mÄ± yoksa yetersiz mi olduÄŸunu sÃ¶yler misiniz? Ä°lk derin modelimizi oluÅŸturduk ve eÄŸittik, bir sonraki adÄ±m onunla bazÄ± tahminler yapmak.


```python
# tahminler yapma
model_1_pred_probs = model_1.predict(val_sentences)
model_1_pred_probs[:10]
```




    array([[0.39653158],
           [0.7810238 ],
           [0.9976156 ],
           [0.10114352],
           [0.10857761],
           [0.9328917 ],
           [0.9154491 ],
           [0.9949896 ],
           [0.9680576 ],
           [0.20620456]], dtype=float32)



Son katmanÄ±mÄ±z bir sigmoid aktivasyon fonksiyonu kullandÄ±ÄŸÄ±ndan, tahminlerimizi olasÄ±lÄ±klar ÅŸeklinde geri alÄ±yoruz.

BunlarÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in `tf.round()` kullanacaÄŸÄ±z, yani 0,5'in altÄ±ndaki tahmin olasÄ±lÄ±klarÄ± 0'a ve 0,5'in Ã¼zerindekiler 1'e yuvarlanacaktÄ±r.

ğŸ”‘ Not: Pratikte, bir sigmoid tahmin olasÄ±lÄ±ÄŸÄ±nÄ±n Ã§Ä±ktÄ± eÅŸiÄŸinin mutlaka 0,5 olmasÄ± gerekmez. Ã–rneÄŸin, test yoluyla, seÃ§tiÄŸiniz deÄŸerlendirme metrikleri iÃ§in 0,25'lik bir kesmenin daha iyi olduÄŸunu gÃ¶rebilirsiniz.


```python
# Tahmin olasÄ±lÄ±klarÄ±nÄ± tek boyutlu float tensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))
model_1_preds[:20]
```




    <tf.Tensor: shape=(20,), dtype=float32, numpy=
    array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,
           0., 0., 1.], dtype=float32)>



Åimdi modelimizin tahminlerini sÄ±nÄ±flar ÅŸeklinde elde ettik, onlarÄ± temel doÄŸruluk doÄŸrulama etiketleriyle karÅŸÄ±laÅŸtÄ±rmak iÃ§in `calculate_results()` iÅŸlevimizi kullanabiliriz.


```python
model_1_results = calculate_results(y_true=val_labels, y_pred=model_1_preds)
model_1_results
```




    {'accuracy': 78.4776902887139,
     'f1': 0.7818959205825942,
     'precision': 0.789165199286798,
     'recall': 0.7847769028871391}



Ä°lk derin modelimizi temel modelimizle karÅŸÄ±laÅŸtÄ±rmaya ne dersiniz?


```python
import numpy as np
np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))
```




    array([False, False, False, False])



Bu tÃ¼r bir karÅŸÄ±laÅŸtÄ±rmayÄ± (yeni modele kÄ±yasla temel) birkaÃ§ kez yapacaÄŸÄ±mÄ±z iÃ§in, bize yardÄ±mcÄ± olacak bir fonksiyon oluÅŸturalÄ±m.


```python
def compare_baseline_to_new_results(baseline_results, new_model_results):
  for key, value in baseline_results.items():
    print(f"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}")

compare_baseline_to_new_results(baseline_results=baseline_results, 
                                new_model_results=model_1_results)
```

    Baseline accuracy: 79.27, New accuracy: 78.48, Difference: -0.79
    Baseline precision: 0.81, New precision: 0.79, Difference: -0.02
    Baseline recall: 0.79, New recall: 0.78, Difference: -0.01
    Baseline f1: 0.79, New f1: 0.78, Difference: -0.00
    

# Tekrarlayan Sinir AÄŸlarÄ± (RNN'ler)

Bir sonraki modelleme deneylerimiz iÃ§in, Tekrarlayan Sinir AÄŸÄ± (RNN) adÄ± verilen Ã¶zel bir tÃ¼r sinir aÄŸÄ± kullanacaÄŸÄ±z.

Bir RNN'nin Ã¶nermesi basittir: gelecekte size yardÄ±mcÄ± olmasÄ± iÃ§in geÃ§miÅŸten gelen bilgileri kullanÄ±n (tekrarlayan terimi buradan gelir). BaÅŸka bir deyiÅŸle, bir girdi (X) alÄ±n ve Ã¶nceki tÃ¼m girdilere dayanarak bir Ã§Ä±ktÄ± (y) hesaplayÄ±n.

Bu kavram, Ã¶zellikle doÄŸal dil metinlerinin (Tweet'lerimiz gibi) pasajlarÄ± gibi dizilerle uÄŸraÅŸÄ±rken yararlÄ±dÄ±r.

Ã–rneÄŸin, bu cÃ¼mleyi okuduÄŸunuzda, mevcut kÃ¶pek kelimesinin anlamÄ±nÄ± deÅŸifre ederken Ã¶nceki kelimeleri baÄŸlam iÃ§ine alÄ±rsÄ±nÄ±z. GeÃ§erli bir kelime olan "kÃ¶pek" kelimesini sonuna koydum ama cÃ¼mlenin geri kalanÄ± baÄŸlamÄ±nda bir anlam ifade etmiyor.

Bir RNN bir metin dizisine (zaten sayÄ±sal biÃ§imde) baktÄ±ÄŸÄ±nda, Ã¶ÄŸrendiÄŸi modeller dizinin sÄ±rasÄ±na gÃ¶re sÃ¼rekli olarak gÃ¼ncellenir.

Basit bir Ã¶rnek iÃ§in iki cÃ¼mle alÄ±n:

- GeÃ§en hafta bÃ¼yÃ¼k deprem oldu, deÄŸil mi?
- GeÃ§en hafta bÃ¼yÃ¼k bir deprem olmadÄ±.

Her ikisi de tamamen aynÄ± kelimeleri iÃ§erir, ancak farklÄ± anlamlara sahiptir. SÃ¶zcÃ¼klerin sÄ±rasÄ± anlamÄ± belirler (noktalama iÅŸaretlerinin de anlamÄ± dikte ettiÄŸi tartÄ±ÅŸÄ±labilir, ancak basitlik adÄ±na, kelimelere odaklanalÄ±m).

Tekrarlayan sinir aÄŸlarÄ±, bir dizi dizi tabanlÄ± problem iÃ§in kullanÄ±labilir:

- **Bire bir:**<br> 
bir girdi, bir Ã§Ä±ktÄ±, gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± gibi.
- **Birden Ã§oÄŸa:**<br> 
bir giriÅŸ, resim yazÄ±sÄ± gibi birÃ§ok Ã§Ä±kÄ±ÅŸ (resim giriÅŸi, resim yazÄ±sÄ± Ã§Ä±kÄ±ÅŸÄ± olarak bir metin dizisi).
- **Ã‡oktan bire:**<br>
birÃ§ok girdi, metin sÄ±nÄ±flandÄ±rmasÄ± gibi bir Ã§Ä±ktÄ± (bir Tweet'i gerÃ§ek hata veya gerÃ§ek hata deÄŸil olarak sÄ±nÄ±flandÄ±rma).
- **Ã‡oktan Ã§oÄŸa:**<br>
birÃ§ok girdi, makine Ã§evirisi (Ä°ngilizceden Ä°spanyolcaya Ã§evirme) veya konuÅŸmayÄ± metne (giriÅŸ olarak ses dalgasÄ±, Ã§Ä±ktÄ± olarak metin) gibi birÃ§ok Ã§Ä±ktÄ±.

VahÅŸi doÄŸada RNN'lerle karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda, bÃ¼yÃ¼k olasÄ±lÄ±kla aÅŸaÄŸÄ±dakilerin varyantlarÄ±yla karÅŸÄ±laÅŸacaksÄ±nÄ±z:

- Uzun kÄ±sa sÃ¼reli hafÄ±za hÃ¼creleri (LSTM'ler).
- KapÄ±lÄ± yinelenen birimler (GRU'lar).
- Ã‡ift yÃ¶nlÃ¼ RNN'ler (bir dizi boyunca ileri ve geri, soldan saÄŸa ve saÄŸdan sola geÃ§er).

BunlarÄ±n her birinin ayrÄ±ntÄ±larÄ±na girmek bu defterin kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r (bunun yerine onlarÄ± kullanmaya odaklanacaÄŸÄ±z), ÅŸimdilik bilmeniz gereken en Ã¶nemli ÅŸey, dizileri modellemede Ã§ok etkili olduklarÄ±nÄ± kanÄ±tladÄ±klarÄ±dÄ±r.

Yazmak Ã¼zere olduÄŸumuz kodun perde arkasÄ±nda neler olduÄŸunu daha iyi anlamak iÃ§in aÅŸaÄŸÄ±daki kaynaklarÄ± tavsiye ederim:
> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) 
> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) 
> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) 


## Model 2: LSTM

RNN'lerin ne olduÄŸu ve ne iÅŸe yaradÄ±ÄŸÄ±yla ilgili tÃ¼m bu konuÅŸmalardan sonra, eminim siz de bir tane oluÅŸturmaya heveslisinizdir. LSTM destekli bir RNN ile baÅŸlayacaÄŸÄ±z.

TensorFlow'da LSTM hÃ¼cresinin (LSTM hÃ¼cresi ve LSTM katmanÄ± genellikle birbirinin yerine kullanÄ±lÄ±r) gÃ¼cÃ¼nden yararlanmak iÃ§in [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/) kullanacaÄŸÄ±z. api_docs/python/tf/keras/layers/LSTM).

Modelimiz `model_1` ile Ã§ok benzer bir yapÄ± alacak:

```
Input (metin) -> Tokenization -> Embedding -> Layers -> Output (etiket olasÄ±lÄ±ÄŸÄ±)
```

Temel fark, gÃ¶mme ve Ã§Ä±ktÄ±mÄ±z arasÄ±na bir LSTM katmanÄ± ekleyeceÄŸimiz olacaktÄ±r.


```python
# LSTM oluÅŸturma
from tensorflow.keras import layers

inputs = layers.Input(shape=(1,), dtype="string")
x = text_vectorizer(inputs)
x = embedding(x)
print(x.shape)

x = layers.LSTM(64)(x)
print(x.shape)

outputs = layers.Dense(1, activation="sigmoid")(x)
model_2 = tf.keras.Model(inputs, outputs, name="model_2_LSTM")
```

    (None, 15, 128)
    (None, 64)
    

> ğŸ”‘ **Not:** [TensorFlow LSTM katmanÄ±](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) iÃ§in belgeleri okurken, Ã§ok sayÄ±da parametre bulacaksÄ±nÄ±z . BunlarÄ±n Ã§oÄŸu, mÃ¼mkÃ¼n olduÄŸunca hÄ±zlÄ± hesaplanmalarÄ±nÄ± saÄŸlamak iÃ§in ayarlanmÄ±ÅŸtÄ±r. Ayarlamak isteyeceÄŸiniz baÅŸlÄ±ca olanlar "units" (gizli birimlerin sayÄ±sÄ±) ve "return_sequences"dir (LSTM veya diÄŸer tekrarlayan katmanlarÄ± istiflerken bunu "True" olarak ayarlayÄ±n).

Åimdi LSTM modelimizi oluÅŸturduk, hadi onu `"binary_crossentropy"` kaybÄ± ve Adam optimizer kullanarak derleyelim.


```python
model_2.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

# Modelimizi fit etmeden Ã¶nce bir Ã¶zet geÃ§elim:
model_2.summary()
```

    Model: "model_2_LSTM"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_2 (InputLayer)         [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization_1 (TextVe (None, 15)                0         
    _________________________________________________________________
    embedding (Embedding)        (None, 15, 128)           1280000   
    _________________________________________________________________
    lstm (LSTM)                  (None, 64)                49408     
    _________________________________________________________________
    dense_1 (Dense)              (None, 1)                 65        
    =================================================================
    Total params: 1,329,473
    Trainable params: 1,329,473
    Non-trainable params: 0
    _________________________________________________________________
    

Ä°yi gÃ¶rÃ¼nÃ¼yor! LSTM katmanÄ±mÄ±zda "model_1"den Ã§ok daha fazla eÄŸitilebilir parametre fark edeceksiniz.

Bu sayÄ±nÄ±n nereden geldiÄŸini bilmek istiyorsanÄ±z, bir LSTM hÃ¼cresindeki parametre sayÄ±sÄ±nÄ± hesaplamak iÃ§in yukarÄ±daki kaynaklarÄ± ve aÅŸaÄŸÄ±dakileri incelemenizi Ã¶neririm:
* [LSTM hÃ¼cresindeki parametre sayÄ±sÄ±nÄ± hesaplamak iÃ§in Stack Overflow yanÄ±tÄ±](https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network ) yazan Marcin MoÅ¼ejko
* [LSTM birimindeki ve katmanÄ±ndaki parametre sayÄ±sÄ± hesaplanÄ±yor](https://medium.com/@priyadarshi.cse/calcizing-number-of-parameters-in-a-lstm-unit-layer-7e491978e1e4) Shridhar Priyadarshi

Åimdi ilk RNN modelimiz derlendi, onu eÄŸitim verilerimizle fit edelim, doÄŸrulama verileri Ã¼zerinde doÄŸrulayalÄ±m ve TensorBoard geri Ã§aÄŸrÄ±mÄ±zÄ± kullanarak eÄŸitim parametrelerini takip edelim.


```python
model_2_history = model_2.fit(
    train_sentences,
    train_labels,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(SAVE_DIR, "LSTM")])
```

    Saving TensorBoard log files to: model_logs/LSTM/20210822-070941
    Epoch 1/5
    215/215 [==============================] - 7s 14ms/step - loss: 0.2219 - accuracy: 0.9237 - val_loss: 0.5674 - val_accuracy: 0.7795
    Epoch 2/5
    215/215 [==============================] - 2s 10ms/step - loss: 0.1562 - accuracy: 0.9429 - val_loss: 0.5965 - val_accuracy: 0.7730
    Epoch 3/5
    215/215 [==============================] - 2s 10ms/step - loss: 0.1307 - accuracy: 0.9510 - val_loss: 0.7095 - val_accuracy: 0.7769
    Epoch 4/5
    215/215 [==============================] - 2s 10ms/step - loss: 0.1053 - accuracy: 0.9606 - val_loss: 0.7949 - val_accuracy: 0.7874
    Epoch 5/5
    215/215 [==============================] - 2s 10ms/step - loss: 0.0886 - accuracy: 0.9673 - val_loss: 0.8062 - val_accuracy: 0.7808
    

GÃ¼zel! LSTM hÃ¼crelerini kullanan ilk eÄŸitimli RNN modelimize sahibiz. Onunla bazÄ± tahminler yapalÄ±m. Son katmandaki sigmoid aktivasyon fonksiyonu nedeniyle daha Ã¶nce olduÄŸu gibi aynÄ± ÅŸey olacak, modelimizde `predict()` yÃ¶ntemini Ã§aÄŸÄ±rdÄ±ÄŸÄ±mÄ±zda sÄ±nÄ±flardan ziyade tahmin olasÄ±lÄ±klarÄ±nÄ± dÃ¶ndÃ¼recek.


```python
model_2_pred_probs = model_2.predict(val_sentences)
model_2_pred_probs.shape, model_2_pred_probs[:10]
```




    ((762, 1), array([[0.1147354 ],
            [0.94750935],
            [0.9996575 ],
            [0.11396935],
            [0.00261294],
            [0.99850935],
            [0.95742464],
            [0.9997907 ],
            [0.9996567 ],
            [0.39139414]], dtype=float32))



Bu tahmin olasÄ±lÄ±klarÄ±nÄ± en yakÄ±n tam sayÄ±ya yuvarlayarak tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rebiliriz (varsayÄ±lan olarak 0,5'in altÄ±ndaki tahmin olasÄ±lÄ±klarÄ± 0'a, 0,5'in Ã¼zerindekiler ise 1'e gidecektir).


```python
model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))
model_2_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>



GÃ¼zel, ÅŸimdi LSTM modelimizi deÄŸerlendirmek iÃ§in `caculate_results()` iÅŸlevimizi ve bunu temel modelimizle karÅŸÄ±laÅŸtÄ±rmak iÃ§in `Compare_baseline_to_new_results()` iÅŸlevimizi kullanalÄ±m.


```python
model_2_results = calculate_results(y_true=val_labels,
                                    y_pred=model_2_preds)
model_2_results
```




    {'accuracy': 78.08398950131233,
     'f1': 0.7794817733933848,
     'precision': 0.781486692298758,
     'recall': 0.7808398950131233}




```python
compare_baseline_to_new_results(baseline_results, model_2_results)
```

    Baseline accuracy: 79.27, New accuracy: 78.08, Difference: -1.18
    Baseline precision: 0.81, New precision: 0.78, Difference: -0.03
    Baseline recall: 0.79, New recall: 0.78, Difference: -0.01
    Baseline f1: 0.79, New f1: 0.78, Difference: -0.01
    

## Model 3: GRU

Bir baÅŸka popÃ¼ler ve etkili RNN bileÅŸeni, GRU veya kapÄ±lÄ± tekrarlayan birimdir. GRU hÃ¼cresi, bir LSTM hÃ¼cresine benzer Ã¶zelliklere sahiptir ancak daha az parametreye sahiptir.

GRU hÃ¼cresini TensorFlow'da kullanmak iÃ§in [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) sÄ±nÄ±fÄ±nÄ± Ã§aÄŸÄ±rabiliriz.

GRU destekli modelin mimarisi, kullandÄ±ÄŸÄ±mÄ±z yapÄ±yla aynÄ± olacak:

```
Input (metin) -> Tokenization -> Embedding -> Layers -> Output (etiket olasÄ±lÄ±ÄŸÄ±)
```
Yine, tek fark, gÃ¶mme ve Ã§Ä±ktÄ± arasÄ±nda kullandÄ±ÄŸÄ±mÄ±z katman(lar) olacaktÄ±r.


```python
from tensorflow.keras import layers

inputs = layers.Input(shape=(1,), dtype="string")
x = text_vectorizer(inputs)
x = embedding(x)
x = layers.GRU(64)(x) 
outputs = layers.Dense(1, activation="sigmoid")(x)
model_3 = tf.keras.Model(inputs, outputs, name="model_3_GRU")
```

TensorFlow, modellerimizde GRU hÃ¼cresi gibi gÃ¼Ã§lÃ¼ bileÅŸenleri kullanmayÄ± kolaylaÅŸtÄ±rÄ±r. Ve ÅŸimdi Ã¼Ã§Ã¼ncÃ¼ modelimiz yapÄ±ldÄ±, eskisi gibi derleyelim.


```python
model_3.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_3.summary()
```

    Model: "model_3_GRU"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_3 (InputLayer)         [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization_1 (TextVe (None, 15)                0         
    _________________________________________________________________
    embedding (Embedding)        (None, 15, 128)           1280000   
    _________________________________________________________________
    gru (GRU)                    (None, 64)                37248     
    _________________________________________________________________
    dense_2 (Dense)              (None, 1)                 65        
    =================================================================
    Total params: 1,317,313
    Trainable params: 1,317,313
    Non-trainable params: 0
    _________________________________________________________________
    

`model_2` (LSTM) ve `model_3` (GRU) arasÄ±ndaki eÄŸitilebilir parametre sayÄ±sÄ±ndaki farka dikkat edin. Fark, GRU hÃ¼cresinden daha fazla eÄŸitilebilir parametreye sahip LSTM hÃ¼cresinden gelir.

Modelimize daha Ã¶nce yaptÄ±ÄŸÄ±mÄ±z gibi fit edeceÄŸiz. AyrÄ±ca, `create_tensorboard_callback()` fonksiyonumuzu kullanarak model sonuÃ§larÄ±mÄ±zÄ± takip edeceÄŸiz.


```python
model_3_history = model_3.fit(
    train_sentences,
    train_labels,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(SAVE_DIR, "GRU")])
```

    Saving TensorBoard log files to: model_logs/GRU/20210822-070958
    Epoch 1/5
    215/215 [==============================] - 5s 14ms/step - loss: 0.1533 - accuracy: 0.9399 - val_loss: 0.7544 - val_accuracy: 0.7690
    Epoch 2/5
    215/215 [==============================] - 2s 9ms/step - loss: 0.0892 - accuracy: 0.9677 - val_loss: 0.6545 - val_accuracy: 0.7808
    Epoch 3/5
    215/215 [==============================] - 2s 9ms/step - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.8501 - val_accuracy: 0.7743
    Epoch 4/5
    215/215 [==============================] - 2s 9ms/step - loss: 0.0622 - accuracy: 0.9740 - val_loss: 0.9582 - val_accuracy: 0.7743
    Epoch 5/5
    215/215 [==============================] - 2s 10ms/step - loss: 0.0565 - accuracy: 0.9768 - val_loss: 1.2119 - val_accuracy: 0.7717
    

TensorFlow'daki GRU hÃ¼cresinin optimize edilmiÅŸ varsayÄ±lan ayarlarÄ± nedeniyle, eÄŸitim hiÃ§ uzun sÃ¼rmez. DoÄŸrulama Ã¶rnekleri Ã¼zerinde bazÄ± tahminlerde bulunma zamanÄ±.


```python
model_3_pred_probs = model_3.predict(val_sentences)
model_3_pred_probs.shape, model_3_pred_probs[:10]
```




    ((762, 1), array([[1.6326897e-02],
            [8.8803720e-01],
            [9.9982280e-01],
            [4.5834299e-02],
            [1.4948420e-04],
            [9.9980944e-01],
            [9.7764552e-01],
            [9.9996221e-01],
            [9.9989629e-01],
            [9.8516256e-01]], dtype=float32))



Yine, onlarÄ± yuvarlayarak tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rebileceÄŸimiz bir dizi tahmin olasÄ±lÄ±ÄŸÄ± elde ederiz.


```python
model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))
model_3_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>



Åimdi tahmini sÄ±nÄ±flarÄ±mÄ±z var, bunlarÄ± temel doÄŸruluk etiketlerine gÃ¶re deÄŸerlendirelim.


```python
model_3_results = calculate_results(y_true=val_labels, 
                                    y_pred=model_3_preds)
model_3_results
```




    {'accuracy': 77.16535433070865,
     'f1': 0.7712815503325242,
     'precision': 0.7712950933950157,
     'recall': 0.7716535433070866}



Son olarak, GRU modelimizin sonuÃ§larÄ±nÄ± taban Ã§izgimizle karÅŸÄ±laÅŸtÄ±rabiliriz.


```python
compare_baseline_to_new_results(baseline_results, model_3_results)
```

    Baseline accuracy: 79.27, New accuracy: 77.17, Difference: -2.10
    Baseline precision: 0.81, New precision: 0.77, Difference: -0.04
    Baseline recall: 0.79, New recall: 0.77, Difference: -0.02
    Baseline f1: 0.79, New f1: 0.77, Difference: -0.01
    

GRU ile LSTM arasÄ±nda ki farkÄ±, [StackExchange'de bulunan yorumda](https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm?newreg=64d5f02c755b43d2b855e03bb715e165) Ã§ok gÃ¼zel Ã¶zetlemiÅŸ:
* GRU, LSTM birimi gibi bilgi akÄ±ÅŸÄ±nÄ± kontrol eder, ancak bir bellek birimi kullanmak zorunda kalmadan. Herhangi bir kontrol olmaksÄ±zÄ±n tam gizli iÃ§eriÄŸi ortaya Ã§Ä±karÄ±r.
* GRU nispeten yeni ve benim aÃ§Ä±mdan performans LSTM ile eÅŸit, ancak hesaplama aÃ§Ä±sÄ±ndan daha verimli (belirtildiÄŸi gibi daha az karmaÅŸÄ±k yapÄ±). Bu yÃ¼zden giderek daha fazla kullanÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz.
* Deneyimlerime gÃ¶re, dil modelleme yapÄ±yorsanÄ±z (diÄŸer gÃ¶revlerden emin deÄŸilsiniz) GRU'lar daha hÄ±zlÄ± eÄŸitim alÄ±r ve daha az eÄŸitim verisi Ã¼zerinde LSTM'lerden daha iyi performans gÃ¶sterir.
* GRU'lar daha basittir ve bu nedenle deÄŸiÅŸtirilmesi daha kolaydÄ±r.

## Model 4: Ã‡ift YÃ¶nlÃ¼ RNN modeli

HalihazÄ±rda GRU ve LSTM hÃ¼creli iki RNN oluÅŸturduk. Åimdi baÅŸka bir tÃ¼r RNN'yi, Ã§ift yÃ¶nlÃ¼ RNN'yi inceleyeceÄŸiz.

Standart bir RNN, bir diziyi soldan saÄŸa iÅŸleyecektir, burada Ã§ift yÃ¶nlÃ¼ bir RNN, diziyi soldan saÄŸa ve ardÄ±ndan tekrar saÄŸdan sola iÅŸleyecektir.

Sezgisel olarak, bu, bir cÃ¼mleyi ilk kez normal ÅŸekilde (soldan saÄŸa) okuyormuÅŸsunuz gibi dÃ¼ÅŸÃ¼nÃ¼lebilir, ancak bir nedenden dolayÄ± bu mantÄ±klÄ± gelmedi, bu yÃ¼zden kelimeler arasÄ±nda geri dÃ¶nÃ¼p tekrar Ã¼zerinden geÃ§tiniz. (saÄŸdan sola).

Pratikte, birÃ§ok dizi modeli, Ã§ift yÃ¶nlÃ¼ RNN'leri kullanÄ±rken performansta sÄ±klÄ±kla gÃ¶rÃ¼lÃ¼r ve geliÅŸme gÃ¶sterir.

Bununla birlikte, performanstaki bu geliÅŸme genellikle daha uzun eÄŸitim sÃ¼releri ve artan model parametreleri pahasÄ±na gelir (model soldan saÄŸa ve saÄŸdan sola gittiÄŸinden, eÄŸitilebilir parametrelerin sayÄ±sÄ± iki katÄ±na Ã§Ä±kar).

Yeterince konuÅŸtuk, hadi Ã§ift yÃ¶nlÃ¼ bir RNN oluÅŸturalÄ±m.

TensorFlow bir kez daha [`tensorflow.keras.layers.Bi Directional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bi Direction) sÄ±nÄ±fÄ±nÄ± saÄŸlayarak bize yardÄ±mcÄ± oluyor. Mevcut RNN'lerimizi sarmak iÃ§in `Bi Directional` sÄ±nÄ±fÄ±nÄ± kullanabilir ve onlarÄ± anÄ±nda Ã§ift yÃ¶nlÃ¼ hale getirebiliriz.


```python
from tensorflow.keras import layers

inputs = layers.Input(shape=(1,), dtype="string")
x = text_vectorizer(inputs)
x = embedding(x)

# Ã§ift yÃ¶nlÃ¼, her iki yÃ¶ne de gider, 
# bu nedenle normal bir LSTM katmanÄ±nÄ±n parametrelerinin iki katÄ±dÄ±r
x = layers.Bidirectional(layers.LSTM(64))(x)

outputs = layers.Dense(1, activation="sigmoid")(x)
model_4 = tf.keras.Model(inputs, outputs, name="model_4_Bidirectional")
```

> ğŸ”‘ **Not:** TensorFlow'daki herhangi bir RNN hÃ¼cresinde "Ã‡ift YÃ¶nlÃ¼" sarmalayÄ±cÄ±yÄ± kullanabilirsiniz. Ã–rneÄŸin, `layers.Bidirectional(layers.GRU(64))` Ã§ift yÃ¶nlÃ¼ bir GRU hÃ¼cresi oluÅŸturur.

Ã‡ift yÃ¶nlÃ¼ modelimiz oluÅŸturuldu, derleyelim.


```python
model_4.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_4.summary()
```

    Model: "model_4_Bidirectional"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_4 (InputLayer)         [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization_1 (TextVe (None, 15)                0         
    _________________________________________________________________
    embedding (Embedding)        (None, 15, 128)           1280000   
    _________________________________________________________________
    bidirectional (Bidirectional (None, 128)               98816     
    _________________________________________________________________
    dense_3 (Dense)              (None, 1)                 129       
    =================================================================
    Total params: 1,378,945
    Trainable params: 1,378,945
    Non-trainable params: 0
    _________________________________________________________________
    

model_2'ye (normal LSTM) kÄ±yasla model_4'te (Ã§ift yÃ¶nlÃ¼ LSTM) artan eÄŸitilebilir parametre sayÄ±sÄ±na dikkat edin. Bunun nedeni, RNN'mize eklediÄŸimiz Ã§ift yÃ¶nlÃ¼lÃ¼ktÃ¼r.

Ã‡ift yÃ¶nlÃ¼ modelimize fit etme ve performansÄ±nÄ± takip etme zamanÄ±.


```python
model_4_history = model_4.fit(
    train_sentences,
    train_labels,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(SAVE_DIR, "bidirectional_RNN")])
```

    Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210822-071022
    Epoch 1/5
    215/215 [==============================] - 8s 21ms/step - loss: 0.1078 - accuracy: 0.9653 - val_loss: 0.9425 - val_accuracy: 0.7664
    Epoch 2/5
    215/215 [==============================] - 3s 14ms/step - loss: 0.0544 - accuracy: 0.9774 - val_loss: 1.2819 - val_accuracy: 0.7585
    Epoch 3/5
    215/215 [==============================] - 3s 14ms/step - loss: 0.0462 - accuracy: 0.9791 - val_loss: 1.1894 - val_accuracy: 0.7664
    Epoch 4/5
    215/215 [==============================] - 3s 14ms/step - loss: 0.0469 - accuracy: 0.9784 - val_loss: 1.3589 - val_accuracy: 0.7782
    Epoch 5/5
    215/215 [==============================] - 3s 14ms/step - loss: 0.0401 - accuracy: 0.9806 - val_loss: 1.4919 - val_accuracy: 0.7612
    

Modelimizin Ã§ift yÃ¶nlÃ¼ olmasÄ± nedeniyle eÄŸitim sÃ¼resinde hafif bir artÄ±ÅŸ gÃ¶rÃ¼yoruz. EndiÅŸelenme, Ã§ok dramatik bir artÄ±ÅŸ deÄŸil. Onunla bazÄ± tahminler yapalÄ±m.


```python
model_4_pred_probs = model_4.predict(val_sentences)
model_4_pred_probs[:10]
```




    array([[1.2317987e-01],
           [7.2211808e-01],
           [9.9997759e-01],
           [9.2619851e-02],
           [5.5663345e-06],
           [9.9944931e-01],
           [9.8846996e-01],
           [9.9999142e-01],
           [9.9998176e-01],
           [9.5131034e-01]], dtype=float32)



Ve onlarÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz ve onlarÄ± temel doÄŸruluk etiketlerine ve temel modele gÃ¶re deÄŸerlendireceÄŸiz.


```python
# # Tahmin olasÄ±lÄ±klarÄ±nÄ± etiketlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))
model_4_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>




```python
# Ã‡ift yÃ¶nlÃ¼ RNN model sonuÃ§larÄ±nÄ± hesaplayÄ±n
model_4_results = calculate_results(val_labels, model_4_preds)
model_4_results
```




    {'accuracy': 76.11548556430446,
     'f1': 0.7593763358258425,
     'precision': 0.7618883943071393,
     'recall': 0.7611548556430446}




```python
# Ã‡ift yÃ¶nlÃ¼ modelin taban Ã§izgisine gÃ¶re nasÄ±l 
# performans gÃ¶sterdiÄŸini kontrol edin
compare_baseline_to_new_results(baseline_results, model_4_results)
```

    Baseline accuracy: 79.27, New accuracy: 76.12, Difference: -3.15
    Baseline precision: 0.81, New precision: 0.76, Difference: -0.05
    Baseline recall: 0.79, New recall: 0.76, Difference: -0.03
    Baseline f1: 0.79, New f1: 0.76, Difference: -0.03
    

## Metin iÃ§in EvriÅŸimli Sinir AÄŸlarÄ±

Daha Ã¶nce gÃ¶rÃ¼ntÃ¼ler iÃ§in evriÅŸimli sinir aÄŸlarÄ±nÄ± (CNN'ler) kullanmÄ±ÅŸ olabilirsiniz, ancak bunlar diziler iÃ§in de kullanÄ±labilir.

GÃ¶rÃ¼ntÃ¼ler ve diziler iÃ§in CNN'leri kullanma arasÄ±ndaki temel fark, verilerin ÅŸeklidir. GÃ¶rÃ¼ntÃ¼ler 2 boyutlu (yÃ¼kseklik x geniÅŸlik) gelirken, diziler genellikle 1 boyutludur (bir metin dizisi).

CNN'leri dizilerle kullanmak iÃ§in 2 boyutlu evriÅŸim yerine 1 boyutlu evriÅŸim kullanÄ±rÄ±z.

Diziler iÃ§in tipik bir CNN mimarisi aÅŸaÄŸÄ±daki gibi gÃ¶rÃ¼necektir:

```
Input (metin) -> Tokenization -> Embedding -> Layers -> Output (sÄ±nÄ±f olasÄ±lÄ±klarÄ±)
```

"Bu, diÄŸer modeller iÃ§in kullandÄ±ÄŸÄ±mÄ±z mimari dÃ¼zene benziyor..." diye dÃ¼ÅŸÃ¼nÃ¼yor olabilirsiniz. HaklÄ±sÄ±nÄ±z da. Fark yine katmanlar bileÅŸenindedir. Bir LSTM veya GRU hÃ¼cresi kullanmak yerine, bir [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/) katmanÄ± ve ardÄ±ndan bir [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) katmanÄ± kullanacaÄŸÄ±z.

## Model 5: Conv1D

Tam 1 boyutlu bir CNN modeli oluÅŸturmadan Ã¶nce, 1 boyutlu evriÅŸim katmanÄ±nÄ±  Ã§alÄ±ÅŸÄ±rken gÃ¶relim. Ã–nce bir metin Ã¶rneÄŸinin gÃ¶mÃ¼lmesini oluÅŸturacaÄŸÄ±z ve onu bir `Conv1D()` katmanÄ± ve `GlobalMaxPool1D()` katmanÄ±ndan geÃ§irmeyi deneyeceÄŸiz.


```python
embedding_test = embedding(text_vectorizer(["this is a test sentence"]))
conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation="relu")
conv_1d_output = conv_1d(embedding_test)
max_pool = layers.GlobalMaxPool1D() 
max_pool_output = max_pool(conv_1d_output)
embedding_test.shape, conv_1d_output.shape, max_pool_output.shape
```




    (TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))



Her katmanÄ±n Ã§Ä±ktÄ± ÅŸekillerine dikkat edin.

GÃ¶mme, ayarladÄ±ÄŸÄ±mÄ±z parametrelerin Ã§Ä±ktÄ± ÅŸekli boyutuna sahiptir (`input_length=15` ve`output_dim=128`).

1 boyutlu evriÅŸim katmanÄ±, parametreleriyle aynÄ± hizada sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ bir Ã§Ä±ktÄ±ya sahiptir. AynÄ± ÅŸey, maksimum havuzlama katmanÄ± Ã§Ä±ktÄ±sÄ± iÃ§in de geÃ§erlidir.

Metnimiz bir dize olarak baÅŸlar, ancak Ã§eÅŸitli dÃ¶nÃ¼ÅŸtÃ¼rme adÄ±mlarÄ±yla 64 uzunluÄŸunda bir Ã¶zellik vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Bu dÃ¶nÃ¼ÅŸÃ¼mlerin her birinin neye benzediÄŸine bir bakalÄ±m.


```python
embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]
```




    (<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=
     array([[[ 0.00319095, -0.01416333, -0.03029248, ..., -0.03457287,
              -0.04297013, -0.04403625],
             [-0.02292195, -0.05479934, -0.00761494, ...,  0.04868896,
               0.05149416,  0.00035047],
             [ 0.01908881, -0.02073449, -0.03212655, ...,  0.04440343,
               0.01428682, -0.01586873],
             ...,
             [-0.00470371,  0.01156277, -0.01759247, ..., -0.00937972,
               0.01118098, -0.00774161],
             [-0.00470371,  0.01156277, -0.01759247, ..., -0.00937972,
               0.01118098, -0.00774161],
             [-0.00470371,  0.01156277, -0.01759247, ..., -0.00937972,
               0.01118098, -0.00774161]]], dtype=float32)>,
     <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=
     array([[[0.00000000e+00, 8.05034712e-02, 0.00000000e+00, 1.15600638e-02,
              0.00000000e+00, 5.81747759e-03, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 1.27381273e-02, 3.38597856e-02, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 4.80861589e-02, 0.00000000e+00,
              3.96751724e-02, 0.00000000e+00, 0.00000000e+00, 3.05385999e-02,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 4.12951857e-02, 0.00000000e+00, 6.95906281e-02,
              0.00000000e+00, 5.94841614e-02, 9.18674469e-02, 5.20823263e-02],
             [2.63430271e-02, 8.44356269e-02, 2.81330571e-03, 6.74604177e-02,
              0.00000000e+00, 8.42802040e-03, 0.00000000e+00, 1.10559706e-02,
              4.07118723e-02, 0.00000000e+00, 0.00000000e+00, 3.80547568e-02,
              0.00000000e+00, 8.79763439e-02, 4.59032431e-02, 3.13887000e-02,
              2.62255073e-02, 4.18251473e-03, 0.00000000e+00, 0.00000000e+00,
              1.02217998e-02, 0.00000000e+00, 9.08166170e-03, 2.56322473e-02,
              7.09645683e-03, 1.22743607e-01, 0.00000000e+00, 3.41253951e-02,
              0.00000000e+00, 0.00000000e+00, 6.04886301e-02, 4.24289927e-02],
             [0.00000000e+00, 2.03429386e-02, 0.00000000e+00, 9.06437784e-02,
              0.00000000e+00, 1.33926468e-02, 6.44886717e-02, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 5.57984598e-03, 0.00000000e+00,
              2.80500129e-02, 3.06625962e-02, 1.82882883e-02, 0.00000000e+00,
              0.00000000e+00, 1.14728551e-04, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.61776145e-02,
              2.19251886e-02, 6.81912601e-02, 0.00000000e+00, 2.30189972e-02,
              0.00000000e+00, 1.26050590e-02, 1.36954803e-02, 0.00000000e+00],
             [0.00000000e+00, 7.14183897e-02, 0.00000000e+00, 7.31983259e-02,
              0.00000000e+00, 0.00000000e+00, 1.36040617e-02, 0.00000000e+00,
              0.00000000e+00, 4.47261706e-02, 0.00000000e+00, 0.00000000e+00,
              1.97688714e-02, 0.00000000e+00, 2.63667684e-02, 1.55701367e-02,
              9.24898498e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.16558182e-02, 0.00000000e+00, 1.84091628e-02,
              0.00000000e+00, 9.06079710e-02, 0.00000000e+00, 5.93137965e-02,
              0.00000000e+00, 7.36142173e-02, 2.71241888e-02, 0.00000000e+00],
             [0.00000000e+00, 5.90131134e-02, 0.00000000e+00, 2.19131652e-02,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 2.85770036e-02, 3.44222710e-02, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 2.71796528e-02, 5.12055531e-02,
              5.00489324e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.82179581e-02, 1.01004215e-02, 0.00000000e+00,
              3.42076607e-02, 5.01884520e-02, 0.00000000e+00, 6.73409179e-02,
              1.43867647e-02, 5.38122803e-02, 5.80260493e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517823e-02, 6.49180636e-03, 2.89049260e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823136e-02, 2.80115753e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30828079e-02, 3.57510448e-02,
              1.88314561e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870250e-02, 4.26470116e-02, 1.91313103e-02,
              1.24170668e-02, 6.92164451e-02, 0.00000000e+00, 4.52357307e-02,
              1.14318049e-02, 4.45467979e-02, 2.09700465e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517749e-02, 6.49180962e-03, 2.89049223e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823210e-02, 2.80119071e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30828042e-02, 3.57510559e-02,
              1.88314579e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870324e-02, 4.26470190e-02, 1.91313159e-02,
              1.24170687e-02, 6.92164376e-02, 0.00000000e+00, 4.52357307e-02,
              1.14318095e-02, 4.45467979e-02, 2.09700502e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517749e-02, 6.49180589e-03, 2.89049186e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823173e-02, 2.80117441e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30827995e-02, 3.57510522e-02,
              1.88314561e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870324e-02, 4.26470190e-02, 1.91313140e-02,
              1.24170706e-02, 6.92164376e-02, 0.00000000e+00, 4.52357270e-02,
              1.14318077e-02, 4.45467979e-02, 2.09700502e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517786e-02, 6.49181195e-03, 2.89049149e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823210e-02, 2.80118053e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30827948e-02, 3.57510522e-02,
              1.88314617e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870250e-02, 4.26470228e-02, 1.91313084e-02,
              1.24170706e-02, 6.92164451e-02, 0.00000000e+00, 4.52357233e-02,
              1.14318114e-02, 4.45468016e-02, 2.09700502e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517711e-02, 6.49181567e-03, 2.89049074e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823210e-02, 2.80116277e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30828023e-02, 3.57510485e-02,
              1.88314617e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870324e-02, 4.26470228e-02, 1.91313103e-02,
              1.24170696e-02, 6.92164302e-02, 0.00000000e+00, 4.52357307e-02,
              1.14318039e-02, 4.45467904e-02, 2.09700465e-02, 0.00000000e+00],
             [0.00000000e+00, 4.34517749e-02, 6.49181474e-03, 2.89049149e-02,
              0.00000000e+00, 0.00000000e+00, 1.56823229e-02, 2.80122069e-04,
              0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 0.00000000e+00, 1.30828032e-02, 3.57510522e-02,
              1.88314542e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
              0.00000000e+00, 3.27870250e-02, 4.26470190e-02, 1.91313140e-02,
              1.24170706e-02, 6.92164451e-02, 0.00000000e+00, 4.52357233e-02,
              1.14318067e-02, 4.45467941e-02, 2.09700484e-02, 0.00000000e+00]]],
           dtype=float32)>,
     <tf.Tensor: shape=(1, 32), dtype=float32, numpy=
     array([[0.02634303, 0.08443563, 0.00649182, 0.09064378, 0.        ,
             0.01339265, 0.06448867, 0.01105597, 0.04071187, 0.04472617,
             0.03442227, 0.03805476, 0.02805001, 0.08797634, 0.04808616,
             0.05120555, 0.05004893, 0.00418251, 0.        , 0.0305386 ,
             0.0102218 , 0.03821796, 0.04264702, 0.04617761, 0.03420766,
             0.12274361, 0.        , 0.06959063, 0.01438676, 0.07361422,
             0.09186745, 0.05208233]], dtype=float32)>)



Pekala, diziler iÃ§in bir CNN'nin Ã§eÅŸitli bileÅŸenlerinin Ã§Ä±ktÄ±larÄ±nÄ± gÃ¶rdÃ¼k, onlarÄ± bir araya getirelim ve tam bir model oluÅŸturalÄ±m, onu derleyelim (tÄ±pkÄ± diÄŸer modellerimizde yaptÄ±ÄŸÄ±mÄ±z gibi) ve bir Ã¶zet alalÄ±m.


```python
from tensorflow.keras import layers

inputs = layers.Input(shape=(1,), dtype="string")
x = text_vectorizer(inputs)
x = embedding(x)
x = layers.Conv1D(filters=32, kernel_size=5, activation="relu")(x)
x = layers.GlobalMaxPool1D()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model_5 = tf.keras.Model(inputs, outputs, name="model_5_Conv1D")

model_5.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_5.summary()
```

    Model: "model_5_Conv1D"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_5 (InputLayer)         [(None, 1)]               0         
    _________________________________________________________________
    text_vectorization_1 (TextVe (None, 15)                0         
    _________________________________________________________________
    embedding (Embedding)        (None, 15, 128)           1280000   
    _________________________________________________________________
    conv1d_1 (Conv1D)            (None, 11, 32)            20512     
    _________________________________________________________________
    global_max_pooling1d_1 (Glob (None, 32)                0         
    _________________________________________________________________
    dense_4 (Dense)              (None, 1)                 33        
    =================================================================
    Total params: 1,300,545
    Trainable params: 1,300,545
    Non-trainable params: 0
    _________________________________________________________________
    

SÃ¼perr! Harika gÃ¶rÃ¼nÃ¼yor! 1-boyutlu evriÅŸimli katman iÃ§in eÄŸitilebilir parametre sayÄ±sÄ±nÄ±n `model_2`'deki LSTM katmanÄ±nÄ±nkine nasÄ±l benzer olduÄŸuna dikkat edin.

1D CNN modelimizi metin verilerimizle fit edelim. Ã–nceki deneylere uygun olarak, `create_tensorboard_callback()` fonksiyonumuzu kullanarak sonuÃ§larÄ±nÄ± kaydedeceÄŸiz.


```python
model_5_history = model_5.fit(train_sentences,
                              train_labels,
                              epochs=5,
                              validation_data=(val_sentences, val_labels),
                              callbacks=[create_tensorboard_callback(SAVE_DIR, 
                                                                     "Conv1D")])
```

    Saving TensorBoard log files to: model_logs/Conv1D/20210822-071110
    Epoch 1/5
    215/215 [==============================] - 4s 10ms/step - loss: 0.1339 - accuracy: 0.9584 - val_loss: 0.8689 - val_accuracy: 0.7664
    Epoch 2/5
    215/215 [==============================] - 2s 7ms/step - loss: 0.0763 - accuracy: 0.9727 - val_loss: 0.9643 - val_accuracy: 0.7651
    Epoch 3/5
    215/215 [==============================] - 2s 7ms/step - loss: 0.0600 - accuracy: 0.9761 - val_loss: 1.0885 - val_accuracy: 0.7546
    Epoch 4/5
    215/215 [==============================] - 2s 7ms/step - loss: 0.0542 - accuracy: 0.9783 - val_loss: 1.1663 - val_accuracy: 0.7559
    Epoch 5/5
    215/215 [==============================] - 2s 7ms/step - loss: 0.0512 - accuracy: 0.9790 - val_loss: 1.2285 - val_accuracy: 0.7572
    

GÃ¼zel! GPU hÄ±zlandÄ±rma sayesinde 1D evriÅŸimli modelimiz gÃ¼zel ve hÄ±zlÄ± bir ÅŸekilde eÄŸitiyor. Onunla bazÄ± tahminler yapalÄ±m ve eskisi gibi deÄŸerlendirelim.


```python
model_5_pred_probs = model_5.predict(val_sentences)
model_5_pred_probs[:10]
```




    array([[1.3275287e-01],
           [3.1561503e-01],
           [9.9978405e-01],
           [5.4979675e-02],
           [2.5409597e-07],
           [9.8810232e-01],
           [9.4828182e-01],
           [9.9995220e-01],
           [9.9999881e-01],
           [9.4418395e-01]], dtype=float32)




```python
model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))
model_5_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>




```python
model_5_results = calculate_results(y_true=val_labels, 
                                    y_pred=model_5_preds)
model_5_results
```




    {'accuracy': 75.7217847769029,
     'f1': 0.7549472494674683,
     'precision': 0.7585989210360964,
     'recall': 0.7572178477690289}




```python
compare_baseline_to_new_results(baseline_results, model_5_results)
```

    Baseline accuracy: 79.27, New accuracy: 75.72, Difference: -3.54
    Baseline precision: 0.81, New precision: 0.76, Difference: -0.05
    Baseline recall: 0.79, New recall: 0.76, Difference: -0.04
    Baseline f1: 0.79, New f1: 0.75, Difference: -0.03
    

# Ã–nceden EÄŸitilmiÅŸ Embedleri Kullanma (NLP iÃ§in transfer Ã¶ÄŸrenimi)

OluÅŸturduÄŸumuz ve eÄŸittiÄŸimiz Ã¶nceki tÃ¼m derin Ã¶ÄŸrenme modelleri iÃ§in her seferinde sÄ±fÄ±rdan kendi yerleÅŸtirmelerimizi oluÅŸturduk ve kullandÄ±k.

Ancak yaygÄ±n bir uygulama, **aktarÄ±m Ã¶ÄŸrenimi** aracÄ±lÄ±ÄŸÄ±yla Ã¶nceden eÄŸitilmiÅŸ embedlerder yararlanmaktÄ±r. Bir sonraki modelimiz iÃ§in, kendi gÃ¶mme katmanÄ±mÄ±zÄ± kullanmak yerine, onu Ã¶nceden eÄŸitilmiÅŸ bir gÃ¶mme katmanÄ±yla deÄŸiÅŸtireceÄŸiz.

Daha spesifik olarak, [TensorFlow Hub](https://tfhub.dev/google) adresinden [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) kullanacaÄŸÄ±z. (universal-sentence-encoder, Ã§eÅŸitli gÃ¶revler iÃ§in Ã§ok sayÄ±da Ã¶nceden eÄŸitilmiÅŸ model kaynaÄŸÄ± iÃ§eren harika bir model).

> ğŸ”‘ **Not:** TensorFlow Hub'da Ã¶nceden eÄŸitilmiÅŸ birÃ§ok farklÄ± metin gÃ¶mme seÃ§eneÄŸi vardÄ±r, ancak bazÄ±larÄ± diÄŸerlerinden farklÄ± seviyelerde metin Ã¶n iÅŸleme gerektirir. BirkaÃ§Ä±nÄ± denemek ve kullanÄ±m durumunuza en uygun olanÄ± gÃ¶rmek en iyisidir.

## Model 6: TensorFlow Hub Ã–nceden EÄŸitilmiÅŸ CÃ¼mle KodlayÄ±cÄ±

OluÅŸturduÄŸumuz gÃ¶mme katmanÄ± ile Evrensel CÃ¼mle KodlayÄ±cÄ± arasÄ±ndaki temel fark, tahmin edebileceÄŸiniz gibi, Evrensel CÃ¼mle KodlayÄ±cÄ±'nÄ±n sÃ¶zcÃ¼k dÃ¼zeyinde bir gÃ¶mme oluÅŸturmak yerine, tam bir cÃ¼mle dÃ¼zeyinde gÃ¶mme oluÅŸturmasÄ±dÄ±r.

GÃ¶mme katmanÄ±mÄ±z ayrÄ±ca her kelime iÃ§in 128 boyutlu bir vektÃ¶r Ã¼retirken, Evrensel CÃ¼mle KodlayÄ±cÄ± her cÃ¼mle iÃ§in 512 boyutlu bir vektÃ¶r verir.

> ğŸ”‘ **Not:** Bir **encoder**, metin gibi ham verileri sayÄ±sal bir gÃ¶sterime (Ã¶zellik vektÃ¶rÃ¼) dÃ¶nÃ¼ÅŸtÃ¼ren bir modelin adÄ±dÄ±r, bir **decoder** sayÄ±sal gÃ¶sterimi istenen bir Ã§Ä±ktÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r .

Her zamanki gibi, bu en iyi bir Ã¶rnekle gÃ¶sterilir. Universal (evrensel) CÃ¼mle KodlayÄ±cÄ± modelini yÃ¼kleyelim ve birkaÃ§ cÃ¼mle Ã¼zerinde test edelim.


```python
import tensorflow_hub as hub

# Evrensel CÃ¼mle KodlayÄ±cÄ±yÄ± yÃ¼kle
embed = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4") 
embed_samples = embed([sample_sentence,
                       "When you call the universal sentence encoder \
                       on a sentence, it turns it into numbers."])

print(embed_samples[0][:50])
```

    tf.Tensor(
    [-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759
      0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523
      0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928
      0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069
     -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095
     -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439
      0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362
     -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528
     -0.03758105  0.0332773 ], shape=(50,), dtype=float32)
    


```python
# Her cÃ¼mle 512 boyutlu bir vektÃ¶re kodlanmÄ±ÅŸtÄ±r
embed_samples[0].shape
```




    TensorShape([512])



CÃ¼mlelerimizi Evrensel CÃ¼mle KodlayÄ±cÄ±ya (USE) geÃ§irmek, onlarÄ± dizelerden 512 boyutlu vektÃ¶rlere kodlar; bu bizim iÃ§in hiÃ§bir anlam ifade etmez, ancak umarÄ±m makine Ã¶ÄŸrenimi modellerimiz iÃ§in bir anlam ifade eder.

Modellerden bahsetmiÅŸken, gÃ¶mme katmanÄ±mÄ±z olarak USE ile bir tane oluÅŸturalÄ±m.

[`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) sÄ±nÄ±fÄ±nÄ± kullanarak TensorFlow Hub USE modÃ¼lÃ¼nÃ¼ Keras katmanÄ±na dÃ¶nÃ¼ÅŸtÃ¼rebiliriz.

> ğŸ”‘ **Not:** TensorFlow Hub'Ä± KULLAN modÃ¼lÃ¼nÃ¼n boyutu nedeniyle, indirilmesi biraz zaman alabilir. Yine de indirildikten sonra Ã¶nbelleÄŸe alÄ±nacak ve kullanÄ±ma hazÄ±r olacaktÄ±r. Ve birÃ§ok TensorFlow Hub modÃ¼lÃ¼nde olduÄŸu gibi, USE'nin daha az yer kaplayan ancak performanstan biraz Ã¶dÃ¼n veren bir ["lite" sÃ¼rÃ¼mÃ¼](https://tfhub.dev/google/universal-sentence-encoder-lite/2) vardÄ±r. ve daha fazla Ã¶n iÅŸleme adÄ±mÄ± gerektirir. Ancak, mevcut iÅŸlem gÃ¼cÃ¼nÃ¼ze baÄŸlÄ± olarak, uygulama kullanÄ±m durumunuz iÃ§in lite sÃ¼rÃ¼mÃ¼ daha iyi olabilir.


```python
# Bu kodlama katmanÄ±nÄ± text_vectorizer ve gÃ¶mme katmanÄ±mÄ±z yerine kullanabiliriz
sentence_encoder_layer = hub.KerasLayer(
    "https://tfhub.dev/google/universal-sentence-encoder/4",
    input_shape=[], # modelimize gelen girdilerin ÅŸekli
    dtype=tf.string, # USE katmanÄ±na gelen veri tipi girdiler
    trainable=False, # Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± koru
    name="USE") 
```

GÃ¼zel! Åimdi Keras katmanÄ± olarak USE'ye sahibiz, onu Keras SÄ±ralÄ± modelinde kullanabiliriz.


```python
model_6 = tf.keras.Sequential([
  sentence_encoder_layer,
  layers.Dense(64, activation="relu"),
  layers.Dense(1, activation="sigmoid")
], name="model_6_USE")

# modeli derleme
model_6.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_6.summary()
```

    Model: "model_6_USE"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    USE (KerasLayer)             (None, 512)               256797824 
    _________________________________________________________________
    dense_5 (Dense)              (None, 64)                32832     
    _________________________________________________________________
    dense_6 (Dense)              (None, 1)                 65        
    =================================================================
    Total params: 256,830,721
    Trainable params: 32,897
    Non-trainable params: 256,797,824
    _________________________________________________________________
    

USE katmanÄ±ndaki parametrelerin sayÄ±sÄ±na dikkat edin, bunlar Ã§eÅŸitli metin kaynaklarÄ±nda (Wikipedia, web haberleri, web soru-cevap forumlarÄ± vb.) Ã¶ÄŸrendiÄŸi Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klardÄ±r.

EÄŸitilebilir parametreler yalnÄ±zca Ã§Ä±ktÄ± katmanlarÄ±mÄ±zdadÄ±r, baÅŸka bir deyiÅŸle, USE aÄŸÄ±rlÄ±klarÄ±nÄ± donmuÅŸ halde tutuyor ve onu bir Ã¶zellik Ã§Ä±karÄ±cÄ± olarak kullanÄ±yoruz. "`hub.KerasLayer`" Ã¶rneÄŸini oluÅŸtururken "`trainable=True`" ayarÄ±nÄ± yaparak bu aÄŸÄ±rlÄ±klara ince ayar yapabiliriz.

Åimdi hazÄ±r bir Ã¶zellik Ã§Ä±karÄ±cÄ± modelimiz var, hadi onu eÄŸitelim ve `create_tensorboard_callback()` fonksiyonumuzu kullanarak sonuÃ§larÄ±nÄ± TensorBoard'a izleyelim.


```python
model_6_history = model_6.fit(
    train_sentences,
    train_labels,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(SAVE_DIR, "tf_hub_sentence_encoder")])
```

    Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210822-071154
    Epoch 1/5
    215/215 [==============================] - 10s 31ms/step - loss: 0.5060 - accuracy: 0.7787 - val_loss: 0.4518 - val_accuracy: 0.8005
    Epoch 2/5
    215/215 [==============================] - 4s 18ms/step - loss: 0.4145 - accuracy: 0.8183 - val_loss: 0.4373 - val_accuracy: 0.8110
    Epoch 3/5
    215/215 [==============================] - 4s 18ms/step - loss: 0.4018 - accuracy: 0.8206 - val_loss: 0.4317 - val_accuracy: 0.8150
    Epoch 4/5
    215/215 [==============================] - 4s 17ms/step - loss: 0.3938 - accuracy: 0.8269 - val_loss: 0.4276 - val_accuracy: 0.8176
    Epoch 5/5
    215/215 [==============================] - 4s 17ms/step - loss: 0.3888 - accuracy: 0.8278 - val_loss: 0.4275 - val_accuracy: 0.8202
    

DiÄŸer modellerimizde yaptÄ±ÄŸÄ±mÄ±z gibi onunla da bazÄ± tahminler yapalÄ±m ve onlarÄ± deÄŸerlendirelim.


```python
# USE TF Hub modeli ile tahminler yapÄ±n
model_6_pred_probs = model_6.predict(val_sentences)
model_6_pred_probs[:10]
```




    array([[0.16858765],
           [0.78706455],
           [0.9866457 ],
           [0.18491879],
           [0.74524015],
           [0.7418657 ],
           [0.9791367 ],
           [0.97791415],
           [0.94224715],
           [0.0893833 ]], dtype=float32)




```python
# Tahmin olasÄ±lÄ±klarÄ±nÄ± etiketlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))
model_6_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>




```python
# Model 6 performans metriklerini hesaplayÄ±n
model_6_results = calculate_results(val_labels, model_6_preds)
model_6_results
```




    {'accuracy': 82.02099737532808,
     'f1': 0.8187283797448478,
     'precision': 0.8226273514784717,
     'recall': 0.8202099737532809}




```python
# KarÅŸÄ±laÅŸtÄ±rma
compare_baseline_to_new_results(baseline_results, model_6_results)
```

    Baseline accuracy: 79.27, New accuracy: 82.02, Difference: 2.76
    Baseline precision: 0.81, New precision: 0.82, Difference: 0.01
    Baseline recall: 0.79, New recall: 0.82, Difference: 0.03
    Baseline f1: 0.79, New f1: 0.82, Difference: 0.03
    

## Model 7

USE iÃ§indeki Ã¶nceden eÄŸitilmiÅŸ yerleÅŸtirmeler gibi transfer Ã¶ÄŸrenme yÃ¶ntemlerini kullanmanÄ±n faydalarÄ±ndan biri, az miktarda veri Ã¼zerinde harika sonuÃ§lar elde etme yeteneÄŸidir (USE makalesi Ã¶zette bundan bahseder).

Bunu test etmek iÃ§in, eÄŸitim verilerinin kÃ¼Ã§Ã¼k bir alt kÃ¼mesini (%10) oluÅŸturacaÄŸÄ±z, bir model eÄŸiteceÄŸiz ve onu deÄŸerlendireceÄŸiz.


```python
train_10_percent = train_df_shuffled[["text", "target"]].sample(frac=0.1, random_state=42)
train_sentences_10_percent = train_10_percent["text"].to_list()
train_labels_10_percent = train_10_percent["target"].to_list()
len(train_sentences_10_percent), len(train_labels_10_percent)

train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),
                                                                                                                            train_labels,
                                                                                                                            test_size=0.1,
                                                                                                                            random_state=42)
print(f"Total training examples: {len(train_sentences)}")
print(f"Length of 10% training examples: {len(train_sentences_10_percent)}")
```

    Total training examples: 6851
    Length of 10% training examples: 686
    

EÄŸitim Ã¶rneklerinin rastgele bir alt kÃ¼mesini seÃ§tiÄŸimiz iÃ§in, sÄ±nÄ±flarÄ±n kabaca dengelenmesi gerekir (tam eÄŸitim veri kÃ¼mesinde olduÄŸu gibi).


```python
# Veri alt kÃ¼memizdeki hedef sayÄ±sÄ±nÄ± kontrol edin
# (bu, orijinal train_labels iÃ§indeki etiketlerin daÄŸÄ±lÄ±mÄ±na yakÄ±n olmalÄ±dÄ±r)
pd.Series(train_labels_10_percent).value_counts()
```




    0    415
    1    271
    dtype: int64



Modelimizin tam eÄŸitim kÃ¼mesinden Ã¶ÄŸrenme yeteneÄŸi ile %10 alt kÃ¼meden Ã¶ÄŸrenme yeteneÄŸi arasÄ±nda uygun bir karÅŸÄ±laÅŸtÄ±rma yaptÄ±ÄŸÄ±mÄ±zdan emin olmak iÃ§in, [`tf.keras.models.clone_model()` kullanarak USE modelimizi ("model_6") kullanarak klonlayacaÄŸÄ±z.`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model)

Bunu yapmak aynÄ± mimariyi yaratacak ancak klon hedefinin Ã¶ÄŸrenilen aÄŸÄ±rlÄ±klarÄ±nÄ± sÄ±fÄ±rlayacaktÄ±r (USE'den gelen Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar kalacak, ancak diÄŸerleri sÄ±fÄ±rlanacaktÄ±r).


```python
model_7 = tf.keras.models.clone_model(model_6)

model_7.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

model_7.summary()
```

    Model: "model_6_USE"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    USE (KerasLayer)             (None, 512)               256797824 
    _________________________________________________________________
    dense_5 (Dense)              (None, 64)                32832     
    _________________________________________________________________
    dense_6 (Dense)              (None, 1)                 65        
    =================================================================
    Total params: 256,830,721
    Trainable params: 32,897
    Non-trainable params: 256,797,824
    _________________________________________________________________
    

`model_7` dÃ¼zeninin `model_6` ile aynÄ± olduÄŸuna dikkat edin. Åimdi yeni oluÅŸturulan modeli %10 eÄŸitim verisi alt kÃ¼memizde eÄŸitelim.


```python
model_7_history = model_7.fit(
    x=train_sentences_10_percent,
    y=train_labels_10_percent,
    epochs=5,
    validation_data=(val_sentences, val_labels),
    callbacks=[create_tensorboard_callback(SAVE_DIR, "10_percent_tf_hub_sentence_encoder")])
```

    Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20210822-071224
    Epoch 1/5
    22/22 [==============================] - 6s 154ms/step - loss: 0.6651 - accuracy: 0.6851 - val_loss: 0.6443 - val_accuracy: 0.6929
    Epoch 2/5
    22/22 [==============================] - 1s 46ms/step - loss: 0.5920 - accuracy: 0.7959 - val_loss: 0.5918 - val_accuracy: 0.7310
    Epoch 3/5
    22/22 [==============================] - 1s 35ms/step - loss: 0.5166 - accuracy: 0.8163 - val_loss: 0.5415 - val_accuracy: 0.7638
    Epoch 4/5
    22/22 [==============================] - 1s 33ms/step - loss: 0.4554 - accuracy: 0.8382 - val_loss: 0.5058 - val_accuracy: 0.7795
    Epoch 5/5
    22/22 [==============================] - 1s 32ms/step - loss: 0.4120 - accuracy: 0.8382 - val_loss: 0.4925 - val_accuracy: 0.7730
    

Daha az miktarda eÄŸitim verisi nedeniyle eÄŸitim, eskisinden daha hÄ±zlÄ± bitti. EÄŸitim verilerinin %10'unu Ã¶ÄŸrendikten sonra modelimizin performansÄ±nÄ± deÄŸerlendirelim.


```python
model_7_pred_probs = model_7.predict(val_sentences)
model_7_pred_probs[:10]
```




    array([[0.26725993],
           [0.7663658 ],
           [0.8697842 ],
           [0.30411467],
           [0.5334834 ],
           [0.82516   ],
           [0.8102658 ],
           [0.84461933],
           [0.8153697 ],
           [0.10006839]], dtype=float32)




```python
model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))
model_7_preds[:10]
```




    <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>




```python
model_7_results = calculate_results(val_labels, model_7_preds)
model_7_results
```




    {'accuracy': 77.29658792650919,
     'f1': 0.7698502254147366,
     'precision': 0.7770640736660165,
     'recall': 0.7729658792650919}




```python
compare_baseline_to_new_results(baseline_results, model_7_results)
```

    Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97
    Baseline precision: 0.81, New precision: 0.78, Difference: -0.03
    Baseline recall: 0.79, New recall: 0.77, Difference: -0.02
    Baseline f1: 0.79, New f1: 0.77, Difference: -0.02
    

# Modellerimizin Her Birinin PerformansÄ±nÄ± KarÅŸÄ±laÅŸtÄ±rma

Åimdi modelimizin sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rma zamanÄ±. Ancak bundan hemen Ã¶nce, bu tÃ¼r bir uygulamanÄ±n standart bir derin Ã¶ÄŸrenme iÅŸ akÄ±ÅŸÄ± olduÄŸunu belirtmekte fayda var. Ã‡eÅŸitli farklÄ± modelleri eÄŸitin, ardÄ±ndan hangisinin en iyi performansÄ± gÃ¶sterdiÄŸini gÃ¶rmek iÃ§in bunlarÄ± karÅŸÄ±laÅŸtÄ±rÄ±n ve gerekirse onu eÄŸitmeye devam edin.

UnutulmamasÄ± gereken Ã¶nemli nokta, tÃ¼m modelleme deneylerimiz iÃ§in aynÄ± eÄŸitim verilerini kullandÄ±ÄŸÄ±mÄ±zdÄ±r (eÄŸitim verilerinin %10'unu kullandÄ±ÄŸÄ±mÄ±z 'model_7' hariÃ§).

Modelimizin performanslarÄ±nÄ± gÃ¶rselleÅŸtirmek iÃ§in, result sÃ¶zlÃ¼klerimiz olan bir pandas DataFrame oluÅŸturalÄ±m ve sonra onu Ã§izelim.


```python
all_model_results = pd.DataFrame({"baseline": baseline_results,
                                  "simple_dense": model_1_results,
                                  "lstm": model_2_results,
                                  "gru": model_3_results,
                                  "bidirectional": model_4_results,
                                  "conv1d": model_5_results,
                                  "tf_hub_sentence_encoder": model_6_results,
                                  "tf_hub_10_percent_data": model_7_results})
all_model_results = all_model_results.transpose()
all_model_results
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>79.265092</td>
      <td>0.811139</td>
      <td>0.792651</td>
      <td>0.786219</td>
    </tr>
    <tr>
      <th>simple_dense</th>
      <td>78.477690</td>
      <td>0.789165</td>
      <td>0.784777</td>
      <td>0.781896</td>
    </tr>
    <tr>
      <th>lstm</th>
      <td>78.083990</td>
      <td>0.781487</td>
      <td>0.780840</td>
      <td>0.779482</td>
    </tr>
    <tr>
      <th>gru</th>
      <td>77.165354</td>
      <td>0.771295</td>
      <td>0.771654</td>
      <td>0.771282</td>
    </tr>
    <tr>
      <th>bidirectional</th>
      <td>76.115486</td>
      <td>0.761888</td>
      <td>0.761155</td>
      <td>0.759376</td>
    </tr>
    <tr>
      <th>conv1d</th>
      <td>75.721785</td>
      <td>0.758599</td>
      <td>0.757218</td>
      <td>0.754947</td>
    </tr>
    <tr>
      <th>tf_hub_sentence_encoder</th>
      <td>82.020997</td>
      <td>0.822627</td>
      <td>0.820210</td>
      <td>0.818728</td>
    </tr>
    <tr>
      <th>tf_hub_10_percent_data</th>
      <td>77.296588</td>
      <td>0.777064</td>
      <td>0.772966</td>
      <td>0.769850</td>
    </tr>
  </tbody>
</table>
</div>




```python
# DoÄŸruluÄŸu diÄŸer metriklerle aynÄ± Ã¶lÃ§eÄŸe indirin
all_model_results["accuracy"] = all_model_results["accuracy"]/100
all_model_results.plot(kind="bar", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));
```


    
![png](8-NLP%27ye%20Giris_files/8-NLP%27ye%20Giris_169_0.png)
    


Ã–nceden eÄŸitilmiÅŸ USE TensorFlow Hub modellerimiz en iyi performansa sahip gibi gÃ¶rÃ¼nÃ¼yor, eÄŸitim verilerinin yalnÄ±zca %10'una sahip olan model bile diÄŸer modellerden daha iyi performans gÃ¶steriyor. Bu, transfer Ã¶ÄŸrenmenin gÃ¼cÃ¼nÃ¼ gÃ¶sterir.

Detaylara inip her modelin F1 puanlarÄ±nÄ± almaya ne dersiniz?


```python
all_model_results.sort_values("f1", ascending=False)["f1"].plot(kind="bar", figsize=(10, 7));
```


    
![png](8-NLP%27ye%20Giris_files/8-NLP%27ye%20Giris_171_0.png)
    


Tek bir Ã¶lÃ§Ã¼mde detaya indiÄŸimizde, USE TensorFlow Hub modellerimizin diÄŸer tÃ¼m modellerden daha iyi performans gÃ¶sterdiÄŸini gÃ¶rÃ¼yoruz. Ä°lginÃ§ bir ÅŸekilde, temelin F1 puanÄ±, daha derin modellerin geri kalanÄ±ndan Ã§ok uzakta deÄŸil.

## Modellerimizi BirleÅŸtirmek

BirÃ§ok Ã¼retim sistemi, bir tahmin yapmak iÃ§in bir **ensemble** (birden Ã§ok farklÄ± modelin bir araya getirilmesi) modellerini kullanÄ±r.

Model istiflemenin ardÄ±ndaki fikir, birbiriyle iliÅŸkisiz birkaÃ§ modelin bir tahmin Ã¼zerinde anlaÅŸmaya varmasÄ± durumunda, tahminin tekil bir model tarafÄ±ndan yapÄ±lan bir tahminden daha saÄŸlam olmasÄ± gerektiÄŸidir.

YukarÄ±daki cÃ¼mledeki anahtar kelime **uncorrelated**, bu da farklÄ± model tÃ¼rleri demenin baÅŸka bir yoludur. Ã–rneÄŸin, bizim durumumuzda taban Ã§izgimizi, Ã§ift yÃ¶nlÃ¼ modelimizi ve TensorFlow Hub USE modelimizi birleÅŸtirebiliriz.

Bu modellerin hepsi aynÄ± veriler Ã¼zerinde eÄŸitilmiÅŸ olsa da, hepsinin farklÄ± bir kalÄ±p bulma yolu vardÄ±r.

ÃœÃ§ LSTM modeli gibi benzer ÅŸekilde eÄŸitilmiÅŸ Ã¼Ã§ model kullanacak olsaydÄ±k, Ã§Ä±ktÄ± tahminleri muhtemelen Ã§ok benzer olacaktÄ±r.

Bunu arkadaÅŸlarÄ±nÄ±zla nerede yemek yiyeceÄŸinize karar vermeye Ã§alÄ±ÅŸmak olarak dÃ¼ÅŸÃ¼nÃ¼n. Hepinizin zevkleri benzerse, muhtemelen hepiniz aynÄ± restoranÄ± seÃ§eceksiniz. Ama hepinizin farklÄ± zevkleri varsa ve yine de aynÄ± restoranÄ± seÃ§erseniz, restoran iyi olmalÄ±.

Bir sÄ±nÄ±flandÄ±rma problemi ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in modellerimizi birleÅŸtirmenin birkaÃ§ yolu vardÄ±r:
1. **Ortalama** - Her Ã¶rnek iÃ§in her modelin Ã§Ä±ktÄ± tahmin olasÄ±lÄ±klarÄ±nÄ± alÄ±n, birleÅŸtirin ve ardÄ±ndan ortalamasÄ±nÄ± alÄ±n.
2. **Ã‡oÄŸunluk oyu (mod)** - Modellerinizin her biri ile tÃ¼m Ã¶rneklerde sÄ±nÄ±f tahminleri yapÄ±n, tahmin edilen sÄ±nÄ±f Ã§oÄŸunlukta olandÄ±r. Ã–rneÄŸin, Ã¼Ã§ farklÄ± model sÄ±rasÄ±yla `[1, 0, 1]` deÄŸerini tahmin ederse, Ã§oÄŸunluk sÄ±nÄ±fÄ± `1` olur, bu nedenle bu tahmin edilen etiket olacaktÄ±r.
3. **Model yÄ±ÄŸÄ±nlama** - SeÃ§tiÄŸiniz modellerin her birinin Ã§Ä±ktÄ±larÄ±nÄ± alÄ±n ve bunlarÄ± baÅŸka bir modele girdi olarak kullanÄ±n.

> ğŸ“– **Kaynak:** Model istifleme/birleÅŸtirme iÃ§in yukarÄ±daki yÃ¶ntemler, Andriy Burkov tarafÄ±ndan [Machine Learning Engineering Book](http://www.mlebook.com/wiki/doku.php) BÃ¶lÃ¼m 6'dan uyarlanmÄ±ÅŸtÄ±r. Makine Ã¶ÄŸrenimi mÃ¼hendisliÄŸi alanÄ±na girmek, yalnÄ±zca modeller oluÅŸturmak deÄŸil, aynÄ± zamanda Ã¼retim Ã¶lÃ§eÄŸinde makine Ã¶ÄŸrenimi sistemleri kurmak istiyorsanÄ±z, tamamÄ±nÄ± okumanÄ±zÄ± ÅŸiddetle tavsiye ederim.

Yine, model istifleme kavramÄ± en iyi eylemde gÃ¶rÃ¼lÃ¼r.

Temel modelimizi (`model_0`), LSTM modelimizi (`model_2`) ve tam eÄŸitim verisi (`model_6`) Ã¼zerinde eÄŸitilmiÅŸ USE modelimizi, her birinin birleÅŸik tahmin olasÄ±lÄ±klarÄ±nÄ±n ortalamasÄ±nÄ± alarak birleÅŸtireceÄŸiz.


```python
# temel modelden tahmin olasÄ±lÄ±klarÄ±nÄ± alÄ±n
baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1)
combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)
# tahmin sÄ±nÄ±flarÄ± iÃ§in olasÄ±lÄ±klarÄ±nÄ± ortalamasÄ±nÄ± alÄ±n ve yuvarlayÄ±n
combined_preds = tf.round(combined_pred_probs/3)
combined_preds[:20]
```




    <tf.Tensor: shape=(20,), dtype=float32, numpy=
    array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,
           0., 0., 1.], dtype=float32)>



OlaÄŸanÃ¼stÃ¼! FarklÄ± sÄ±nÄ±flardan oluÅŸan birleÅŸtirilmiÅŸ bir tahminler dizimiz var, bunlarÄ± gerÃ§ek etiketlere gÃ¶re deÄŸerlendirelim ve yÄ±ÄŸÄ±lmÄ±ÅŸ modelimizin sonuÃ§larÄ±nÄ± `all_model_results` DataFrame'imize ekleyelim.


```python
ensemble_results = calculate_results(val_labels, combined_preds)
ensemble_results
```




    {'accuracy': 79.92125984251969,
     'f1': 0.7991404257926901,
     'precision': 0.7990931458872615,
     'recall': 0.7992125984251969}




```python
# BirleÅŸtirilmiÅŸ modelimizin sonuÃ§larÄ±nÄ± DataFrame sonuÃ§larÄ±na ekleyin
all_model_results.loc["ensemble_results"] = ensemble_results
# DoÄŸruluÄŸu, sonuÃ§larÄ±n geri kalanÄ±yla aynÄ± Ã¶lÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
all_model_results.loc["ensemble_results"]["accuracy"] = all_model_results.loc["ensemble_results"]["accuracy"]/100

all_model_results
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.792651</td>
      <td>0.811139</td>
      <td>0.792651</td>
      <td>0.786219</td>
    </tr>
    <tr>
      <th>simple_dense</th>
      <td>0.784777</td>
      <td>0.789165</td>
      <td>0.784777</td>
      <td>0.781896</td>
    </tr>
    <tr>
      <th>lstm</th>
      <td>0.780840</td>
      <td>0.781487</td>
      <td>0.780840</td>
      <td>0.779482</td>
    </tr>
    <tr>
      <th>gru</th>
      <td>0.771654</td>
      <td>0.771295</td>
      <td>0.771654</td>
      <td>0.771282</td>
    </tr>
    <tr>
      <th>bidirectional</th>
      <td>0.761155</td>
      <td>0.761888</td>
      <td>0.761155</td>
      <td>0.759376</td>
    </tr>
    <tr>
      <th>conv1d</th>
      <td>0.757218</td>
      <td>0.758599</td>
      <td>0.757218</td>
      <td>0.754947</td>
    </tr>
    <tr>
      <th>tf_hub_sentence_encoder</th>
      <td>0.820210</td>
      <td>0.822627</td>
      <td>0.820210</td>
      <td>0.818728</td>
    </tr>
    <tr>
      <th>tf_hub_10_percent_data</th>
      <td>0.772966</td>
      <td>0.777064</td>
      <td>0.772966</td>
      <td>0.769850</td>
    </tr>
    <tr>
      <th>ensemble_results</th>
      <td>0.799213</td>
      <td>0.799093</td>
      <td>0.799213</td>
      <td>0.799140</td>
    </tr>
  </tbody>
</table>
</div>



YÄ±ÄŸÄ±lmÄ±ÅŸ model diÄŸer modellere karÅŸÄ± nasÄ±l bir sonuÃ§ verdi?

> ğŸ”‘ **Not:** Modelimizin sonuÃ§larÄ±nÄ±n Ã§oÄŸu benzer gÃ¶rÃ¼nÃ¼yor. Bu, verilerimizden Ã¶ÄŸrenilebileceklerin bazÄ± sÄ±nÄ±rlamalarÄ± olduÄŸu anlamÄ±na gelebilir. Modelleme denemelerinizin Ã§oÄŸu benzer sonuÃ§lar verdiÄŸinde, verilerinizi tekrar gÃ¶zden geÃ§irmek iyi bir fikirdir.

## EÄŸitilmiÅŸ Bir Modeli Kaydetme ve YÃ¼kleme

EÄŸitim sÃ¼resi Ã§ok uzun sÃ¼rmese de, yeniden eÄŸitmek zorunda kalmamak iÃ§in eÄŸitilmiÅŸ modellerinizi kaydetmek iyi bir uygulamadÄ±r.

Modellerinizi kaydetmek, aynÄ± zamanda, bir web uygulamasÄ±nda olduÄŸu gibi, dizÃ¼stÃ¼ bilgisayarÄ±nÄ±zÄ±n dÄ±ÅŸÄ±nda baÅŸka bir yerde kullanmak Ã¼zere dÄ±ÅŸa aktarmanÄ±za da olanak tanÄ±r.

[TensorFlow'da bir modeli kaydetmenin] iki ana yolu vardÄ±r(https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):
1. `HDF5` biÃ§imi.
2. `KayÄ±tlÄ±Model` biÃ§imi (varsayÄ±lan).

Ä°kisine de bir gÃ¶z atalÄ±m.


```python
model_6.save("model_6.h5")
```

Bir modeli `HDF5` olarak kaydederseniz, tekrar yÃ¼klerken TensorFlow'a kullandÄ±ÄŸÄ±nÄ±z Ã¶zel nesneler hakkÄ±nda bilgi vermeniz gerekir.


```python
# Modeli Ã¶zel Hub KatmanÄ± ile yÃ¼kleyin (HDF5 formatÄ± iÃ§in gereklidir)
loaded_model_6 = tf.keras.models.load_model(
    "model_6.h5", 
    custom_objects={"KerasLayer": hub.KerasLayer})
```


```python
# YÃ¼klenen modelimiz nasÄ±l performans gÃ¶steriyor?
loaded_model_6.evaluate(val_sentences, val_labels)
```

    24/24 [==============================] - 1s 16ms/step - loss: 0.4275 - accuracy: 0.8202
    




    [0.4274521470069885, 0.8202099800109863]



Hedef modelimizde `save()` yÃ¶ntemini Ã§aÄŸÄ±rmak ve ona bir dosya yolu iletmek, modelimizi `SavedModel` formatÄ±nda kaydetmemizi saÄŸlar.


```python
model_6.save("model_6_SavedModel_format")
```

    WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.
    

    INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets
    

    INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets
    

SavedModel biÃ§imini (varsayÄ±lan) kullanÄ±rsanÄ±z, `tensorflow.keras.models.load_model()` iÅŸlevini kullanarak Ã¶zel nesneler belirtmeden modelinizi yeniden yÃ¼kleyebilirsiniz.


```python
# TF Hub CÃ¼mle KodlayÄ±cÄ±yÄ± YÃ¼kle SavedModel
loaded_model_6_SavedModel = tf.keras.models.load_model("model_6_SavedModel_format")
```


```python
# YÃ¼klenen SavedModel biÃ§imini deÄŸerlendirin
loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)
```

    24/24 [==============================] - 1s 15ms/step - loss: 0.4275 - accuracy: 0.8202
    




    [0.4274521470069885, 0.8202099800109863]



GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, modelimizi her iki formatta da kaydedip yÃ¼klemek aynÄ± performansÄ± veriyor.

> ğŸ¤” **Soru:** "loadModel" biÃ§imini mi yoksa "HDF5" biÃ§imini mi kullanmalÄ±sÄ±nÄ±z?

Ã‡oÄŸu kullanÄ±m durumu iÃ§in `SavedModel` formatÄ± yeterli olacaktÄ±r. Ancak bu, TensorFlow'a Ã¶zel bir standarttÄ±r. Daha genel amaÃ§lÄ± bir veri standardÄ±na ihtiyacÄ±nÄ±z varsa, "HDF5" daha iyi olabilir.

## En YanlÄ±ÅŸ Ã–rnekleri Bulma

Daha Ã¶nce bahsetmiÅŸtik ki, modelleme deneylerimizin Ã§oÄŸu, farklÄ± tÃ¼rde modeller kullanmamÄ±za raÄŸmen benzer sonuÃ§lar veriyorsa, verilere geri dÃ¶nÃ¼p bunun neden olabileceÄŸini incelemenin iyi bir fikir olduÄŸundan bahsetmiÅŸtik.

Verilerinizi incelemenin en iyi yollarÄ±ndan biri, modelinizin tahminlerini sÄ±ralamak ve onun en yanlÄ±ÅŸ yaptÄ±ÄŸÄ± Ã¶rnekleri bulmaktÄ±r, yani hangi tahminlerin yÃ¼ksek tahmin olasÄ±lÄ±ÄŸÄ± vardÄ± ama yanlÄ±ÅŸ Ã§Ä±ktÄ±.

Bir kez daha, gÃ¶rselleÅŸtirme sizin arkadaÅŸÄ±nÄ±zdÄ±r. GÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin.

Ä°ÅŸleri gÃ¶rsel hale getirmek iÃ§in, en iyi performans gÃ¶steren modelimizin tahmin olasÄ±lÄ±klarÄ±nÄ± ve sÄ±nÄ±flarÄ±nÄ± doÄŸrulama Ã¶rnekleriyle (metin ve kesin doÄŸruluk etiketleri) birlikte alalÄ±m ve bunlarÄ± bir panda DataFrame'de birleÅŸtirelim.

* En iyi modelimiz hala mÃ¼kemmel deÄŸilse, hangi Ã¶rnekler yanlÄ±ÅŸ gidiyor?
* Hangileri en yanlÄ±ÅŸ?
* YanlÄ±ÅŸ olan bazÄ± etiketler var mÄ±? Ã–rneÄŸin. model doÄŸru anlÄ±yor ancak temel doÄŸruluk etiketi bunu yansÄ±tmÄ±yor


```python
val_df = pd.DataFrame({"text": val_sentences,
                       "target": val_labels,
                       "pred": model_6_preds,
                       "pred_prob": tf.squeeze(model_6_pred_probs)})
val_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>pred</th>
      <th>pred_prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.168588</td>
    </tr>
    <tr>
      <th>1</th>
      <td>FedEx no longer to transport bioterror germs i...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.787065</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Gunmen kill four in El Salvador bus attack: Su...</td>
      <td>1</td>
      <td>1.0</td>
      <td>0.986646</td>
    </tr>
    <tr>
      <th>3</th>
      <td>@camilacabello97 Internally and externally scr...</td>
      <td>1</td>
      <td>0.0</td>
      <td>0.184919</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Radiation emergency #preparedness starts with ...</td>
      <td>1</td>
      <td>1.0</td>
      <td>0.745240</td>
    </tr>
  </tbody>
</table>
</div>



Åimdi modelimizin yanlÄ±ÅŸ tahminlerini bulalÄ±m (burada `target != pred`) ve bunlarÄ± tahmin olasÄ±lÄ±klarÄ±na gÃ¶re sÄ±ralayalÄ±m (`pred_prob` sÃ¼tunu).


```python
most_wrong = val_df[val_df["target"] != val_df["pred"]].sort_values("pred_prob", ascending=False)
most_wrong[:10]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>pred</th>
      <th>pred_prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>31</th>
      <td>? High Skies - Burning Buildings ? http://t.co...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.915444</td>
    </tr>
    <tr>
      <th>759</th>
      <td>FedEx will no longer transport bioterror patho...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.892491</td>
    </tr>
    <tr>
      <th>49</th>
      <td>@madonnamking RSPCA site multiple 7 story high...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.862208</td>
    </tr>
    <tr>
      <th>628</th>
      <td>@noah_anyname That's where the concentration c...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.851035</td>
    </tr>
    <tr>
      <th>209</th>
      <td>Ashes 2015: AustraliaÂ‰Ã›Âªs collapse at Trent Br...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.840667</td>
    </tr>
    <tr>
      <th>393</th>
      <td>@SonofLiberty357 all illuminated by the bright...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.826442</td>
    </tr>
    <tr>
      <th>109</th>
      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.825141</td>
    </tr>
    <tr>
      <th>251</th>
      <td>@AshGhebranious civil rights continued in the ...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.813603</td>
    </tr>
    <tr>
      <th>698</th>
      <td>Ã¥ÃˆMGN-AFRICAÃ¥Â¨ pin:263789F4 Ã¥Ãˆ Correction: Ten...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.791938</td>
    </tr>
    <tr>
      <th>1</th>
      <td>FedEx no longer to transport bioterror germs i...</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.787065</td>
    </tr>
  </tbody>
</table>
</div>



Son olarak, Ã¶rnek metni, doÄŸruluk etiketini, tahmin sÄ±nÄ±fÄ±nÄ± ve tahmin olasÄ±lÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirmek iÃ§in bazÄ± kodlar yazabiliriz. Ã–rneklerimizi tahmin olasÄ±lÄ±ÄŸÄ±na gÃ¶re sÄ±raladÄ±ÄŸÄ±mÄ±z iÃ§in, `en yanlÄ±ÅŸ` DataFrame'imizin baÅŸÄ±ndaki Ã¶rneklere bakmak bize yanlÄ±ÅŸ pozitifler gÃ¶sterecektir.

Bir hatÄ±rlatÄ±cÄ±:
* `0` = GerÃ§ek bir felaket Tweet deÄŸil
* `1` = GerÃ§ek felaket Tweet


```python
for row in most_wrong[:10].itertuples(): 
  _, text, target, pred, prob = row
  print(f"Target: {target}, Pred: {int(pred)}, Prob: {prob}")
  print(f"Text:\n{text}\n")
  print("----\n")
```

    Target: 0, Pred: 1, Prob: 0.9154438972473145
    Text:
    ? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8924906253814697
    Text:
    FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8622081279754639
    Text:
    @madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8510348796844482
    Text:
    @noah_anyname That's where the concentration camps and mass murder come in. 
     
    EVERY. FUCKING. TIME.
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8406673073768616
    Text:
    Ashes 2015: AustraliaÂ‰Ã›Âªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8264415860176086
    Text:
    @SonofLiberty357 all illuminated by the brightly burning buildings all around the town!
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.8251414895057678
    Text:
    [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.813603401184082
    Text:
    @AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.791938304901123
    Text:
    Ã¥ÃˆMGN-AFRICAÃ¥Â¨ pin:263789F4 Ã¥Ãˆ Correction: Tent Collapse Story: Correction: Tent Collapse story Ã¥Ãˆ http://t.co/fDJUYvZMrv @wizkidayo
    
    ----
    
    Target: 0, Pred: 1, Prob: 0.7870645523071289
    Text:
    FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday
    
    ----
    
    


```python
# En yanlÄ±ÅŸ yanlÄ±ÅŸ negatifleri kontrol edin (model 1 tahmin etmeliyken 0 tahmin etti)
for row in most_wrong[-10:].itertuples():
  _, text, target, pred, prob = row
  print(f"Target: {target}, Pred: {int(pred)}, Prob: {prob}")
  print(f"Text:\n{text}\n")
  print("----\n")
```

    Target: 1, Pred: 0, Prob: 0.05815977230668068
    Text:
    'The way you move is like a full on rainstorm and I'm a house of cards'
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.0545167438685894
    Text:
    @DavidVonderhaar At least you were sincere ??
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.05418562889099121
    Text:
    going to redo my nails and watch behind the scenes of desolation of smaug ayyy
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.05028621107339859
    Text:
    You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.04881070926785469
    Text:
    @willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.04162179306149483
    Text:
    I get to smoke my shit in peace
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.03738167881965637
    Text:
    Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.036325037479400635
    Text:
    Reddit Will Now QuarantineÂ‰Ã›_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.035058073699474335
    Text:
    @SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren
    
    ----
    
    Target: 1, Pred: 0, Prob: 0.027997875586152077
    Text:
    Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube
    
    ----
    
    

En yanlÄ±ÅŸ Ã¶rneklerle ilgili ilginÃ§ bir ÅŸey fark ettiniz mi? Etiketler doÄŸru mu? Geri dÃ¶nÃ¼p olmayan etiketleri dÃ¼zeltirsek ne olur sizce?

## Test Veri Seti Ãœzerinde Tahminler Yapmak

Pekala, modelimizin doÄŸrulama setinde nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶rdÃ¼k. Peki ya test veri seti?

Test veri seti iÃ§in etiketlerimiz yok, bu yÃ¼zden bazÄ± tahminler yapmamÄ±z ve bunlarÄ± kendimiz incelememiz gerekecek. Test veri setinden rastgele Ã¶rnekler Ã¼zerinde tahminler yapmak iÃ§in bazÄ± kodlar yazalÄ±m ve gÃ¶rselleÅŸtirelim.


```python
test_sentences = test_df["text"].to_list()
test_samples = random.sample(test_sentences, 10)
for test_sample in test_samples:
  pred_prob = tf.squeeze(model_6.predict([test_sample]))
  pred = tf.round(pred_prob)
  print(f"Pred: {int(pred)}, Prob: {pred_prob}")
  print(f"Text:\n{test_sample}\n")
  print("----\n")
```

    Pred: 0, Prob: 0.02110372669994831
    Text:
    @noobde this monkey will be a good character in mkx lol banana fatality
    
    ----
    
    Pred: 0, Prob: 0.08776362240314484
    Text:
    genuine Leather man Bag Messenger fit iPad mini 4 tablet case cross body air jp - Full reaÂ‰Ã›_ http://t.co/Vl26HSrq4E http://t.co/ryl0Y88fKM
    
    ----
    
    Pred: 0, Prob: 0.3871268928050995
    Text:
    It was finally demolished in the spring of 2013 and the property has sat vacant since. The justÂ‰Ã›_: saddlebrooke... http://t.co/bd5B5yffyb
    
    ----
    
    Pred: 1, Prob: 0.7170340418815613
    Text:
    Bioterrorism and Ebola. http://t.co/ORIOVftLK4 RT #STOPIslam #TCOT #CCOT #MakeDCListen #TeaParty
    
    ----
    
    Pred: 1, Prob: 0.9093793630599976
    Text:
    Evacuation order lifted for town of Roosevelt - Washington Times http://t.co/Kue48Nmjxh
    
    ----
    
    Pred: 0, Prob: 0.21379774808883667
    Text:
    It's nice out. Guessing the heat wave is over.
    
    ----
    
    Pred: 0, Prob: 0.13666385412216187
    Text:
    @DukeSkywalker @facialabuse you should do a competetion between @xxxmrbootleg &amp; #ClaudioMeloni (ultimate throat penetrator) to a wreck off.
    
    ----
    
    Pred: 0, Prob: 0.3559725284576416
    Text:
    CommoditiesÃ¥ÃŠAre Crashing Like It's 2008 All Over Again http://t.co/EM1cN7alGk
    
    ----
    
    Pred: 0, Prob: 0.1974869817495346
    Text:
    Serial arsonist gets no bail not jail release http://t.co/rozs6aumsS
    
    ----
    
    Pred: 0, Prob: 0.13319750130176544
    Text:
    Choking Hazard Prompts Recall Of Kraft Cheese Singles http://t.co/98nOsYzu58
    
    ----
    
    

Modelinizin gÃ¶rÃ¼nmeyen veriler Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸine ve ardÄ±ndan gerÃ§ek testte nasÄ±l performans gÃ¶sterebileceÄŸine bir gÃ¶z atmak iÃ§in bu tÃ¼r gÃ¶rselleÅŸtirme kontrollerini mÃ¼mkÃ¼n olduÄŸunca sÄ±k yapmak Ã¶nemlidir.

## HÄ±z/Puan Dengesi

YapacaÄŸÄ±mÄ±z son testlerden biri, en iyi modelimiz ve temel modelimiz arasÄ±ndaki hÄ±z/puan dengelerini bulmaktÄ±r.

Bu neden Ã¶nemli?

Deneme yoluyla bulduÄŸunuz en iyi performans gÃ¶steren modeli seÃ§mek cazip gelse de, bu model aslÄ±nda bir Ã¼retim ortamÄ±nda Ã§alÄ±ÅŸmayabilir.

Bu ÅŸekilde ifade edin, Twitter olduÄŸunuzu ve saatte 1 milyon Tweet aldÄ±ÄŸÄ±nÄ±zÄ± hayal edin (bu uydurma bir sayÄ±dÄ±r, gerÃ§ek sayÄ± Ã§ok daha yÃ¼ksektir). Ve Tweet'leri okumak ve bir felaketle ilgili ayrÄ±ntÄ±larÄ± gerÃ§ek zamanlÄ±ya yakÄ±n bir ÅŸekilde yetkilileri uyarmak iÃ§in bir felaket algÄ±lama sistemi oluÅŸturmaya Ã§alÄ±ÅŸÄ±yorsunuz.

Ä°ÅŸlem gÃ¼cÃ¼ Ã¼cretsiz deÄŸildir, bu nedenle proje iÃ§in tek bir iÅŸlem makinesiyle sÄ±nÄ±rlÄ±sÄ±nÄ±z. Bu makinede, modellerinizden biri %80 doÄŸrulukla saniyede 10.000 tahminde bulunurken, modellerinizden biri (daha bÃ¼yÃ¼k bir model) %85 doÄŸrulukla saniyede 100 tahmin yapar.

Hangi modeli seÃ§ersiniz?

Ä°kinci modelin performans artÄ±ÅŸÄ±, ekstra kapasiteyi kaÃ§Ä±rmaya deÄŸer mi? Tabii ki burada deneyebileceÄŸiniz birÃ§ok seÃ§enek var, ilk modele mÃ¼mkÃ¼n olduÄŸunca Ã§ok Tweet gÃ¶ndermek ve ardÄ±ndan modelin en az emin olduÄŸu ÅŸeyleri ikinci modele gÃ¶ndermek gibi.

Buradaki amaÃ§, deney yoluyla bulduÄŸunuz en iyi modeli gÃ¶stermektir, Ã¼retimde kullandÄ±ÄŸÄ±nÄ±z model olmayabilir.

Bunu daha somut hale getirmek iÃ§in, bir model ve bir dizi Ã¶rnek alacak bir fonksiyon yazalÄ±m.


```python
import time
def pred_timer(model, samples):
  start_time = time.perf_counter() 
  model.predict(samples) 
  end_time = time.perf_counter() 
  total_time = end_time-start_time 
  time_per_pred = total_time/len(val_sentences)
  return total_time, time_per_pred
```

Ä°yi gÃ¶rÃ¼nÃ¼yor!

Åimdi en iyi performans gÃ¶steren modelimizin (`model_6`) ve temel modelimizin (`model_0`) tahmin sÃ¼relerini deÄŸerlendirmek iÃ§in `pred_timer()` fonksiyonumuzu kullanalÄ±m.


```python
model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)
model_6_total_pred_time, model_6_time_per_pred
```




    (0.3335412910000173, 0.0004377182296588153)




```python
baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)
baseline_total_pred_time, baseline_time_per_pred
```




    (0.023066670999980943, 3.0271221784751892e-05)



Mevcut donanÄ±mÄ±mÄ±zla (benim durumumda bir Google Colab not defteri kullanÄ±yorum) en iyi performans gÃ¶steren modelimiz, temel modelimiz olarak tahminler yapmak iÃ§in 10 kat daha fazla zaman alÄ±yor. Bu ekstra tahmin sÃ¼resi buna deÄŸer mi?

Modelimizin F1 puanlarÄ±yla tahmin baÅŸÄ±na sÃ¼reyi karÅŸÄ±laÅŸtÄ±ralÄ±m.


```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 7))
plt.scatter(baseline_time_per_pred, baseline_results["f1"], label="baseline")
plt.scatter(model_6_time_per_pred, model_6_results["f1"], label="tf_hub_sentence_encoder")
plt.legend()
plt.title("F1-score versus time per prediction")
plt.xlabel("Time per prediction")
plt.ylabel("F1-Score");
```


    
![png](8-NLP%27ye%20Giris_files/8-NLP%27ye%20Giris_207_0.png)
    


Elbette, bu noktalarÄ±n her biri iÃ§in ideal konum, grafiÄŸin sol Ã¼st kÃ¶ÅŸesinde olmaktÄ±r (tahmin baÅŸÄ±na dÃ¼ÅŸÃ¼k sÃ¼re, yÃ¼ksek F1 puanÄ±).

Bizim durumumuzda, tahmin ve performans baÅŸÄ±na sÃ¼re iÃ§in aÃ§Ä±k bir fark var. En iyi performans gÃ¶steren modelimiz, tahmin baÅŸÄ±na bir bÃ¼yÃ¼klÃ¼k sÄ±rasÄ± daha uzun sÃ¼rÃ¼yor, ancak yalnÄ±zca birkaÃ§ F1 puanÄ± artÄ±ÅŸÄ±yla sonuÃ§lanÄ±yor.

Bu tÃ¼r bir fark, makine Ã¶ÄŸrenimi modellerini kendi uygulamalarÄ±nÄ±za dahil ederken aklÄ±nÄ±zda bulundurmanÄ±z gereken bir ÅŸeydir.
