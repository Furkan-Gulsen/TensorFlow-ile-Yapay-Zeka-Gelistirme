## Tensorflow ile Transfer Learning - Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature extraction)

```python
# GPU kullanÄ±yoruz mu test edelim
!nvidia-smi
```

    Sun Jul 18 06:27:06 2021       
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |                               |                      |               MIG M. |
    |===============================+======================+======================|
    |   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
    | N/A   43C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
    |                               |                      |                  N/A |
    +-------------------------------+----------------------+----------------------+
                                                                                   
    +-----------------------------------------------------------------------------+
    | Processes:                                                                  |
    |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
    |        ID   ID                                                   Usage      |
    |=============================================================================|
    |  No running processes found                                                 |
    +-----------------------------------------------------------------------------+


## TensorFlow Hub ile Transfer Learning: Verilerin %10'u ile Harika SonuÃ§lar Elde Etme

"Elbette bir baÅŸkasÄ± bu iÅŸ iÃ§in doÄŸru modeli yapmak iÃ§in zaman harcadÄ±..." diye dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z, ÅŸanslÄ±sÄ±nÄ±z demektir.

Derin Ã¶ÄŸrenmeyi kullanmak isteyeceÄŸiniz sorunlarÄ±n Ã§oÄŸu iÃ§in, muhtemelen Ã§alÄ±ÅŸan bir model zaten mevcuttur. Ve iyi haber ÅŸu ki, Ã§oÄŸuna TensorFlow Hub'dan eriÅŸebilirsiniz. [TensorFlow Hub](https://tfhub.dev/), mevcut model bileÅŸenleri iÃ§in bir havuzdur. Bir URL kadar az olan tam eÄŸitimli bir modeli iÃ§e aktarabilmenizi ve kullanabilmenizi saÄŸlar.

Åimdi, size transfer Ã¶ÄŸrenmenin gÃ¼cÃ¼nÃ¼ gerÃ§ekten gÃ¶stermek istiyorum.

Bunu yapmak iÃ§in, orijinal verinin yalnÄ±zca %10'u ile, yani 10 kat daha az veri ile ÅŸimdiye kadar elde ettiÄŸimiz en iyi modelimizin elde ettiÄŸi sonuÃ§larÄ±n Ã§oÄŸunu (veya daha iyisini) elde edebileceÄŸimizi sÃ¶ylesem ne olur?

Bu mantÄ±ksÄ±z gÃ¶rÃ¼nÃ¼yor deÄŸil mi?

Bir yemek resminin nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ne dair daha fazla Ã¶rneÄŸin daha iyi sonuÃ§lara yol aÃ§tÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nmez miydiniz?

Ve genel olarak, daha fazla verinin daha iyi sonuÃ§lara yol aÃ§tÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z haklÄ±sÄ±nÄ±z.

Ancak, ya daha fazla veriye sahip deÄŸilseniz? SÄ±nÄ±f baÅŸÄ±na 750 gÃ¶rsel yerine, sÄ±nÄ±f baÅŸÄ±na 75 gÃ¶rseliniz olsaydÄ± ne olurdu?

Belirli bir sÄ±nÄ±fa ait 675 resim daha toplamak uzun zaman alabilir.

Ä°ÅŸte transfer Ã¶ÄŸreniminin bir baÅŸka Ã¶nemli faydasÄ± da burada devreye giriyor.

AktarÄ±m Ã¶ÄŸrenimi genellikle daha az veriyle harika sonuÃ§lar elde etmenizi saÄŸlar.

Kullanmakta olduÄŸumuz verilerin bir alt kÃ¼mesini, yani 10_food_classes veri kÃ¼mesindeki eÄŸitim verilerinin %10'unu indirelim ve bunu bir yemek gÃ¶rÃ¼ntÃ¼sÃ¼ sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ± eÄŸitmek iÃ§in kullanalÄ±m.

<img src="https://cdn-images-1.medium.com/max/602/1*NF1_eYZrV5fj0_EICLKytw.jpeg" />

## Veriyi Azaltma


```python
# verisetini iÃ§eriye aktarma
import zipfile

!gdown --id 1EJHNCG19hJG6XwIFxt2rpah-Q1Ikrbxw
zip_ref = zipfile.ZipFile("10_food_classes_10_percent.zip", "r")
zip_ref.extractall()
zip_ref.close()
```

    Downloading...
    From: https://drive.google.com/uc?id=1EJHNCG19hJG6XwIFxt2rpah-Q1Ikrbxw
    To: /content/10_food_classes_10_percent.zip
    169MB [00:01, 158MB/s]



```python
# Her klasÃ¶rde kaÃ§ resim var?
import os

for dirpath, dirnames, filenames in os.walk("10_food_classes_10_percent"):
  print(f"'{dirpath}' klasÃ¶rÃ¼nde {len(filenames)} veri var.")
```

    '10_food_classes_10_percent' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_10_percent/test' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_10_percent/test/hamburger' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/grilled_salmon' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/pizza' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/chicken_curry' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/sushi' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/ice_cream' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/fried_rice' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/chicken_wings' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/steak' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/test/ramen' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_10_percent/train' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_10_percent/train/hamburger' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/grilled_salmon' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/pizza' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/chicken_curry' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/sushi' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/ice_cream' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/fried_rice' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/chicken_wings' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/steak' klasÃ¶rÃ¼nde 75 veri var.
    '10_food_classes_10_percent/train/ramen' klasÃ¶rÃ¼nde 75 veri var.


EÄŸitim verilerinin her birinin artÄ±k 750 gÃ¶rÃ¼ntÃ¼ yerine 75 gÃ¶rÃ¼ntÃ¼ye sahip olduÄŸuna dikkat edin. Bu, transfer Ã¶ÄŸreniminin daha az etiketli gÃ¶rÃ¼ntÃ¼lerle ne kadar iyi performans gÃ¶sterebileceÄŸini gÃ¶stermenin anahtarÄ±dÄ±r.

Test dizinleri hala aynÄ± miktarda gÃ¶rÃ¼ntÃ¼ye sahip. Bu, daha az veri Ã¼zerinde eÄŸitim yapacaÄŸÄ±mÄ±z, ancak modellerimizi aynÄ± miktarda test verisi Ã¼zerinde deÄŸerlendireceÄŸimiz anlamÄ±na geliyor.

## Verileri HazÄ±rlama

Verileri indirdik, ÅŸimdi `imageDataGenerator` sÄ±nÄ±fÄ±nÄ± ve `flow_from_directory` yÃ¶ntemini kullanarak resimlerimizi yÃ¼kleyelim.


```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMAGE_SHAPE = (224, 224)
BATCH_SIZE = 32

train_dir = "10_food_classes_10_percent/train/"
test_dir = "10_food_classes_10_percent/test/"

train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)

print("Training resimleri:")
train_data_10_percent = train_datagen.flow_from_directory(train_dir,
                                               target_size=IMAGE_SHAPE,
                                               batch_size=BATCH_SIZE,
                                               class_mode="categorical")

print("Testing resimleri:")
test_data = train_datagen.flow_from_directory(test_dir,
                                              target_size=IMAGE_SHAPE,
                                              batch_size=BATCH_SIZE,
                                              class_mode="categorical")
```

    Training resimleri:
    Found 750 images belonging to 10 classes.
    Testing resimleri:
    Found 2500 images belonging to 10 classes.


MÃ¼kemmel! Verileri yÃ¼klediÄŸimizde, 10 sÄ±nÄ±fa (sÄ±nÄ±f baÅŸÄ±na 75) ait eÄŸitim veri setinde 750 gÃ¶rÃ¼ntÃ¼ ve 10 sÄ±nÄ±fa ait (sÄ±nÄ±f baÅŸÄ±na 250) test setinde 2500 gÃ¶rÃ¼ntÃ¼ olduÄŸunu gÃ¶rÃ¼yoruz.

## Callback Ä°ÅŸlevlerini Ayarlama 

Bir model oluÅŸturmadan Ã¶nce, aÅŸina olacaÄŸÄ±mÄ±z Ã¶nemli bir kavram var Ã§Ã¼nkÃ¼ gelecekteki model oluÅŸturma deneylerimizde kilit bir rol oynayacak.

Ve bu kavram Callback.

[Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks), eÄŸitim sÄ±rasÄ±nda veya sonrasÄ±nda gerÃ§ekleÅŸtirilmek Ã¼zere modellerinize ekleyebileceÄŸiniz ekstra iÅŸlevlerdir. En popÃ¼ler callback'lerden bazÄ±larÄ± ÅŸunlardÄ±r:
- [**TensorBoard ile modeli izleme**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)<br>
Birden fazla modelin performansÄ±nÄ± gÃ¼nlÃ¼ÄŸe kaydedin ve ardÄ±ndan bu modelleri TensorBoard'da (sinir aÄŸÄ± parametrelerini incelemek iÃ§in bir gÃ¶sterge panosu) gÃ¶rsel bir ÅŸekilde gÃ¶rÃ¼ntÃ¼leyin ve karÅŸÄ±laÅŸtÄ±rÄ±n. Verileriniz Ã¼zerinde farklÄ± modellerin sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmanÄ±za yardÄ±mcÄ± olur.
- [**Model Checkpointing**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)<br>
Modelinizi eÄŸitirken kaydedin, bÃ¶ylece gerekirse eÄŸitimi durdurabilir ve kaldÄ±ÄŸÄ±nÄ±z yerden devam etmek iÃ§in geri dÃ¶nebilirsiniz. EÄŸitim uzun sÃ¼rÃ¼yorsa ve bir oturuÅŸta yapÄ±lamÄ±yorsa faydalÄ±dÄ±r.
- [**Early Stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)<br> 
Model eÄŸitiminizi isteÄŸe baÄŸlÄ± bir sÃ¼re iÃ§in bÄ±rakÄ±n ve geliÅŸme sona erdiÄŸinde eÄŸitimi otomatik olarak durdurmasÄ±nÄ± saÄŸlayÄ±n. BÃ¼yÃ¼k bir veri kÃ¼meniz olduÄŸunda ve eÄŸitimin ne kadar sÃ¼receÄŸini bilmediÄŸinizde faydalÄ±dÄ±r.

BunlarÄ±n her birini inceleyeceÄŸiz, ancak bu defter iÃ§in TensorBoard geri aramasÄ±nÄ±n nasÄ±l kullanÄ±labileceÄŸini gÃ¶receÄŸiz.

TensorBoard geri Ã§aÄŸrÄ±sÄ±na `tf.keras.callbacks.TensorBoard()` kullanÄ±larak eriÅŸilebilir. Ana iÅŸlevi, bir modelin eÄŸitim performans Ã¶lÃ§Ã¼mlerini belirtilen bir log_dir'e kaydetmektir.

VarsayÄ±lan olarak, gÃ¼nlÃ¼kler `update_freq='epoch'` parametresi kullanÄ±larak her epoch'ta kaydedilir. Bu iyi bir varsayÄ±landÄ±r, Ã§Ã¼nkÃ¼ model performansÄ±nÄ±n izlenmesi sÄ±klÄ±kla model eÄŸitimini yavaÅŸlatabilir.

TensorBoard kullanarak modelleme deneylerimizi izlemek iÃ§in, bizim iÃ§in bir TensorBoard geri Ã§aÄŸrÄ±sÄ± oluÅŸturan bir fonksiyon oluÅŸturalÄ±m.

> ğŸ”‘ Not: Bir TensorBoard geri Ã§aÄŸrÄ±sÄ± oluÅŸturmak iÃ§in bir fonksiyon yaratÄ±rÄ±z Ã§Ã¼nkÃ¼ daha sonra gÃ¶receÄŸimiz gibi, her model kendi TensorBoard geri Ã§aÄŸÄ±rma Ã¶rneÄŸine ihtiyaÃ§ duyar (bÃ¶ylece fonksiyon her Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda yeni bir tane yaratacaktÄ±r).


```python
# Tensorboard callback iÅŸlevini oluÅŸturma
import datetime
def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"TensorBoard gÃ¼nlÃ¼k dosyalarÄ±nÄ± kaydetme: {log_dir}")
  return tensorboard_callback
```

Birden fazla modeli Ã§alÄ±ÅŸtÄ±rmanÄ±z muhtemel olduÄŸundan, bunlarÄ± bir ÅŸekilde takip edebilmek iyi bir fikirdir.

Bizim durumumuzda, fonksiyonumuz bir modelin performans gÃ¼nlÃ¼klerini `[dir_name]/[experiment_name]/[current_timestamp]` adlÄ± bir dizine kaydeder, burada:

- `dir_name` genel gÃ¼nlÃ¼kler dizinidir
- `experiment_name` belirli bir modeldir
- `current_timestamp` Python'un datetime.datetime().now() deÄŸerine dayalÄ± olarak deneyin baÅŸladÄ±ÄŸÄ± zamandÄ±r

> ğŸ”‘ Not: KullanÄ±m durumunuza baÄŸlÄ± olarak, yukarÄ±daki deneme amaÃ§lÄ± izleme adlandÄ±rma yÃ¶ntemi iÅŸe yarayabilir veya daha spesifik bir ÅŸeye ihtiyacÄ±nÄ±z olabilir. Ä°yi haber ÅŸu ki, TensorBoard geri aramasÄ±, onlarÄ± nerede izleyeceÄŸinizi belirttiÄŸiniz sÃ¼rece modelleme gÃ¼nlÃ¼klerini izlemeyi kolaylaÅŸtÄ±rÄ±r. BÃ¶ylece, deneylerinizi nasÄ±l adlandÄ±rdÄ±ÄŸÄ±nÄ±z konusunda istediÄŸiniz kadar yaratÄ±cÄ± olabilirsiniz, sadece sizin veya ekibinizin onlarÄ± anlayabildiÄŸinden emin olun.

## TensorFlow Hub Kullanarak Bir Model OluÅŸturma

GeÃ§miÅŸte, sÄ±fÄ±rdan katman katman kendi modellerimizi oluÅŸturmak iÃ§in TensorFlow'u kullandÄ±k. Åimdi benzer bir iÅŸlem yapacaÄŸÄ±z, ancak modelimizin katmanlarÄ±nÄ±n Ã§oÄŸu TensorFlow Hub'dan gelecek.

AslÄ±nda, TensorFlow Hub'dan iki model kullanacaÄŸÄ±z:

- **ResNetV2**<br>
2016'dan itibaren son teknoloji bir bilgisayarlÄ± gÃ¶rÃ¼ modeli mimarisi.
- **EfficientNet**<br>
2019'dan itibaren son teknoloji bir bilgisayarlÄ± gÃ¶rÃ¼ mimarisi.

Son teknoloji, bir noktada, bu modellerin her ikisinin de bilgisayarla gÃ¶rme kÄ±yaslamalarÄ±nÄ±n altÄ±n standardÄ± olan ImageNet'te (ILSVRC-2012-CLS) en dÃ¼ÅŸÃ¼k hata oranÄ±nÄ± elde ettiÄŸi anlamÄ±na gelir.

Merak ediyor olabilirsiniz, bu modelleri TensorFlow Hub'da nasÄ±l buluyorsunuz?

Ä°ÅŸte attÄ±ÄŸÄ±m adÄ±mlar:

1. tfhub.dev'e gidin.
2. Sorunlu etki alanÄ±nÄ±zÄ± seÃ§in, Ã¶r. "GÃ¶rÃ¼ntÃ¼" (yemek resimleri kullanÄ±yoruz).
3. Bizim durumumuzda TF2 olan TF sÃ¼rÃ¼mÃ¼nÃ¼zÃ¼ seÃ§in.
4. Ãœzerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z sorun dÄ±ÅŸÄ±ndaki tÃ¼m "Problem Domain" filtrelerini kaldÄ±rÄ±n.
  - **Not:** "Image feature vector" hemen hemen her problemin yanÄ±nda kullanÄ±labilir, buna birazdan geleceÄŸiz.
Listelenen modeller, probleminiz iÃ§in potansiyel olarak kullanÄ±labilecek tÃ¼m modellerdir.

> ğŸ¤” **Soru:**<br> GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma modelleri iÃ§in birÃ§ok seÃ§enek gÃ¶rÃ¼yorum, hangisinin en iyi olduÄŸunu nasÄ±l bileceÄŸim?

En son modellerin bir listesini [paperswithcode.com](https://www.paperswithcode.com/)'da gÃ¶rebilirsiniz; bu kaynak, raporladÄ±klarÄ± bulgular iÃ§in kod uygulamalarÄ±na sahip en son derin Ã¶ÄŸrenme makalesi sonuÃ§larÄ±nÄ± toplamak iÃ§in bir kaynaktÄ±r.

GÃ¶rÃ¼ntÃ¼lerle Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in hedefimiz [ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet)'te en iyi performansÄ± gÃ¶steren modeller.

Muhtemelen kodlu kaÄŸÄ±tlarda listelenen model mimarilerinin tÃ¼mÃ¼nÃ¼n TensorFlow Hub'da gÃ¶rÃ¼nmediÄŸini gÃ¶receksiniz. Ve bu sorun deÄŸil, hala mevcut olanÄ± kullanabiliriz.

6. TensorFlow Hub'da Mimari sekmesini seÃ§in ve mimari adlarÄ±ndan oluÅŸan bir aÃ§Ä±lÄ±r menÃ¼nÃ¼n gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ gÃ¶receksiniz.
  - Buradaki temel kural genellikle, daha bÃ¼yÃ¼k sayÄ±lara sahip isimler daha iyi performans gÃ¶steren modeller anlamÄ±na gelir. Ã–rneÄŸin, EfficientNetB4, EfficientNetB0'dan daha iyi performans gÃ¶sterir.
    - Bununla birlikte, daha bÃ¼yÃ¼k sayÄ±larla yapÄ±lan Ã¶dÃ¼nleÅŸim, hesaplamanÄ±n daha uzun sÃ¼rdÃ¼ÄŸÃ¼ anlamÄ±na gelebilir.

7. EfficientNetB0'Ä± seÃ§in ve aÅŸaÄŸÄ±dakine benzer bir ÅŸey gÃ¶rmelisiniz:

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png" />

8. ["efficientnet/b0/feature-vector"](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1) baÅŸlÄ±ÄŸÄ±na tÄ±klamak bizi "URL'yi kopyala" yazan bir buton iÃ§eren bir sayfaya getiriyor. Bu URL, EfficientNetB0'Ä±n gÃ¼cÃ¼nden yararlanmak iÃ§in kullanabileceÄŸimiz ÅŸeydir.
  - URL'yi kopyalamak size ÅŸÃ¶yle bir ÅŸey vermelidir: https://tfhub.dev/tensorflow/quality/b0/feature-vector/1

> ğŸ¤” Soru: GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± yaptÄ±ÄŸÄ±mÄ±zÄ± sanÄ±yordum, neden sÄ±nÄ±flandÄ±rma deÄŸil de Ã¶zellik vektÃ¶rÃ¼nÃ¼ seÃ§iyoruz?

Harika gÃ¶zlem. Bu, Ã¶zellik Ã§Ä±karma ve ince ayar gibi farklÄ± aktarÄ±m Ã¶ÄŸrenme tÃ¼rlerinin devreye girdiÄŸi yerdir.

1. **"As is" transfer Ã¶ÄŸrenme**, Ã¶nceden eÄŸitilmiÅŸ bir modeli olduÄŸu gibi alÄ±p herhangi bir deÄŸiÅŸiklik yapmadan gÃ¶revinize uyguladÄ±ÄŸÄ±nÄ±z zamandÄ±r.

  - Ã–rneÄŸin, birÃ§ok bilgisayarlÄ± gÃ¶rÃ¼ modeli, 1000 farklÄ± gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±fÄ±nÄ± iÃ§eren ImageNet veri kÃ¼mesi Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸtir. Bu, bu modele tek bir gÃ¶rÃ¼ntÃ¼nÃ¼n geÃ§irilmesinin 1000 farklÄ± tahmin olasÄ±lÄ±ÄŸÄ± deÄŸeri (her sÄ±nÄ±f iÃ§in 1) Ã¼reteceÄŸi anlamÄ±na gelir.

    - SÄ±nÄ±flandÄ±rmak istediÄŸiniz 1000 gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±fÄ±nÄ±z varsa ve bunlarÄ±n tÃ¼mÃ¼ ImageNet sÄ±nÄ±flarÄ±yla aynÄ±ysa bu yararlÄ±dÄ±r, ancak yalnÄ±zca kÃ¼Ã§Ã¼k bir sÄ±nÄ±f alt kÃ¼mesini (10 farklÄ± tÃ¼r gibi) sÄ±nÄ±flandÄ±rmak istiyorsanÄ±z bu yararlÄ± deÄŸildir. TensorFlow Hub'da adlarÄ±nda `/classification` bulunan modeller bu tÃ¼r bir iÅŸlevsellik saÄŸlar.

2. **Ã–zellik Ã§Ä±karma transferi Ã¶ÄŸrenimi**, Ã¶nceden eÄŸitilmiÅŸ bir modelin Ã¶ÄŸrendiÄŸi temel kalÄ±plarÄ± (aÄŸÄ±rlÄ±klar da denir) aldÄ±ÄŸÄ±nÄ±zda ve Ã§Ä±ktÄ±larÄ±nÄ± probleminize daha uygun olacak ÅŸekilde ayarladÄ±ÄŸÄ±nÄ±zda gerÃ§ekleÅŸir.

  - Ã–rneÄŸin, kullandÄ±ÄŸÄ±nÄ±z Ã¶nceden eÄŸitilmiÅŸ modelin 236 farklÄ± katmanÄ± olduÄŸunu varsayalÄ±m (EfficientNetB0'Ä±n 236 katmanÄ± vardÄ±r), ancak ImageNet'te Ã¶nceden eÄŸitildiÄŸi iÃ§in Ã¼st katman 1000 sÄ±nÄ±f verir. Bunu kendi probleminize gÃ¶re ayarlamak iÃ§in, orijinal etkinleÅŸtirme katmanÄ±nÄ± kaldÄ±rabilir ve onu kendinizle ancak doÄŸru sayÄ±da Ã§Ä±ktÄ± sÄ±nÄ±fÄ±yla deÄŸiÅŸtirebilirsiniz. Buradaki Ã¶nemli kÄ±sÄ±m, sadece en Ã¼stteki birkaÃ§ katmanÄ±n eÄŸitilebilir hale gelmesi, geri kalanÄ±nÄ±n donmuÅŸ kalmasÄ±dÄ±r.

    - Bu ÅŸekilde, temeldeki tÃ¼m desenler diÄŸer katmanlarda kalÄ±r ve bunlarÄ± kendi probleminiz iÃ§in kullanabilirsiniz. Bu tÃ¼r aktarÄ±m Ã¶ÄŸrenimi, verileriniz bir modelin Ã¶nceden eÄŸitilmiÅŸ olduÄŸu verilere benzer olduÄŸunda Ã§ok faydalÄ±dÄ±r.

3. **Ä°nce ayarlÄ± (fine tuning) transfer Ã¶ÄŸrenimi**, Ã¶nceden eÄŸitilmiÅŸ bir modelin temel modellerini (aÄŸÄ±rlÄ±k olarak da adlandÄ±rÄ±lÄ±r) aldÄ±ÄŸÄ±nÄ±z ve bunlarÄ± kendi probleminize gÃ¶re ayarladÄ±ÄŸÄ±nÄ±z (ince ayar yaptÄ±ÄŸÄ±nÄ±z) zamandÄ±r.

  - Bu genellikle Ã¶nceden eÄŸitilmiÅŸ modeldeki katmanlarÄ±n bir kÄ±smÄ±nÄ±n, Ã§oÄŸunun veya tamamÄ±nÄ±n eÄŸitilmesi anlamÄ±na gelir. Bu, verilerinizin orijinal modelin eÄŸitildiÄŸi verilerden biraz farklÄ± olduÄŸu bÃ¼yÃ¼k bir veri kÃ¼meniz (Ã¶r. sÄ±nÄ±f baÅŸÄ±na 100'den fazla gÃ¶rÃ¼ntÃ¼) olduÄŸunda kullanÄ±ÅŸlÄ±dÄ±r.

YaygÄ±n bir iÅŸ akÄ±ÅŸÄ±, Ã¶nceden eÄŸitilmiÅŸ bir modelin alt katmanlarÄ±nda Ã¶ÄŸrenilen tÃ¼m kalÄ±plarÄ± "dondurarak" eÄŸitilemez hale getirmektir. ArdÄ±ndan, Ã¶nceden eÄŸitilmiÅŸ modelin Ã§Ä±ktÄ±larÄ±nÄ± Ã¶zel verilerinize gÃ¶re ayarlayabilmesi iÃ§in Ã¼ste ki 2-3 katmanÄ±nÄ± eÄŸitin (Ã¶zellik Ã§Ä±karma).

Ä°lk 2-3 katmanÄ± eÄŸittikten sonra, giderek daha fazla katmanÄ± kademeli olarak "Ã§Ã¶zebilir" ve Ã¶nceden eÄŸitilmiÅŸ modelde daha fazla ince ayar yapmak iÃ§in eÄŸitim sÃ¼recini kendi verileriniz Ã¼zerinde Ã§alÄ±ÅŸtÄ±rabilirsiniz.

> ğŸ¤” Soru: Ã–zellik Ã§Ä±karmada neden yalnÄ±zca ilk 2-3 katmanÄ± eÄŸitelim?

Bir bilgisayarlÄ± gÃ¶rÃ¼ modelinde bir katman ne kadar dÃ¼ÅŸÃ¼kse, girdi katmanÄ±na ne kadar yakÄ±nsa, Ã¶ÄŸrendiÄŸi Ã¶zellikler o kadar bÃ¼yÃ¼k olur. Ã–rneÄŸin, kedilerin veya kÃ¶peklerin gÃ¶rÃ¼ntÃ¼lerini tanÄ±mlamak iÃ§in bir bilgisayarlÄ± gÃ¶rme modelindeki bir alt katman, bacaklarÄ±n ana hatlarÄ±nÄ± Ã¶ÄŸrenebilirken, Ã§Ä±ktÄ±ya daha yakÄ±n katmanlar diÅŸlerin ÅŸeklini Ã¶ÄŸrenebilir. Ã‡oÄŸu zaman, daha bÃ¼yÃ¼k Ã¶zelliklerin (Ã¶ÄŸrenilmiÅŸ kalÄ±plar aynÄ± zamanda Ã¶zellikler olarak da adlandÄ±rÄ±lÄ±r) kalmasÄ±nÄ± istersiniz, Ã§Ã¼nkÃ¼ bunlar her iki hayvan iÃ§in de benzerdir, ancak farklÄ±lÄ±klar daha ince taneli Ã¶zelliklerde kalÄ±r.

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png" />

Tamam, yeterince konuÅŸtuk, ÅŸimdi bunu uygulayarak gÃ¶relim. Bir kez yaptÄ±ÄŸÄ±mÄ±zda, neler olduÄŸunu aÃ§Ä±klayacaÄŸÄ±z.

Ä°lk Ã¶nce TensorFlow ve TensorFlow Hub'Ä± iÃ§e aktaracaÄŸÄ±z.


```python
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow.keras import layers
```

Åimdi, yukarÄ±daki adÄ±mlarÄ± kullanarak TensorFlow Hub'dan iki yaygÄ±n bilgisayarlÄ± gÃ¶rÃ¼ mimarisinin, [EfficientNetB0 (2019)](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1) ve [ResNetV250 (2016)](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4) Ã¶zellik vektÃ¶r URL'lerini alacaÄŸÄ±z.

Her ikisini de alÄ±yoruz Ã§Ã¼nkÃ¼ verilerimizde hangisinin daha iyi performans gÃ¶sterdiÄŸini gÃ¶rmek iÃ§in onlarÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z.

> ğŸ”‘ Not: AynÄ± veriler Ã¼zerinde farklÄ± model mimarisi performansÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± Ã§ok yaygÄ±n bir uygulamadÄ±r. Bunun basit nedeni, probleminiz iÃ§in hangi modelin en iyi performansÄ± gÃ¶sterdiÄŸini bilmek istemenizdir.


```python
# Resnet 50 V2 Ã¶zellik vektÃ¶rÃ¼
resnet_url = "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4"

# EfficientNet0 Ã¶zellik vektÃ¶rÃ¼
efficientnet_url = "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
```

Bu URL'ler, TensorFlow Hub'da kaydedilmiÅŸ Ã¶nceden eÄŸitilmiÅŸ bir modele baÄŸlanÄ±r.

BunlarÄ± modelimizde kullandÄ±ÄŸÄ±mÄ±zda, model otomatik olarak indirilip kullanmamÄ±z iÃ§in indirilecektir.

Bunu yapmak iÃ§in TensorFlow hub kitaplÄ±ÄŸÄ± iÃ§indeki [KerasLayer()](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) modelini kullanabiliriz.

Ä°ki modeli karÅŸÄ±laÅŸtÄ±racaÄŸÄ±mÄ±zdan, kendi kodumuzdan tasarruf etmek iÃ§in bir `create_model()` iÅŸlevi yaratacaÄŸÄ±z. Bu iÅŸlev, bir modelin TensorFlow Hub URL'sini alacak, uygun sayÄ±da Ã§Ä±ktÄ± katmanÄ±na sahip bir Keras SÄ±ralÄ± modeli oluÅŸturacak ve modeli dÃ¶ndÃ¼recektir.


```python
def create_model(model_url, num_classes=10):
  """
  Bir TensorFlow Hub URL'sini alÄ±r ve onunla bir Keras SÄ±ralÄ± modeli oluÅŸturur.
  
  Args:
    model_url (str): Bir TensorFlow Hub Ã¶zelliÄŸi Ã§Ä±karma URL'si.
    num_classes (int): Ã‡Ä±kÄ±ÅŸ katmanÄ±ndaki Ã§Ä±kÄ±ÅŸ nÃ¶ronlarÄ±nÄ±n sayÄ±sÄ±, 
          varsayÄ±lan olarak 10 olan hedef sÄ±nÄ±flarÄ±n sayÄ±sÄ±na eÅŸit olmalÄ±dÄ±r.

  Returns:
    Ã–zellik Ã§Ä±karma katmanÄ± olarak model_url ve num_classes Ã§Ä±ktÄ±larÄ± ile 
    YoÄŸun Ã§Ä±ktÄ± katmanÄ± ile derlenmemiÅŸ Keras SÄ±ralÄ± modeli.
  """
  # Ã–nceden eÄŸitilmiÅŸ modeli indirin ve Keras katmanÄ± olarak kaydedin
  feature_extractor_layer = hub.KerasLayer(model_url,
                                           trainable=False, # temel kalÄ±plarÄ± dondur
                                           name='feature_extraction_layer',
                                           input_shape=IMAGE_SHAPE+(3,)) # giriÅŸ gÃ¶rÃ¼ntÃ¼ ÅŸeklini tanÄ±mla
  
  # Kendi modelimizi oluÅŸturun
  model = tf.keras.Sequential([
    feature_extractor_layer, # Ã¶zellik Ã§Ä±karma katmanÄ±nÄ± temel olarak kullanÄ±n
    layers.Dense(num_classes, activation='softmax', name='output_layer') # kendi Ã§Ä±ktÄ± katmanÄ±mÄ±zÄ± yarat      
  ])

  return model
```

Harika! Åimdi bir model oluÅŸturmak iÃ§in bir fonksiyonumuz var, bunu ilk Ã¶nce Ã¶zellik Ã§Ä±karma katmanÄ±mÄ±z olarak ResNetV250 mimarisini kullanarak bir model oluÅŸturmak iÃ§in kullanacaÄŸÄ±z.

Model somutlaÅŸtÄ±rÄ±ldÄ±ktan sonra, kayÄ±p fonksiyonumuz olarak `categorical_crossentropy`'yi, metriÄŸimiz olarak Adam optimizer'Ä± ve doÄŸruluÄŸu kullanarak onu derleyeceÄŸiz.


```python
# Model oluÅŸturma
resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)

# Derleme
resnet_model.compile(loss='categorical_crossentropy',
                     optimizer=tf.keras.optimizers.Adam(),
                     metrics=['accuracy'])
```

<img src="https://www.lifejson.com/wp-content/uploads/2019/09/resnet50.jpg" />

Mevcut modelimiz nasÄ±l gÃ¶rÃ¼nÃ¼yor. Ãœstte Ã¶zel bir yoÄŸun katmana sahip bir ResNet50V2 mimarisi (1000 ImageNet sÄ±nÄ±fÄ± yerine 10 sÄ±nÄ±f) var.

Åimdi modeli fit etme zamanÄ±.

Train_data_10_percent iÃ§indeki eÄŸitim verilerini ve test_data olarak kaydedilen test verilerini hazÄ±rladÄ±k. Ancak fit iÅŸlevini Ã§aÄŸÄ±rmadan Ã¶nce, ekleyeceÄŸimiz bir ÅŸey daha var, bir callback. Daha spesifik olarak, modelimizin performansÄ±nÄ± TensorBoard'da izleyebilmemiz iÃ§in bir TensorBoard callback. 

Fit fonksiyonunda callbacks parametresini kullanarak modelimize bir callback ekleyebiliriz.

Bizim durumumuzda, daha Ã¶nce oluÅŸturduÄŸumuz `create_tensorboard_callback()` parametresini bazÄ± Ã¶zel girdilerle ileteceÄŸiz, bÃ¶ylece hangi adÄ±mlarda Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zÄ± bileceÄŸiz. Bu adÄ±mlarÄ± kÄ±sa tutalÄ±m ve 5 epoch boyunca training yapalÄ±m.



```python
# modeli fit etme
resnet_history = resnet_model.fit(train_data_10_percent,
                   epochs=5,
                   steps_per_epoch=len(train_data_10_percent),
                   validation_data=test_data,
                   validation_steps=len(test_data),
                   callbacks=[
                        create_tensorboard_callback(
                            # buraya kaydet
                            dir_name="tensorflow_hub", 
                            # log dosyalarÄ±nÄ±n adÄ±
                            experiment_name="resnet50V2")]) 
```

    TensorBoard gÃ¼nlÃ¼k dosyalarÄ±nÄ± kaydetme: tensorflow_hub/resnet50V2/20210718-071814
    Epoch 1/5
    24/24 [==============================] - 51s 786ms/step - loss: 1.9539 - accuracy: 0.3627 - val_loss: 1.2220 - val_accuracy: 0.6100
    Epoch 2/5
    24/24 [==============================] - 15s 653ms/step - loss: 0.9010 - accuracy: 0.7573 - val_loss: 0.8473 - val_accuracy: 0.7336
    Epoch 3/5
    24/24 [==============================] - 15s 653ms/step - loss: 0.6149 - accuracy: 0.8373 - val_loss: 0.7469 - val_accuracy: 0.7636
    Epoch 4/5
    24/24 [==============================] - 16s 690ms/step - loss: 0.4715 - accuracy: 0.8867 - val_loss: 0.7012 - val_accuracy: 0.7716
    Epoch 5/5
    24/24 [==============================] - 16s 668ms/step - loss: 0.3838 - accuracy: 0.9173 - val_loss: 0.6743 - val_accuracy: 0.7828


GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re sadece 5 epcoh'tan sonra, ResNetV250 Ã¶zellik Ã§Ä±karma modeli, yaptÄ±ÄŸÄ±mÄ±z mimarilerden herhangi birini cebinden Ã§Ä±karacak hale geldi ve eÄŸitim setinde yaklaÅŸÄ±k %90 doÄŸruluk ve test setinde yaklaÅŸÄ±k %80 doÄŸruluk elde etti... eÄŸitim gÃ¶rÃ¼ntÃ¼lerinin sadece %10'u ile! Bu, transfer Ã¶ÄŸrenmenin gÃ¼cÃ¼nÃ¼ gÃ¶sterir.

`Plot_loss_curves` fonksiyonumuzu kullanarak modelimizin eÄŸitim eÄŸrilerini kontrol edelim.


```python
import matplotlib.pyplot as plt

def plot_loss_curves(history):
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();
```


```python
plot_loss_curves(resnet_history)
```


    
![png](https://github.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/blob/main/4-Transfer%20Learning%20-%20%C3%96zellik%20%C3%87%C4%B1kar%C4%B1m%C4%B1%20(Feature%20extraction)/images/plot1.png?raw=true)
    
    
![png](https://github.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/blob/main/4-Transfer%20Learning%20-%20%C3%96zellik%20%C3%87%C4%B1kar%C4%B1m%C4%B1%20(Feature%20extraction)/images/plot2.png?raw=true)
    



```python
resnet_model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    feature_extraction_layer (Ke (None, 2048)              23564800  
    _________________________________________________________________
    output_layer (Dense)         (None, 10)                20490     
    =================================================================
    Total params: 23,585,290
    Trainable params: 20,490
    Non-trainable params: 23,564,800
    _________________________________________________________________


TensorFlow Hub'Ä±n gÃ¼cÃ¼nÃ¼ burada gÃ¶rebilirsiniz. Ã–zellik Ã§Ä±karma katmanÄ±, modelin ImageNet veri kÃ¼mesinde Ã¶nceden Ã¶ÄŸrenmiÅŸ olduÄŸu Ã¶nceden Ã¶ÄŸrenilmiÅŸ desenler olan 23.564.800 parametreye sahiptir. Trainable=False ayarÄ±nÄ± yaptÄ±ÄŸÄ±mÄ±z iÃ§in, bu modeller eÄŸitim sÄ±rasÄ±nda donmuÅŸ (eÄŸitilemez) olarak kalÄ±r.

Bu, eÄŸitim sÄ±rasÄ±nda modelin Ã§Ä±ktÄ± katmanÄ±ndaki 20.490 parametreyi veri kÃ¼memize uyacak ÅŸekilde gÃ¼ncellediÄŸi anlamÄ±na gelir.

Tamam, bir ResNetV250 modelini eÄŸittik, aynÄ±sÄ±nÄ± EfficientNetB0 modeliyle yapmanÄ±n zamanÄ± geldi.

`create_model()` iÅŸlevindeki model_url parametresi ve `create_tensorboard_callback()` iÅŸlevindeki `trial_name` parametresi dÄ±ÅŸÄ±nda kurulum Ã¶ncekiyle tamamen aynÄ± olacaktÄ±r.


```python
efficientnet_model = create_model(model_url=efficientnet_url,
                                  num_classes=train_data_10_percent.num_classes)

efficientnet_model.compile(loss='categorical_crossentropy',
                           optimizer=tf.keras.optimizers.Adam(),
                           metrics=['accuracy'])

efficientnet_history = efficientnet_model.fit(train_data_10_percent, 
                                              epochs=5, 
                                              steps_per_epoch=len(train_data_10_percent),
                                              validation_data=test_data,
                                              validation_steps=len(test_data),
                                              callbacks=[create_tensorboard_callback(dir_name="tensorflow_hub", 
                                                                                     experiment_name="efficientnetB0")])
```

    TensorBoard gÃ¼nlÃ¼k dosyalarÄ±nÄ± kaydetme: tensorflow_hub/efficientnetB0/20210718-072739
    Epoch 1/5
    24/24 [==============================] - 26s 784ms/step - loss: 1.8246 - accuracy: 0.4560 - val_loss: 1.2880 - val_accuracy: 0.7260
    Epoch 2/5
    24/24 [==============================] - 15s 626ms/step - loss: 1.0520 - accuracy: 0.7760 - val_loss: 0.8606 - val_accuracy: 0.8164
    Epoch 3/5
    24/24 [==============================] - 15s 656ms/step - loss: 0.7489 - accuracy: 0.8333 - val_loss: 0.6961 - val_accuracy: 0.8452
    Epoch 4/5
    24/24 [==============================] - 16s 666ms/step - loss: 0.6025 - accuracy: 0.8587 - val_loss: 0.6101 - val_accuracy: 0.8576
    Epoch 5/5
    24/24 [==============================] - 15s 634ms/step - loss: 0.5112 - accuracy: 0.8947 - val_loss: 0.5553 - val_accuracy: 0.8648


`EfficientNetB0` modeli, `ResNetV250` modelinden bile daha iyi bir sonuÃ§ verdi! Yine eÄŸitim verilerinin yalnÄ±zca %10'u ile test setinde %85'in Ã¼zerinde doÄŸruluk elde etmek. Ne kadar havalÄ± deÄŸil mi?

BirkaÃ§ satÄ±r kodla, son teknoloji modellerden yararlanabiliyor ve bunlarÄ± kendi kullanÄ±m durumumuza gÃ¶re ayarlayabiliyoruz.

KayÄ±p (Loss) eÄŸrilerini kontrol edelim.


```python
plot_loss_curves(efficientnet_history)
```


    
![png](https://github.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/blob/main/4-Transfer%20Learning%20-%20%C3%96zellik%20%C3%87%C4%B1kar%C4%B1m%C4%B1%20(Feature%20extraction)/images/plot3.png)
    



    
![png](https://github.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/blob/main/4-Transfer%20Learning%20-%20%C3%96zellik%20%C3%87%C4%B1kar%C4%B1m%C4%B1%20(Feature%20extraction)/images/plot4.png)
    


EfficientNetB0 modelinin kayÄ±p eÄŸrilerine bakÄ±ldÄ±ÄŸÄ±nda, modelimizi daha uzun sÃ¼re eÄŸitmeye devam edersek, daha da geliÅŸebilir gibi gÃ¶rÃ¼nÃ¼yor. Belki de denemek isteyebileceÄŸiniz bir ÅŸeydir?

Model Ã¶zetini kontrol edelim.


```python
efficientnet_model.summary()
```

    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    feature_extraction_layer (Ke (None, 1280)              4049564   
    _________________________________________________________________
    output_layer (Dense)         (None, 10)                12810     
    =================================================================
    Total params: 4,062,374
    Trainable params: 12,810
    Non-trainable params: 4,049,564
    _________________________________________________________________


ResNet50V2 Ã§Ä±karma katmanÄ±ndan dÃ¶rt kat daha az parametreye (4.049.564'e karÅŸÄ± 23.564.800) sahip olmasÄ±na raÄŸmen, EfficientNetB0 Ã¶zellik Ã§Ä±karma katmanÄ± daha iyi performans saÄŸlÄ±yor gibi gÃ¶rÃ¼nÃ¼yor. Åimdi "verimli(efficient)" ismin nereden geldiÄŸi aÃ§Ä±ÄŸa kavuÅŸtu.

## TensorBoard Kullanarak Modelleri KarÅŸÄ±laÅŸtÄ±rma

Pekala, doÄŸruluk puanlarÄ±na bakarak iki modelimizin performansÄ±nÄ± zaten karÅŸÄ±laÅŸtÄ±rmÄ±ÅŸ olmamÄ±za raÄŸmen. Peki ya ikiden fazla modeliniz varsa?

TensorBoard (Google Colab'a Ã¶nceden yÃ¼klenmiÅŸ) gibi bir deneme izleme aracÄ±nÄ±n devreye girdiÄŸi yer burasÄ±dÄ±r.

Ä°ÅŸin iyi yanÄ±, bir TensorBoard geri aramasÄ± oluÅŸturduÄŸumuzdan, modelimizin tÃ¼m eÄŸitim gÃ¼nlÃ¼kleri otomatik olarak kaydedildi. BunlarÄ± gÃ¶rselleÅŸtirmek iÃ§in sonuÃ§larÄ± TensorBoard.dev'e yÃ¼kleyebiliriz.

SonuÃ§larÄ±nÄ±zÄ± TensorBoard.dev'e yÃ¼klemek, birden Ã§ok farklÄ± modelleme deneyini izlemenize ve paylaÅŸmanÄ±za olanak tanÄ±r. DolayÄ±sÄ±yla, sonuÃ§larÄ±nÄ±zÄ± birine gÃ¶stermeniz gerekirse, onlara TensorBoard.dev'inize ve beraberindeki Colab not defterine bir baÄŸlantÄ± gÃ¶nderebilirsiniz.

> ğŸ”‘ Not: Bu deneyler herkese aÃ§Ä±ktÄ±r, hassas verileri yÃ¼klemeyin. Gerekirse deneyleri silebilirsiniz.

TensorBoard'a bir dizi TensorFlow gÃ¼nlÃ¼ÄŸÃ¼ yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki komutu kullanabiliriz:

```
!tensorboard dev upload --logdir ./tensorflow_hub/ \ upload directory
  --name "EfficientNetB0 vs. ResNet50V2" \ 
  --description "Comparing two different TF Hub feature extraction models architectures using 10% of training images" \ 
  --one_shot
```

- **--logdir** hedef yÃ¼kleme dizinidir
- **--name** deneyin adÄ±dÄ±r
- **--description**, deneyin kÄ±sa bir aÃ§Ä±klamasÄ±dÄ±r
- **--one_shot**, yÃ¼kleme tamamlandÄ±ÄŸÄ±nda TensorBoard yÃ¼kleyicisinden Ã§Ä±kar

Tensorboard dev yÃ¼kleme komutunu Ã§alÄ±ÅŸtÄ±rmak, Ã¶nce sizden TensorBoard.dev'e yÃ¼klemeyi yetkilendirmenizi isteyecektir. YÃ¼klemeye yetki verdikten sonra gÃ¼nlÃ¼k dosyalarÄ±nÄ±z yÃ¼klenecektir.


```python
!tensorboard dev upload --logdir ./tensorflow_hub/ \
  --name "EfficientNetB0 vs. ResNet50V2" \
  --description "EÄŸitim gÃ¶rÃ¼ntÃ¼lerinin %10'unu kullanarak iki farklÄ± TF Hub Ã¶zellik Ã§Ä±karma modeli mimarisini karÅŸÄ±laÅŸtÄ±rma" \
  --one_shot
```

    2021-07-18 07:32:27.365995: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
    
    ***** TensorBoard Uploader *****
    
    This will upload your TensorBoard logs to https://tensorboard.dev/ from
    the following directory:
    
    ./tensorflow_hub/
    
    This TensorBoard will be visible to everyone. Do not upload sensitive
    data.
    
    Your use of this service is subject to Google's Terms of Service
    <https://policies.google.com/terms> and Privacy Policy
    <https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service
    <https://tensorboard.dev/policy/terms/>.
    
    This notice will not be shown again while you are logged into the uploader.
    To log out, run `tensorboard dev auth revoke`.
    
    Continue? (yes/NO) yes
    
    Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=bf8UoFUQvUQSTPqShxA60TFbcmiXbj&prompt=consent&access_type=offline
    Enter the authorization code: 4/1AX4XfWgr_3RcFJ17qHRy42CpJB67ENEt-17XiwOjtcTFfG4dkewDiiQbWJU
    
    Data for the "text" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the "--plugins" command line argument.
    
    New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/8GMyPMx6Q8i6PWKxlobOUA/
    
    [1m[2021-07-18T07:32:52][0m Started scanning logdir.
    [1m[2021-07-18T07:32:54][0m Total uploaded: 60 scalars, 0 tensors, 2 binary objects (5.8 MB)
    [1m[2021-07-18T07:32:54][0m Done scanning logdir.
    
    
    Done. View your TensorBoard at https://tensorboard.dev/experiment/8GMyPMx6Q8i6PWKxlobOUA/


AynÄ± dizini tekrar yÃ¼klerseniz, onunla birlikte kullanabileceÄŸiniz yeni bir deneme kimliÄŸi alÄ±rsÄ±nÄ±z.

Bu, denemelerinizi izlemek iÃ§in yÃ¼klemelerinizi nasÄ±l adlandÄ±rdÄ±ÄŸÄ±nÄ±za bakmak isteyebilirsiniz. Bu ÅŸekilde, onlarÄ± TensorBoard.dev'de bulduÄŸunuzda, her deney sÄ±rasÄ±nda ne olduÄŸunu anlayabilirsiniz (Ã¶rneÄŸin, "efficientNet0_10_percent_data").

YÃ¼klediÄŸiniz tÃ¼m deneyleri gÃ¶rmek iÃ§in ÅŸu komutu kullanabilirsiniz:


```python
!tensorboard dev list
```

    2021-07-18 07:33:48.244992: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
    Data for the "text" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the "--plugins" command line argument.
    https://tensorboard.dev/experiment/8GMyPMx6Q8i6PWKxlobOUA/
    	Name                 EfficientNetB0 vs. ResNet50V2
    	Description          EÄŸitim gÃ¶rÃ¼ntÃ¼lerinin %10'unu kullanarak iki farklÄ± TF Hub Ã¶zellik Ã§Ä±karma modeli mimarisini karÅŸÄ±laÅŸtÄ±rma
    	Id                   8GMyPMx6Q8i6PWKxlobOUA
    	Created              2021-07-18 07:32:52 (1 minute ago)
    	Updated              2021-07-18 07:32:54 (1 minute ago)
    	Runs                 4
    	Tags                 5
    	Scalars              60
    	Tensor bytes         0
    	Binary object bytes  6086643
    https://tensorboard.dev/experiment/i2nAxQRWTdi5SaO8AGLEyQ/
    	Name                 Transfer learning experiments
    	Description          A series of different transfer learning experiments with varying amounts of data and fine-tuning
    	Id                   i2nAxQRWTdi5SaO8AGLEyQ
    	Created              2021-06-20 19:15:09
    	Updated              2021-06-20 19:15:14
    	Runs                 10
    	Tags                 5
    	Scalars              162
    	Tensor bytes         0
    	Binary object bytes  4197130
    Total: 2 experiment(s)


<img src="https://i.ibb.co/bKLwqgv/Screenshot-from-2021-07-18-10-34-59.png" />

UnutmayÄ±n, TensorBoard.dev'e yapÄ±lan tÃ¼m yÃ¼klemeler herkese aÃ§Ä±ktÄ±r, bu nedenle bir deneyi silmek iÃ§in ÅŸu komutu kullanabilirsiniz:

`tensorboard dev delete --experiment_id [INSERT_EXPERIMENT_ID]`


```python
# Delete an experiment
!tensorboard dev delete --experiment_id 8GMyPMx6Q8i6PWKxlobOUA
```

    2021-07-18 07:37:06.957170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
    Data for the "text" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the "--plugins" command line argument.
    Deleted experiment 8GMyPMx6Q8i6PWKxlobOUA.



```python
# hala var olup olmadÄ±ÄŸÄ±nÄ± kontrol edin
!tensorboard dev list
```

    2021-07-18 07:37:31.456131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
    Data for the "text" plugin is now uploaded to TensorBoard.dev! Note that uploaded data is public. If you do not want to upload data for this plugin, use the "--plugins" command line argument.
    No experiments. Use `tensorboard dev upload` to get started.

