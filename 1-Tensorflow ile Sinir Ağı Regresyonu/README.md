Bu konuya baÅŸlamadan Ã¶nce aÅŸaÄŸÄ±da bulunan kavramlar Ã§ok iyi bir ÅŸekilde anlaÅŸÄ±lmasÄ± gerekiyor.

## Regresyon Analizi Nedir?

**Regresyon analizi, iki ya da daha Ã§ok nicel deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§mek iÃ§in kullanÄ±lan analiz metodudur.** EÄŸer tek bir deÄŸiÅŸken kullanÄ±larak analiz yapÄ±lÄ±yorsa buna tek deÄŸiÅŸkenli regresyon, birden Ã§ok deÄŸiÅŸken kullanÄ±lÄ±yorsa Ã§ok deÄŸiÅŸkenli regresyon analizi olarak isimlendirilir. Regresyon analizi ile deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin varlÄ±ÄŸÄ±, eÄŸer iliÅŸki var ise bunun gÃ¼cÃ¼ hakkÄ±nda bilgi edinilebilir. 

Ã–rneÄŸin; <br>
Bir daire satÄ±n almayÄ± dÃ¼ÅŸÃ¼nÃ¼yorsunuz. Bu dairenin fiyatÄ±nÄ± belirleyen birden Ã§ok unsur vardÄ±r. Ã–rnek:
- Toplu taÅŸÄ±maya yakÄ±nlÄ±ÄŸÄ±
- ManzarasÄ±
- KaÃ§Ä±ncÄ± katta olduÄŸu
- BinanÄ±n yapÄ±m yÄ±lÄ±

gibi benzeri bir Ã§ok unsur binanÄ±n fiyatÄ±nÄ± belirleyen Ã¶nemli faktÃ¶rlerdir. 

Regresyonda, deÄŸiÅŸkenlerden biri baÄŸÄ±mlÄ± diÄŸerleri baÄŸÄ±msÄ±z deÄŸiÅŸken olmalÄ±dÄ±r. 


## Yapay Sinir AÄŸÄ± Nedir?

Yapay sinir aÄŸlarÄ± (YSA), insan beyninin bilgi iÅŸleme tekniÄŸinden esinlenerek geliÅŸtirilmiÅŸ bir bilgi iÅŸlem teknolojisidir. YSA ile basit biyolojik sinir sisteminin Ã§alÄ±ÅŸma ÅŸekli taklit edilir. Yani biyolojik nÃ¶ron hÃ¼crelerinin ve bu hÃ¼crelerin birbirleri ile arasÄ±nda kurduÄŸu sinaptik baÄŸÄ±n dijital olarak modellenmesidir.

NÃ¶ronlar Ã§eÅŸitli ÅŸekillerde birbirlerine baÄŸlanarak aÄŸlar oluÅŸtururlar. Bu aÄŸlar Ã¶ÄŸrenme, hafÄ±zaya alma ve veriler arasÄ±ndaki iliÅŸkiyi ortaya Ã§Ä±karma kapasitesine sahiptirler. DiÄŸer bir ifadeyle, YSA'lar, normalde bir insanÄ±n dÃ¼ÅŸÃ¼nme ve gÃ¶zlemlemeye yÃ¶nelik doÄŸal yeteneklerini gerektiren problemlere Ã§Ã¶zÃ¼m Ã¼retmektedir. Bir insanÄ±n, dÃ¼ÅŸÃ¼nme ve gÃ¶zlemleme yeteneklerini gerektiren problemlere yÃ¶nelik Ã§Ã¶zÃ¼mler Ã¼retebilmesinin temel sebebi ise insan beyninin ve dolayÄ±sÄ±yla insanÄ±n sahip olduÄŸu yaÅŸayarak veya deneyerek Ã¶ÄŸrenme yeteneÄŸidir.

Yapay Sinir AÄŸlarÄ±nÄ±n AvantajlarÄ±
- Yapay Sinir AÄŸlarÄ± bir Ã§ok hÃ¼creden meydana gelir ve bu hÃ¼creler eÅŸ zamanlÄ± Ã§alÄ±ÅŸarak karmaÅŸÄ±k iÅŸleri gerÃ§ekleÅŸtirir.
- Ã–ÄŸrenme kabiliyeti vardÄ±r ve farklÄ± Ã¶ÄŸrenme algoritmalarÄ±yla Ã¶ÄŸrenebilirler.
- GÃ¶rÃ¼lmemiÅŸ Ã§Ä±ktÄ±lar iÃ§in sonuÃ§ (bilgi) Ã¼retebilirler. GÃ¶zetimsiz Ã¶ÄŸrenim sÃ¶z konusudur.
- Ã–rÃ¼ntÃ¼ tanÄ±ma ve sÄ±nÄ±flandÄ±rma yapabilirler. Eksik Ã¶rÃ¼ntÃ¼leri tamamlayabilirler.
- Hata toleransÄ±na sahiptirler. Eksik veya belirsiz bilgiyle Ã§alÄ±ÅŸabilirler. HatalÄ± durumlarda dereceli bozulma (graceful degradation) gÃ¶sterirler.
- Paralel Ã§alÄ±ÅŸabilmekte ve gerÃ§ek zamanlÄ± bilgiyi iÅŸleyebilmektedirler.

### Yapay Sinir AÄŸlarÄ±nÄ±n SÄ±nÄ±flandÄ±rÄ±lmasÄ±

#### Tek KatmanlÄ± Yapay Sinir AÄŸlarÄ±
Tek katmanlÄ± yapay sinir aÄŸlarÄ± sadece girdi ve Ã§Ä±ktÄ± katmanlarÄ±ndan oluÅŸur. Ã‡Ä±ktÄ± Ã¼niteleri bÃ¼tÃ¼n girdi Ã¼nitelerine (X) baÄŸlanmaktadÄ±r ve her baÄŸlantÄ±nÄ±n bir aÄŸÄ±rlÄ±ÄŸÄ± (W) vardÄ±r. 

#### Ã‡ok KatmanlÄ± Yapay Sinir AÄŸlarÄ±

DoÄŸrusal olmayan problemlerin Ã§Ã¶zÃ¼mÃ¼ iÃ§in uygun bir aÄŸ yapÄ±sÄ±dÄ±r. Bu sebeple daha karÄ±ÅŸÄ±k problemlerin Ã§Ã¶zÃ¼mÃ¼nde kullanÄ±lÄ±r. KarÄ±ÅŸÄ±k problemlerin modeli olmasÄ± aÄŸÄ±n eÄŸitimini zorlaÅŸtÄ±ran bir yapÄ±ya bÃ¼rÃ¼nmesine sebep olur. Tek katmanlÄ± aÄŸ yapÄ±sÄ±na gÃ¶re daha karmaÅŸÄ±k bir yapÄ±dadÄ±r. Fakat problem Ã§Ã¶zÃ¼mlerinde genellikle Ã§ok katmanlÄ± aÄŸ yapÄ±sÄ± kullanÄ±lÄ±r Ã§Ã¼nkÃ¼ tek katmanlÄ± yapÄ±lara gÃ¶re daha baÅŸarÄ±lÄ± sonuÃ§lar verir. Ã‡ok katmanlÄ± yapay sinir aÄŸlarÄ± modellerinde en az 1 adet gizli katman bulunur.

### Yapay Sinir HÃ¼cresi

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/1200px-Neuron_Hand-tuned.svg.png" />

CanlÄ±lardaki sinir hÃ¼crelerinin biyolojik gÃ¶rÃ¼nÃ¼mÃ¼ yukarÄ±da gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ÅŸekildeki gibidir. Ã‡ekirdeÄŸimiz var ve bir akson boyunca iletim yapÄ±lÄ±yor. Burada Ã§Ä±kÄ±ÅŸ terminallerinde dentrit uclarÄ±ndan elde edilen sensÃ¶r verilerimiz Ã§ekirdekte aÄŸÄ±rlandÄ±rÄ±larak akson boyunca iletiliyor ve baÅŸka sinir hÃ¼cresine baÄŸlanÄ±yor. Bu ÅŸekilde sinirler arasÄ± iletiÅŸim saÄŸlanmÄ±ÅŸ oluyor.

Ä°nsandaki bir sinir hÃ¼cresinin matematiksel modeli ise ÅŸu ÅŸekilde gÃ¶sterilebilir:

<img src="https://mesutpiskin.com/blog/wp-content/uploads/2017/08/ysa_matematiksel_modeli.png" />

Dentrit dediÄŸimiz yollar boyunca aÄŸÄ±rlÄ±klarÄ±mÄ±z mevcut ve bu dentritlere giren bir baÅŸka nÃ¶rondan da gelmiÅŸ olabilecek bir giriÅŸ deÄŸerimiz (x0 ) var. GiriÅŸ deÄŸerimiz ve dentritteki aÄŸÄ±rlÄ±ÄŸÄ±mÄ±z(w0) Ã§arpÄ±ldÄ±ktan sonra( w0x0)  sinir hÃ¼cresine iletilir ve sinir hÃ¼cresinde bu Ã§arpma iÅŸlemi yapÄ±lÄ±yor ve tÃ¼m dentritlerden gelen aÄŸÄ±rlÄ±k ile giriÅŸ Ã§arpÄ±mlarÄ± toplanÄ±r. Yani aÄŸÄ±rlÄ±klÄ± toplama iÅŸlemi yapÄ±lÄ±r. ArdÄ±ndan bir bias(b) ile toplandÄ±ktan sonra aktivasyon fonksiyonu ardÄ±ndan Ã§Ä±kÄ±ÅŸa aktarÄ±lÄ±r. Bu Ã§Ä±kÄ±ÅŸ nihai Ã§Ä±kÄ±ÅŸ olabileceÄŸi gibi bir baÅŸka hÃ¼crenin giriÅŸi olabilir. Matematiksel olarak aÄŸÄ±rlÄ±klar ile giriÅŸler Ã§arpÄ±lÄ±r artÄ± bir bias eklenir. BÃ¶ylelikle basit bir matematiksel model elde edilir.

Yapay Sinir AÄŸlarÄ±nda yapÄ±lan temel iÅŸlem; modelin en iyi skoru vereceÄŸi w(aÄŸÄ±rlÄ±k parametresi) ve b(bias deÄŸeri) parametrelerinin hesabÄ±nÄ± yapmaktÄ±r.                     

Her bir sinir hÃ¼cresi aynÄ± ÅŸekilde hesaplanÄ±r ve bunlar birbirine seri ya da paralel ÅŸekilde baÄŸlanÄ±r.

Bir yapay sinir hÃ¼cresi beÅŸ bÃ¶lÃ¼mden oluÅŸmaktadÄ±r;

1. **Girdiler:**<br> Girdiler nÃ¶ronlara gelen verilerdir. Bu girdilerden gelen veriler biyolojik sinir hÃ¼crelerinde olduÄŸu gibi toplanmak Ã¼zere nÃ¶ron Ã§ekirdeÄŸine gÃ¶nderilir.

2. **AÄŸÄ±rlÄ±klar:**<br> Yapay sinir hÃ¼cresine gelen bilgiler girdiler Ã¼zerinden Ã§ekirdeÄŸe ulaÅŸmadan Ã¶nce geldikleri baÄŸlantÄ±larÄ±n aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arpÄ±larak Ã§ekirdeÄŸe iletilir. Bu sayede girdilerin Ã¼retilecek Ã§Ä±ktÄ± Ã¼zerindeki etkisi ayarlanabilinmektedir.

3. **Toplama Fonksiyonu (BirleÅŸtirme Fonksiyonu):**<br> Toplama fonksiyonu bir yapay sinir hÃ¼cresine aÄŸÄ±rlÄ±klarla Ã§arpÄ±larak gelen girdileri toplayarak o hÃ¼crenin net girdisini hesaplayan bir fonksiyondur

4. **Aktivasyon fonksiyonu:**<br> Ã–nceki katmandaki tÃ¼m girdilerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± alan ve daha sonra bir Ã§Ä±kÄ±ÅŸ deÄŸeri (tipik olarak doÄŸrusal olmayan) Ã¼reten ve bir sonraki katmana geÃ§iren bir fonksiyondur. (Ã¶rneÄŸin, ReLU veya sigmoid ).

5. **Ã‡Ä±ktÄ±lar:**<br> Aktivasyon fonksiyonundan Ã§Ä±kan deÄŸer hÃ¼crenin Ã§Ä±ktÄ± deÄŸeri olmaktadÄ±r. Her hÃ¼crenin birden fazla girdisi olmasÄ±na raÄŸmen bir tek Ã§Ä±ktÄ±sÄ± olmaktadÄ±r. Bu Ã§Ä±ktÄ± istenilen sayÄ±da hÃ¼creye baÄŸlanabilir.

### Yapay Sinir AÄŸlarÄ±nÄ± BaÄŸlantÄ±larÄ±na GÃ¶re SÄ±nÄ±flandÄ±rma

Yapay sinir aÄŸlarÄ± kendi arasÄ±nda baÄŸlantÄ±lar iÃ§erir. Bunlar ileri beslemeli ve geri beslemeli aÄŸlar olarak sÄ±nÄ±flandÄ±rÄ±lÄ±rlar.

#### Ä°leri Beslemeli AÄŸlar

<img src="https://i.hizliresim.com/qLLIIK.png" />

- Tek yÃ¶nlÃ¼ bilgi akÄ±ÅŸÄ± sÃ¶z konusudur.
- Bu aÄŸ modelinde Girdi tabakasÄ±ndan alÄ±nan bilgiler Gizli katmana iletilir.
- Gizli ve Ã‡Ä±ktÄ± tabakalarÄ±ndan bilginin iÅŸlenmesi ile Ã§Ä±kÄ±ÅŸ deÄŸeri belirlenir.

#### Geri Beslemeli AÄŸlar

<img src="https://www.derinogrenme.com/wp-content/uploads/2017/02/gsa.png"/>

- Bir geri beslemeli sinir aÄŸÄ±, Ã§Ä±kÄ±ÅŸ ve ara katlardaki Ã§Ä±kÄ±ÅŸlarÄ±n, giriÅŸ birimlerine veya Ã¶nceki ara katmanlara geri beslendiÄŸi bir aÄŸ yapÄ±sÄ±dÄ±r. BÃ¶ylece, giriÅŸler hem ileri yÃ¶nde hem de geri yÃ¶nde aktarÄ±lmÄ±ÅŸ olur.
- Bu Ã§eÅŸit YSAâ€™larÄ±n dinamik hafÄ±zalarÄ± vardÄ±r ve bir andaki Ã§Ä±kÄ±ÅŸ hem o andaki hem de Ã¶nceki giriÅŸleri yansÄ±tÄ±r. Bundan dolayÄ±, Ã¶zellikle Ã¶nceden tahmin uygulamalarÄ± iÃ§in uygundurlar.


## Input ve Output DeÄŸeri
```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# deÄŸerleri oluÅŸturma
X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])

# etiketleri oluÅŸturma
y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])

# hadi ÅŸimdi gÃ¶rselleÅŸtirelim
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

YukarÄ±da ki modellemede X ve y arasÄ±nda ki matematiksel Ã¶rÃ¼ntÃ¼yÃ¼ hesaplayabilir misiniz?

Ã–rneÄŸin; X'e 40 deÄŸerini verirsek y deÄŸeri ne olur ? Ya da y deÄŸerini 30 yapan X deÄŸeri nedir?

Bunu neden elle (klasik) hesaplayalÄ±m. Bu sadece 2 deÄŸiÅŸkeni olan basit bir yapÄ±. Ya 100 deÄŸiÅŸkeni olsaydÄ±? O zamanda elle hesaplayabiliriz cÃ¼mlesini kurabilirmiydik? Tabiki de HAYIR. O zaman bunun iÃ§in neden bir sinir aÄŸÄ± eÄŸitmiyoruz? Hadi baÅŸlayalÄ±m...

```python
""" 
Input  : Modele giren verilerimizin ÅŸekli
Output : Modelimizden Ã§Ä±kmasÄ±nÄ± istediÄŸimiz verilerin ÅŸekli 
Bunlar, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z soruna baÄŸlÄ± olarak farklÄ±lÄ±k gÃ¶sterecektir.
Sinir aÄŸlarÄ± tensor (veya dizi) olarak temsilsil edilir.
"""

# Ã–rnek bir tensÃ¶r oluÅŸturalÄ±m
house_info = tf.constant(["bedroom", "bathroom", "garage"])
house_price = tf.constant([939700])
house_info, house_price
```
> (<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,
 <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)

```python
house_info.shape
```
> TensorShape([3])

```python
# YukarÄ±daki Ã¶rneÄŸi numpy kÃ¼tÃ¼phanesi ile yapmÄ±ÅŸtÄ±k. Bunu tensÃ¶r yapÄ±sÄ±na Ã§evirelim
X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])
y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

TensÃ¶rde oluÅŸturmayÄ± hatÄ±rladÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi yukarÄ±da bahsettiÄŸimiz X ve y 
sorununa dair bir sinir aÄŸÄ± eÄŸitelim. 

AmacÄ±mÄ±z kÄ±saca; verilen X deÄŸerine gÃ¶re y deÄŸerini bulmak. Burada input deÄŸerimiz X, output deÄŸerimiz y'dir. 

```python
# Tek bir X Ã¶rneÄŸinin shape deÄŸeri
input_shape = X[0].shape

# Tek bir y Ã¶rneÄŸinin shape deÄŸeri
output_shape = y[0].shape

# bunlarÄ±n ikisi de skalerdir (shape deÄŸeri yoktur)
input_shape, output_shape
```
> (TensorShape([]), TensorShape([]))

Neden input ve output deÄŸerlimizin bir ÅŸekli yok.

Bunun nedeni, modelimize ne tÃ¼r veriler ilettiÄŸimiz Ã¶nemli deÄŸil, her zaman 
input olarak alacak ve output olarak bir tÃ¼r tensÃ¶r olarak geri dÃ¶necektir.

Ancak bizim durumumuzda veri kÃ¼memiz nedeniyle (sadece 2 kÃ¼Ã§Ã¼k sayÄ± listesi), 
Ã¶zel bir tÃ¼r tensÃ¶re bakÄ±yoruz, daha spesifik olarak bir 
rank'Ä± 0 tensÃ¶r veya bir skaler.

```python
X[0], y[0]
```
> (<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,
 <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)
 
- X[0] = -7.0
- y[0] = 3.0
Bir y deÄŸerini tahmin etmek iÃ§in bir X deÄŸeri kullanÄ±yoruz. Bu bizim modelimizin en basit denklemi. 

Burada anlatmak istediÄŸim nokta; bir input deÄŸeri ile output deÄŸeri kullanmaktÄ±r. Klasik programlama da bir input ve bir fonksiyon kullanarak bir output deÄŸeri elde edersiniz. Bizim sinir aÄŸlarÄ±nda (yada ML) yapmak istediÄŸimiz ÅŸey; bir input ve bir output deÄŸeri vererek arada ki fonksiyonunu kendi Ã¼retmesini istiyoruz.

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png" />

*Konut fiyatlarÄ±nÄ± tahmin etmek iÃ§in bir makine Ã¶ÄŸrenimi algoritmasÄ± oluÅŸturmaya Ã§alÄ±ÅŸÄ±yorsanÄ±z, girdileriniz yatak odasÄ± sayÄ±sÄ±, banyo sayÄ±sÄ± ve garaj sayÄ±sÄ± olabilir ve size 3 (3 farklÄ± Ã¶zellik) girdi ÅŸekli verir. Ve evin fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in Ã§Ä±ktÄ± ÅŸekliniz 1 olur.*

## Modellemedeki AdÄ±mlar

ArtÄ±k elimizde hangi verilere, girdi ve Ã§Ä±ktÄ± ÅŸekillerine sahip olduÄŸumuzu biliyoruz, onu modellemek iÃ§in nasÄ±l bir sinir aÄŸÄ± kuracaÄŸÄ±mÄ±za bakalÄ±m.

TensorFlow'da bir model oluÅŸturmak ve eÄŸitmek iÃ§in tipik olarak 3 temel adÄ±m vardÄ±r.

- **Bir model oluÅŸturma**<br>
Bir sinir aÄŸÄ±nÄ±n katmanlarÄ±nÄ± kendiniz bir araya getirin ([Functional](https://www.tensorflow.org/guide/keras/functional) veya [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'yi kullanarak) veya Ã¶nceden oluÅŸturulmuÅŸ bir modeli iÃ§e aktarÄ±n (transfer learning olarak bilinir). 
- **Model derleme**<br>
Bir model performansÄ±nÄ±n nasÄ±l Ã¶lÃ§Ã¼leceÄŸini (kayÄ±p metrikler) tanÄ±mlamanÄ±n yanÄ± sÄ±ra nasÄ±l iyileÅŸtirileceÄŸini (optimize) tanÄ±mlama. 
- **Model uydurma**<br>
Modelin verilerdeki kalÄ±plarÄ± bulmaya Ã§alÄ±ÅŸmasÄ±na izin vermek (X, y'ye nasÄ±l ulaÅŸÄ±r). 

Regresyon verilerimiz iÃ§in bir model oluÅŸturmak Ã¼zere [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'sini kullanarak bunlarÄ± Ã§alÄ±ÅŸÄ±rken gÃ¶relim. Ve sonra her birinin Ã¼zerinden geÃ§eceÄŸiz.

```python
"""
Biz her modeli Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda model, belirli bir metolojide Ã§alÄ±ÅŸacak.
Ama burada ÅŸu sÄ±kÄ±ntÄ± var: Modeli her run ettiÄŸimizde farklÄ± bir sonuÃ§ alacaÄŸÄ±z.
Ä°ÅŸte burada tf.random.set_seed(number) kullanarak o rastgeleliÄŸi belirli bir
yolla baÄŸlamÄ±ÅŸ oluyoruz. Bu sayede her run ettiÄŸimizde aynÄ± sonucu alacaÄŸÄ±z.
"""
tf.random.set_seed(42)

# Sequential API'yi kullanarak bir model oluÅŸturun
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# Modeli derleme
model.compile(loss=tf.keras.losses.mae, # mean absolute error
              optimizer=tf.keras.optimizers.SGD(), # stochastic gradient descent
              metrics=["mae"])

# modeli fit etme
model.fit(X, y, epochs=5)
```

Ä°ÅŸte bu kadar basit :) 

X'e baÄŸlÄ± bir y deÄŸeri oluÅŸturan bir modeli geliÅŸtirdik.

```python
# X ve y deÄŸerlerini kontrol edelim
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)

```python
# Var olan bir X deÄŸeri ile modelimiz doÄŸru bir y deÄŸeri Ã¼retecek mi?
model.predict([8.0])
```
Ama ama bu niye bÃ¶yle oldu :(  Her ÅŸeyi doÄŸru yaptÄ±k gibi. Modele bir input ve output deÄŸeri verdik. Bunu bir sinir aÄŸÄ±na baÄŸladÄ±k. Fakat doÄŸru sonuÃ§la alakasÄ± bile olmayan bir output deÄŸeri verdi bize. 

> Bu soruya cevap vermeden Ã¶nce size kÄ±sa bir soru sormak istiyorum. TensorFlow iÃ§erisinde hep Keras dediÄŸimiz yapÄ±larÄ± gÃ¶rÃ¼yoruz. Bu keras nedir? [Cevap](https://i.ibb.co/LNScsJd/cevap1.png)


## Bir Model GeliÅŸtirmek

Model istediÄŸimiz sonucu vermeyi bÄ±rakÄ±n, yakÄ±nÄ±na dahi yanaÅŸamadÄ±. Peki burada Ã§Ã¶zÃ¼m ne?

DoÄŸru tahmin ettiniz. Fine tuning yani ince ayar yapmak. Modeli geliÅŸtirmek iÃ§in hangi adÄ±mlarÄ± uyguladÄ±k:

1. **Model oluÅŸturma**<br>
Burada daha fazla katman eklemek, her katmandaki gizli birimlerin (nÃ¶ronlar olarak da adlandÄ±rÄ±lÄ±r) sayÄ±sÄ±nÄ± artÄ±rmak, her katmanÄ±n etkinleÅŸtirme iÅŸlevlerini deÄŸiÅŸtirmek isteyebilirsiniz.
2. **Model derleme**<br>
Optimizasyon fonksiyonunu seÃ§mek veya belki de optimizasyon fonksiyonunun Ã¶ÄŸrenme oranÄ±nÄ± deÄŸiÅŸtirmek isteyebilirsiniz.
3. **Modeli fit etme**<br>
Daha fazla epoch veya daha fazla veri ile daha iyi sonuÃ§lar almak isteyebilirsiniz.

Vay. Az Ã¶nce bir dizi olasÄ± adÄ±mÄ± tanÄ±ttÄ±k. HatÄ±rlanmasÄ± gereken Ã¶nemli ÅŸey, bunlarÄ±n her birini nasÄ±l deÄŸiÅŸtireceÄŸiniz, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z soruna baÄŸlÄ± olacaktÄ±r.

```python
# yukarÄ±da bu yapÄ±yÄ± ayrÄ±ntÄ±sÄ±yla anlattÄ±m
tf.random.set_seed(42)

# bir Ã¶nceki modelin aynÄ±sÄ±nÄ± uygulayalÄ±m
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli aynÄ± ÅŸekilde derleyelim
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# ÅŸimdi fit edelim, ama bu sefer 100 epoch kullanarak
model.fit(X, y, epochs=100)
```
YukarÄ± da ki kod bloÄŸunu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda MAE deÄŸerinin yani kayÄ±p fonksiyonun adÄ±m adÄ±m dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶zlemleyeceksiniz. Ä°ÅŸte bu anda geriye yaslanÄ±p iÅŸlemin bitmesini bekleyebilirsiniz Ã§Ã¼nkÃ¼ bu doÄŸru gittiÄŸinizi gÃ¶steriyor.

YukarÄ±da 5 epoch ile eÄŸittimizde hiÃ§ gÃ¼zel bir tahmin deÄŸeri almadÄ±k. Peki ya ÅŸimdi?

```python
model.predict([8.0])
```
Ä°ÅŸte buuu ğŸ’ª 0.33 lÃ¼k bir sapma var ama modelimiz resmen input ve output deÄŸerlerini ile doÄŸru eÄŸitilmiÅŸ.

Åimdi de modelimizde olmayan bir sayÄ± ile deneme yapalÄ±m. 
Modelimize tekrar gÃ¶z atalÄ±m. Test etmek iÃ§in arada ki baÄŸlantÄ±yÄ± bulmamÄ±z gerekiyor.
```python
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)
 
- -7 --> 3
- -4 --> 6
- -1 --> 9

YukarÄ±da ki eÅŸitliklere baktÄ±ÄŸÄ±mÄ±zda x + 10 = y gibi bir eÅŸitiÄŸin olduÄŸunu hemen anlayabiliriz. Denklemi Ã§Ä±kardÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi dizide olmayan bir sayÄ±da nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶zlemleyebiliriz.

```python
model.predict([20]) # cevabÄ±n 20+10= 30 olmasÄ±nÄ± bekliyoruz
```
HÄ±mm. YaklaÅŸÄ±k bir sonuÃ§ ama tam da istediÄŸimiz bir cevap deÄŸil. Modelimizi bir deÄŸerlendirelim daha sonra nasÄ±l daha iyi sonuÃ§ alacaÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rÃ¼z.
 
 
## Modeli DeÄŸerlendirme

Sinir aÄŸÄ± oluÅŸtururken takip edilen tipik bir akÄ±ÅŸ var:
```
Bir model yarat -> Onu deÄŸerlendir -> Bir model yarat -> Onu deÄŸerlendir -> Bir model yarat -> Onu deÄŸerlendir ...
```
Fine tuning (ince ayarlama), sÄ±fÄ±rdan bir model oluÅŸturmak deÄŸil, mevcut bir model Ã¼zerinde ayarlamalar yapmaktÄ±r.

Modeli deÄŸerlendirirken yapÄ±lacak en gÃ¼zel davranÄ±ÅŸlardan bazÄ±larÄ± ÅŸunlardÄ±r:
- GÃ¶rselleÅŸtirin
- GÃ¶rselleÅŸtirin
- GÃ¶rselleÅŸtirin

LÃ¼tfen modeli gÃ¶rselleÅŸtirin. GÃ¶rselleÅŸtirmeniz gereken bazÄ± fikirler:
- Veriler - hangi verilerle Ã§alÄ±ÅŸÄ±yorsunuz? NasÄ±l gÃ¶rÃ¼nÃ¼yor?
- Modelin kendisi - mimari neye benziyor? FarklÄ± ÅŸekiller nelerdir?
- Bir modelin eÄŸitimi - bir model Ã¶ÄŸrenirken nasÄ±l performans gÃ¶sterir?
- Bir modelin tahminleri - bir modelin tahminleri temel gerÃ§eÄŸe (orijinal etiketler) karÅŸÄ± nasÄ±l sÄ±ralanÄ±r?

GÃ¶rselleÅŸtirmeyi 1 adÄ±m sonraya erteliyoruz Ã§Ã¼nkÃ¼ yukarÄ±da eÄŸittiÄŸimiz model tam da istediÄŸimiz sonucu vermedi. Bu yÃ¼zden yukarÄ±da ki modeli daha fazla veri ile tekrar eÄŸitmek iyi olabilir.

```python
# Daha bÃ¼yÃ¼k bir veriseti yaratma
X = np.arange(-100, 100, 4)
X
```
> array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,
        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,
        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,
         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,
         76,   80,   84,   88,   92,   96])

```python
# ÅŸimdi de etiketlerini oluÅŸturalÄ±m
y = np.arange(-90, 110, 4)
y
```
> array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,
       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,
        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,
        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])

`x + 10 = y` eÅŸitliÄŸi saÄŸladÄ±k gibi duruyor. 

### Verileri Train ve Test Olarak AyÄ±rma

Bir makine Ã¶ÄŸrenimi projesindeki diÄŸer en yaygÄ±n ve Ã¶nemli adÄ±mlardan biri, bir eÄŸitim ve test seti (ve gerektiÄŸinde bir doÄŸrulama seti) oluÅŸturmaktÄ±r.

Her set belirli bir amaca hizmet eder:

- **EÄŸitim seti**<br>
Model, genellikle mevcut toplam verilerin (epoch boyunca Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z ders materyalleri gibi) %70-80'i olan bu verilerden Ã¶ÄŸrenir.
- **DoÄŸrulama seti**<br> 
Model, genellikle mevcut toplam verilerin %10-15'i olan bu verilere gÃ¶re ayarlanÄ±r (final sÄ±navÄ±ndan Ã¶nce girdiÄŸiniz alÄ±ÅŸtÄ±rma sÄ±navÄ± gibi).
- **Test seti**<br>
Model, Ã¶ÄŸrendiklerini test etmek iÃ§in bu veriler Ã¼zerinde deÄŸerlendirilir, genellikle mevcut toplam verilerin %10-15'i kadardÄ±r (dÃ¶nem sonunda girdiÄŸiniz final sÄ±navÄ± gibi).

Åimdilik sadece bir eÄŸitim ve test seti kullanacaÄŸÄ±z, bu, modelimizin Ã¶ÄŸrenilmesi ve deÄŸerlendirilmesi iÃ§in bir veri setimiz olacaÄŸÄ± anlamÄ±na geliyor.

X ve y dizilerimizi bÃ¶lerek bunlarÄ± oluÅŸturabiliriz.

> ğŸ”‘ Not: GerÃ§ek dÃ¼nya verileriyle uÄŸraÅŸÄ±rken, bu adÄ±m tipik olarak bir projenin hemen baÅŸlangÄ±cÄ±nda yapÄ±lÄ±r (test seti her zaman diÄŸer tÃ¼m verilerden ayrÄ± tutulmalÄ±dÄ±r). Modelimizin eÄŸitim verilerini Ã¶ÄŸrenmesini ve ardÄ±ndan gÃ¶rÃ¼nmeyen Ã¶rneklere ne kadar iyi genelleÅŸtiÄŸine dair bir gÃ¶sterge elde etmek iÃ§in test verileri Ã¼zerinde deÄŸerlendirmesini istiyoruz.

```python
# verisetimizin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne bakalÄ±m
len(X)
```
> 50


```python
# verileri train ve test olarak ayÄ±ralÄ±m
X_train = X[:40] # verilerin %80'ine denk geliyor
y_train = y[:40]

X_test = X[40:]
y_test = y[40:]

len(X_train), len(X_test)
```
> (40, 10)


### Verileri GÃ¶rselleÅŸtirme

ArtÄ±k eÄŸitim ve test verilerimiz var, artÄ±k bunu gÃ¶rselleÅŸtirmek iyi bir fikir.

Neyin ne olduÄŸunu ayÄ±rt etmek iÃ§in gÃ¼zel renklerle Ã§izelim.

```python
plt.figure(figsize=(10, 7))
# train verileri mavi olsun
plt.scatter(X_train, y_train, c='b', label='Training data')
# test verileri yeÅŸil olsun
plt.scatter(X_test, y_test, c='g', label='Testing data')
plt.legend();
```
> <img src="https://i.ibb.co/xDL5jBD/indir.png" />

GÃ¼zel! Verilerinizi, modelinizi, herhangi bir ÅŸeyi gÃ¶rselleÅŸtirebildiÄŸiniz her an, bu iyi bir fikirdir.

Bu grafiÄŸi gÃ¶z Ã¶nÃ¼nde bulundurarak, yeÅŸil noktalarÄ± (X_test) Ã§izmek iÃ§in mavi noktalardaki (X_train) deseni Ã¶ÄŸrenen bir model oluÅŸturmaya Ã§alÄ±ÅŸacaÄŸÄ±z.

```python
tf.random.set_seed(42)

# bir model yaratma
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli derleme
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# modeli fit etme
# model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)
```

### Modeli GÃ¶rselleÅŸtirme

Bir model oluÅŸturduktan sonra, ona bir gÃ¶z atmak isteyebilirsiniz (Ã¶zellikle daha Ã¶nce Ã§ok model oluÅŸturmadÄ±ysanÄ±z).

Modelinizin katmanlarÄ±nÄ± ve ÅŸekillerini, Ã¼zerinde Summary()'i arayarak inceleyebilirsiniz.

ğŸ”‘ Not: Bir modeli gÃ¶rselleÅŸtirmek, Ã¶zellikle girdi ve Ã§Ä±ktÄ± ÅŸekli uyumsuzluklarÄ±yla karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda faydalÄ±dÄ±r.

```python
# Ã§alÄ±ÅŸmayacak (modeli fit etmedik)
model.summary()
```
> ValueError

Sizce yukarÄ±da ki hatanÄ±n sebebi modeli fit etmememiz mi? HÄ±mm. Hata mesajÄ±nÄ± okuduÄŸumuzda `input_shape` deÄŸerinin olmadÄ±ÄŸÄ±nÄ± sÃ¶ylÃ¼yor. 

`Input_shape` deÄŸeri ilk katmana girilir. Åimdi deneyelim ve bakalÄ±m hata gideriliyor mu?


```python
tf.random.set_seed(42)

# bir model yaratma
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1, input_shape=[1])
])

# modeli derleme
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# modeli fit etme
# model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)
```

```python
model.summary()
```
> <img src="https://i.ibb.co/8cZRccR/Ekran-g-r-nt-s-2021-07-04-120440.png" />

Modelimizde `summary()` iÅŸlevini Ã§aÄŸÄ±rmak bize iÃ§erdiÄŸi katmanlarÄ±, Ã§Ä±ktÄ± ÅŸeklini ve parametre sayÄ±sÄ±nÄ± gÃ¶sterir.

- **Toplam parametreler**<br>
Modeldeki toplam parametre sayÄ±sÄ±.
- **EÄŸitilebilir parametreler**<br>
Bunlar, modelin eÄŸitirken gÃ¼ncelleyebileceÄŸi parametrelerdir (kalÄ±plardÄ±r).
- **EÄŸitilemez parametreler**<br>
Bu parametreler eÄŸitim sÄ±rasÄ±nda gÃ¼ncellenmez (bu, transfer learninig sÄ±rasÄ±nda diÄŸer modellerden Ã¶nceden Ã¶ÄŸrenilmiÅŸ kalÄ±plarÄ± getirdiÄŸinizde tipiktir).

> ğŸ“– Kaynak: Bir katmandaki eÄŸitilebilir parametrelere daha derinlemesine bir genel bakÄ±ÅŸ iÃ§in [MIT'nin derin Ã¶ÄŸrenme videosuna](https://www.youtube.com/watch?v=njKP3FqW3Sk) giriÅŸine gÃ¶z atÄ±n.

> ğŸ›  AlÄ±ÅŸtÄ±rma: Dense katmandaki gizli birimlerin sayÄ±sÄ±yla oynamayÄ± deneyin (Ã¶rn. `Dense(2)`, `Dense(3)`). Bu, Toplam/EÄŸitilebilir parametreleri nasÄ±l deÄŸiÅŸtirir? DeÄŸiÅŸikliÄŸe neyin sebep olduÄŸunu araÅŸtÄ±rÄ±n.

Åimdilik, bu parametreler hakkÄ±nda dÃ¼ÅŸÃ¼nmeniz gereken tek ÅŸey, bunlarÄ±n verilerdeki Ã¶ÄŸrenilebilir kalÄ±plarÄ±dÄ±r.

Modelimizi eÄŸitim verileriyle fir edelim ÅŸimdi.


```python
# modeli eÄŸitim verileriyle fit etme
model.fit(X_train, y_train, epochs=100, verbose=0)
```

Ã–zetin yanÄ± sÄ±ra plot_model() kullanarak modelin 2D grafiÄŸini de gÃ¶rÃ¼ntÃ¼leyebilirsiniz.

```python
from tensorflow.keras.utils import plot_model

plot_model(model, show_shapes=True)
```
> <img src="https://i.ibb.co/8cZRccR/Ekran-g-r-nt-s-2021-07-04-120440.png" />

Bizim durumumuzda, kullandÄ±ÄŸÄ±mÄ±z modelin yalnÄ±zca bir girdisi ve bir Ã§Ä±ktÄ±sÄ± var, ancak daha karmaÅŸÄ±k modelleri gÃ¶rselleÅŸtirmek hata ayÄ±klama iÃ§in Ã§ok yardÄ±mcÄ± olabilir.

### Tahminleri GÃ¶rselleÅŸtirme

Åimdi eÄŸitilmiÅŸ bir modelimiz var, hadi bazÄ± tahminleri gÃ¶rselleÅŸtirelim.

Tahminleri gÃ¶rselleÅŸtirmek iÃ§in, onlarÄ± temel gerÃ§ek etiketlerine gÃ¶re planlamak her zaman iyi bir fikirdir.

Bunu genellikle y_test ve y_pred (gerÃ§ek ve tahminler) ÅŸeklinde gÃ¶rÃ¼rsÃ¼nÃ¼z.

Ä°lk olarak, test verileri (X_test) Ã¼zerinde bazÄ± tahminler yapacaÄŸÄ±z, modelin test verilerini hiÃ§ gÃ¶rmediÄŸini unutmayÄ±n.


```python
# modeli predict edelim (X_test verileri ile)
y_preds = model.predict(X_test)

# tahminleri gÃ¶relim
y_preds
```
> array([[53.57109 ],
       [57.05633 ],
       [60.541573],
       [64.02681 ],
       [67.512054],
       [70.99729 ],
       [74.48254 ],
       [77.96777 ],
       [81.45301 ],
       [84.938255]], dtype=float32)

BunlarÄ± gerÃ§ek deÄŸerler ile karÅŸÄ±laÅŸtÄ±rÄ±p modelin doÄŸruluÄŸunu anlamak iÃ§in bir fonksiyon yaratalÄ±m:

```python
def plot_predictions(train_data=X_train, 
                     train_labels=y_train, 
                     test_data=X_test, 
                     test_labels=y_test, 
                     predictions=y_preds):
  """
  EÄŸitim verilerini, test verilerini gÃ¶rselleÅŸtirir ve tahminleri karÅŸÄ±laÅŸtÄ±rÄ±r.
  """
  plt.figure(figsize=(10, 7))
  # train verileri mavi olsun
  plt.scatter(train_data, train_labels, c="b", label="Training data")
  # test verileri yeÅŸil olsun
  plt.scatter(test_data, test_labels, c="g", label="Testing data")
  # tahmin deÄŸerleri kÄ±rmÄ±zÄ± olsun
  plt.scatter(test_data, predictions, c="r", label="Predictions")
  plt.legend();
  
plot_predictions(train_data=X_train,
                 train_labels=y_train,
                 test_data=X_test,
                 test_labels=y_test,
                 predictions=y_preds)
```
> <img src="https://i.ibb.co/Vv70dWN/indir-2.png" />

### Tahminleri DeÄŸerlendirme

GÃ¶rselleÅŸtirmelerin yanÄ± sÄ±ra deÄŸerlendirme metrikleri, modelinizi deÄŸerlendirmek iÃ§in alternatif en iyi seÃ§eneÄŸinizdir.

Ãœzerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z soruna baÄŸlÄ± olarak, farklÄ± modellerin farklÄ± deÄŸerlendirme Ã¶lÃ§Ã¼tleri vardÄ±r.

Regresyon problemleri iÃ§in kullanÄ±lan ana metriklerden ikisi ÅŸunlardÄ±r:

- **Mean absolute error (MAE)**<br>
Tahminlerin her biri arasÄ±ndaki ortalama fark.
- **Mean squared error (MSE)**<br>
Tahminler arasÄ±ndaki kare ortalama fark.

Bu deÄŸerlerin her biri ne kadar dÃ¼ÅŸÃ¼kse, o kadar iyidir.

AyrÄ±ca, derleme adÄ±mÄ± sÄ±rasÄ±nda herhangi bir Ã¶lÃ§Ã¼m ayarÄ±nÄ±n yanÄ± sÄ±ra modelin kaybÄ±nÄ± dÃ¶ndÃ¼recek olan `model.evaluate()` Ã¶ÄŸesini de kullanabilirsiniz.

```python
model.evaluate(X_test, y_test)
```
> [18.74532699584961, 18.74532699584961]

Biz MAE(`metrics=['MAE']`) deÄŸerini kullandÄ±ÄŸÄ±mÄ±z iÃ§in evaluate fonksiyonu bize MAE deÄŸerini dÃ¶ndÃ¼recektir.

TensorFlow'da ayrÄ±ca MSE ve MAE iÃ§in ayrÄ± olarak fonksiyonlar vardÄ±r. Bunlar deÄŸerlendirme iÃ§in ayrÄ±ca kullanÄ±labilir.


```python
# MAE deÄŸerini fonksiyon ile hesaplama
mae = tf.metrics.mean_absolute_error(y_true=y_test, 
                                     y_pred=y_preds)
mae
```
> <tf.Tensor: shape=(10,), dtype=float32, numpy=
array([34.42891 , 30.943668, 27.45843 , 23.97319 , 20.487946, 17.202168,
       14.510478, 12.419336, 11.018796, 10.212349], dtype=float32)>

Aaa. Neden bir Ã§Ä±ktÄ± yerine on farklÄ± Ã§Ä±ktÄ± aldÄ±k?

Bunun nedeni, y_test ve y_preds tensorlerinin farklÄ± ÅŸekillerde olmasÄ±ndan kaynaklanÄ±yor.

```python
# y etiket tensorÃ¼nÃ¼ kontrol edelim
y_test
```
> array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])

```python
# tahminleri kontrol edelim
y_preds
```
> array([[53.57109 ],
       [57.05633 ],
       [60.541573],
       [64.02681 ],
       [67.512054],
       [70.99729 ],
       [74.48254 ],
       [77.96777 ],
       [81.45301 ],
       [84.938255]], dtype=float32)

```python
# tesorlerin ÅŸekillerini kontrol edelim
y_test.shape, y_preds.shape
```
> ((10,), (10, 1))

HatÄ±rlarsanÄ±z en baÅŸta Input ve Outpu deÄŸerlerini konuÅŸmuÅŸduk. Ve o sorun geldi Ã§attÄ±. Bu deÄŸerlerin aynÄ± ÅŸekillere sahip olmasoÄ± gerekiyor yoksa deÄŸerlendirmemiz imkansÄ±z.

`squeeze()` kullanarak bunu dÃ¼zeltebiliriz, 1 boyutunu y_preds tensÃ¶rÃ¼mÃ¼zden kaldÄ±racak ve onu y_test ile aynÄ± ÅŸekle getirecektir.

```python
# squeeze() kullanmadan Ã¶nce
y_preds.shape
```
> (10, 1)


```python
# squeeze() kullandÄ±ktan sonra
y_preds.squeeze().shape
```
> (10, )

```python
# verilere  ayrÄ±ntÄ±lÄ± bakalÄ±m
y_test, y_preds.squeeze()
```
> (array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106]),
 array([53.57109 , 57.05633 , 60.541573, 64.02681 , 67.512054, 70.99729 ,
        74.48254 , 77.96777 , 81.45301 , 84.938255], dtype=float32))

TamamdÄ±r, ÅŸimdi y_test ve y_preds tensorlerÄ±mÄ±zÄ± nasÄ±l aynÄ± ÅŸekle getireceÄŸimizi biliyoruz, hadi deÄŸerlendirme metriklerimizi kullanalÄ±m.

```python
# MAE deÄŸerini hesaplama
mae = tf.metrics.mean_absolute_error(y_true=y_test, 
                                     y_pred=y_preds.squeeze())

# MSE deÄŸerini hesaplama
mse = tf.metrics.mean_squared_error(y_true=y_test,
                                    y_pred=y_preds.squeeze())
mse, mae
```
> (<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>, <tf.Tensor: shape=(), dtype=float32, numpy=353.57336> )

MAE'yi saf TensorFlow iÅŸlevlerini kullanarak da hesaplayabiliriz.

```python
tf.reduce_mean(tf.abs(y_test-y_preds.squeeze()))
```
> <tf.Tensor: shape=(), dtype=float64, numpy=18.745327377319335>

Yine, tekrar kullanabileceÄŸinizi (veya kendinizi tekrar tekrar kullanÄ±rken bulabileceÄŸinizi) dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z herhangi bir ÅŸeyi iÅŸlevsel hale getirmek iyi bir fikirdir.

DeÄŸerlendirme metriklerimiz iÃ§in fonksiyonlar yaratalÄ±m

```python
def mae(y_test, y_pred):
  """
  y_test ve y_preds arasÄ±ndaki ortalama mutlak hatayÄ± hesaplar.
  """
  return tf.metrics.mean_absolute_error(y_test,
                                        y_pred)
  
def mse(y_test, y_pred):
  """
  y_test ve y_preds arasÄ±ndaki ortalama karesel hatayÄ± hesaplar
  """
  return tf.metrics.mean_squared_error(y_test,
                                       y_pred)
```

### Bir Modeli GeliÅŸtirmek Ä°Ã§in Denemeler Yapmak

DeÄŸerlendirme metriklerini ve modelinizin yaptÄ±ÄŸÄ± tahminleri gÃ¶rdÃ¼kten sonra, muhtemelen modeli geliÅŸtirmek isteyeceksiniz.

Yine, bunu yapmanÄ±n birÃ§ok farklÄ± yolu vardÄ±r, ancak bunlardan baÅŸlÄ±ca 3 tanesi ÅŸunlardÄ±r:

- **Daha fazla veri elde edin**<br>
Modeliniz iÃ§in daha fazla Ã¶rnek alÄ±n (kalÄ±plarÄ± Ã¶ÄŸrenmek iÃ§in daha fazla fÄ±rsat).
- **Modelinizi bÃ¼yÃ¼tÃ¼n (daha karmaÅŸÄ±k bir model kullanÄ±n)**<br>
Bu, her katmanda daha fazla katman veya daha fazla gizli birim ÅŸeklinde olabilir.
- **Daha uzun sÃ¼re eÄŸitin**<br>
Modelinize verilerdeki kalÄ±plarÄ± bulma ÅŸansÄ± verin.

Veri kÃ¼memizi oluÅŸturduÄŸumuzdan, kolayca daha fazla veri Ã¼retebiliyorduk, ancak gerÃ§ek dÃ¼nya veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken durum her zaman bÃ¶yle olmuyor.

Åimdi 2 ve 3'Ã¼ kullanarak modelimizi nasÄ±l geliÅŸtirebileceÄŸimize bir gÃ¶z atalÄ±m.

Bunu yapmak iÃ§in 3 model oluÅŸturacaÄŸÄ±z ve sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z:

- `model_1` - orijinal modelle aynÄ±, 1 katman, 100 epoch iÃ§in eÄŸitilmiÅŸ.
- `model_2` - 100 epoch iÃ§in eÄŸitilmiÅŸ 2 katman.
- `model_3` - 500 epoch iÃ§in eÄŸitilmiÅŸ 2 katman.

`Model_1` 


```python
tf.random.set_seed(42)

# Orijinal modeli Ã§oÄŸaltÄ±yoruz
model_1 = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli derleme
model_1.compile(loss=tf.keras.losses.mae,
                optimizer=tf.keras.optimizers.SGD(),
                metrics=['mae'])

# modeli fit etme
model_1.fit(X_train, y_train, epochs=100, verbose=0)
```

```python
# tahminleri model_1 iÃ§in gÃ¶rselleÅŸtirelim
y_preds_1 = model_1.predict(X_test)
plot_predictions(predictions=y_preds_1)
```
> <img src="https://i.ibb.co/Vv70dWN/indir-2.png" />


```python
mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()
mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()
mae_1, mse_1
```
> (18.745327, 353.57336)

`model_2`

Bu sefer ekstra yoÄŸun bir katman ekleyeceÄŸiz (bÃ¶ylece artÄ±k modelimiz 2 katmana sahip olacak), diÄŸer her ÅŸeyi aynÄ± tutacaÄŸÄ±z.

```python
tf.random.set_seed(42)

model_2 = tf.keras.Sequential([
  tf.keras.layers.Dense(1),
  tf.keras.layers.Dense(1) # ikinci katmanÄ± ekliyoruz
])

# modeli derleme
model_2.compile(loss=tf.keras.losses.mae,
                optimizer=tf.keras.optimizers.SGD(),
                metrics=['mae'])

# modeli fit etme
model_2.fit(X_train, y_train, epochs=100, verbose=0)
```

```python
# tahminleri model_2 iÃ§in gÃ¶rselleÅŸtirelim
y_preds_2 = model_2.predict(X_test)
plot_predictions(predictions=y_preds_2)
```
> <img src="https://i.ibb.co/jgMsKNM/3.png" />

Ã‡oook iyi. Tek gereken ÅŸey ekstradan bir katmanmÄ±ÅŸ.

```python
mae_2 = mae(y_test, y_preds_2.squeeze()).numpy()
mse_2 = mse(y_test, y_preds_2.squeeze()).numpy()
mae_2, mse_2
```
> (1.9098114, 5.459232)


`model_3`

3.modelimiz iÃ§in her ÅŸeyi model_2 ile aynÄ± tutacaÄŸÄ±z, ancak bu sefer daha uzun train edeceÄŸiz (100 yerine 500 epoch).

Bu, modelimize verilerdeki kalÄ±plarÄ± Ã¶ÄŸrenme ÅŸansÄ± verecektir.


```python
tf.random.set_seed(42)

model_3 = tf.keras.Sequential([
  tf.keras.layers.Dense(1),
  tf.keras.layers.Dense(1) 
])

# modeli derleme
model_3.compile(loss=tf.keras.losses.mae,
                optimizer=tf.keras.optimizers.SGD(),
                metrics=['mae'])

# modeli fit etme (100 yerine 500 epoch)
model_3.fit(X_train, y_train, epochs=500, verbose=0)
```

Modeli gÃ¶rselleÅŸtirmeden Ã¶nce epoch terimini anlatmadÄ±ÄŸÄ±mÄ± fark ettim. Åuan Ã§okca kullanÄ±yoruz ve bilmemeniz neden sonucun deÄŸiÅŸtiÄŸini anlamanÄ±zÄ± zorlaÅŸtÄ±rabilir.

> KÄ±saca epoch, eÄŸitim sÄ±rasÄ±nda tÃ¼m eÄŸitim verilerinin aÄŸa gÃ¶sterilme sayÄ±sÄ±dÄ±r. Daha fazla ayrÄ±ntÄ± iÃ§in [bu yazÄ±yÄ±](https://medium.com/deep-learning-turkiye/derin-ogrenme-uygulamalarinda-en-sik-kullanilan-hiper-parametreler-ece8e9125c4) okuyabilirsiniz.


```python
# tahminleri model_3 iÃ§in gÃ¶rselleÅŸtirelim
y_preds_3 = model_3.predict(X_test)
plot_predictions(predictions=y_preds_3)
```
> <img src="https://i.ibb.co/dLfmNb2/4.png" />

Amaa daha iyi olmasÄ± gerekmiyor muydu modelin?

GÃ¶rÃ¼nen o ki, modelimiz Ã§ok uzun sÃ¼re eÄŸitilmiÅŸ ve bu nedenle daha kÃ¶tÃ¼ sonuÃ§lara yol aÃ§mÄ±ÅŸ olabilir (daha sonra eÄŸitimi Ã§ok uzun sÃ¼re engellemenin yollarÄ±nÄ± gÃ¶receÄŸiz).

```python
mae_3 = mae(y_test, y_preds_3.squeeze()).numpy()
mse_3 = mse(y_test, y_preds_3.squeeze()).numpy()
mae_3, mse_3
```
> (68.68786, 4804.4717)

### SonuÃ§larÄ± KarÅŸÄ±laÅŸtÄ±rma


```python
model_results = [["model_1", mae_1, mse_1],
                 ["model_2", mae_2, mse_2],
                 ["model_3", mae_3, mse_3]]
```

```python
import pandas as pd
all_results = pd.DataFrame(model_results, columns=["model", "mae", "mse"])
all_results
```
> <img src="https://i.ibb.co/bPDFRbf/5.png" />

En iyi performansÄ± `model_2` gÃ¶steriyor.

Ve ÅŸimdi, "modelleri karÅŸÄ±laÅŸtÄ±rmak sÄ±kÄ±cÄ±..." diye dÃ¼ÅŸÃ¼nebilirsiniz ama burada sadece 3 modeli karÅŸÄ±laÅŸtÄ±rdÄ±k.

Ancak bu, birÃ§ok farklÄ± model kombinasyonunu denemek ve hangisinin en iyi performansÄ± gÃ¶sterdiÄŸini gÃ¶rmek, makine Ã¶ÄŸrenimi modellemesinin neyle ilgili olduÄŸunun bir parÃ§asÄ±dÄ±r.

OluÅŸturduÄŸunuz her model kÃ¼Ã§Ã¼k bir deneydir.

> ğŸ”‘ Not: Ana hedeflerinizden biri, deneyleriniz arasÄ±ndaki sÃ¼reyi en aza indirmek olmalÄ±dÄ±r. Ne kadar Ã§ok deney yaparsanÄ±z, hangilerinin iÅŸe yaramadÄ±ÄŸÄ±nÄ± o kadar Ã§ok anlarsÄ±nÄ±z ve sÄ±rayla neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± bulmaya yaklaÅŸÄ±rsÄ±nÄ±z. Makine Ã¶ÄŸrenimi uygulayÄ±cÄ±sÄ±nÄ±n sloganÄ±nÄ± hatÄ±rlayÄ±n: "deney, deney, deney".

AyrÄ±ca bulacaÄŸÄ±nÄ±z baÅŸka bir ÅŸey de iÅŸe yarayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z ÅŸeyin (bir modeli daha uzun sÃ¼re eÄŸitmek gibi) her zaman iÅŸe yaramayabilir ve Ã§oÄŸu zaman tam tersi de geÃ§erlidir.



### Denemelerinizi izleme

Hangisinin diÄŸerlerinden daha iyi performans gÃ¶sterdiÄŸini gÃ¶rmek iÃ§in modelleme deneylerinizi takip etmek, gerÃ§ekten iyi bir alÄ±ÅŸkanlÄ±ktÄ±r.

YukarÄ±da bunun basit bir versiyonunu yaptÄ±k (sonuÃ§larÄ± farklÄ± deÄŸiÅŸkenlerde tutarak).

> ğŸ“– Kaynak: Ancak daha fazla model oluÅŸturduÄŸunuzda, aÅŸaÄŸÄ±daki gibi araÃ§larÄ± kullanmak isteyeceksiniz:

- **[TensorBoard](https://tensorboard.dev/)**
TensorFlow kitaplÄ±ÄŸÄ±nÄ±n modelleme deneylerini izlemeye yardÄ±mcÄ± olan bir bileÅŸeni (bunu daha sonra gÃ¶receÄŸiz).

- **[Weights & Biases](https://wandb.ai/site)**
Her tÃ¼rlÃ¼ makine Ã¶ÄŸrenimi deneyini izlemek iÃ§in bir araÃ§.



## Bir Modeli Kaydetme

Bir modeli eÄŸittiÄŸinizde ve beÄŸeninize uygun bir model bulduÄŸunuzda, muhtemelen onu baÅŸka bir yerde (bir web uygulamasÄ± veya mobil cihaz gibi) kullanmak Ã¼zere kaydetmek isteyeceksiniz.

`model.save()` kullanarak bir TensorFlow/Keras modelini kaydedebilirsiniz.

TensorFlow'da bir modeli kaydetmenin iki yolu vardÄ±r:

- [SavedModel](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) biÃ§imi (varsayÄ±lan).
- [HDF5](https://www.tensorflow.org/tutorials/keras/save_and_load#hdf5_format) formatÄ±.

Ä°kisi arasÄ±ndaki temel fark, SavedModel'in, modeli tekrar yÃ¼klerken ek deÄŸiÅŸiklikler yapmadan Ã¶zel nesneleri (Ã¶zel katmanlar gibi) otomatik olarak kaydedebilmesidir.

Hangisini kullanmalÄ±sÄ±nÄ±z?

Durumunuza baÄŸlÄ±dÄ±r ancak SavedModel formatÄ± Ã§oÄŸu zaman yeterli olacaktÄ±r.

Her iki yÃ¶ntem de aynÄ± yÃ¶ntem Ã§aÄŸrÄ±sÄ±nÄ± kullanÄ±r.

```python
# SavedModel formatÄ±nÄ± kullanarak bir modeli kaydedin
model_2.save('best_model_SavedModel_format')

# Kontrol et - diÄŸer dosyalarÄ±n yanÄ± sÄ±ra bir protobuf ikili dosyasÄ± (.pb) verir
!ls best_model_SavedModel_format
```
> assets	keras_metadata.pb  saved_model.pb  variables

Åimdi modeli HDF5 formatÄ±nda kaydedelim, aynÄ± yÃ¶ntemi kullanacaÄŸÄ±z ama farklÄ± bir dosya adÄ±yla.

```python
# HDF5 formatÄ±nÄ± kullanarak bir modeli kaydedin
model_2.save("best_model_HDF5_format.h5") # sonuna '.h5' eklenmesine dikkat edin

!ls best_model_HDF5_format.h5
```
> best_model_HDF5_format.h5

## Modeli YÃ¼kleme

`load_model()` yÃ¶ntemini kullanarak kaydedilmiÅŸ bir modeli yÃ¼kleyebiliriz.

FarklÄ± biÃ§imler (SavedModel ve HDF5) iÃ§in bir model yÃ¼klemek aynÄ±dÄ±r (belirli biÃ§imlerin yol adlarÄ± doÄŸru olduÄŸu sÃ¼rece).


```python
loaded_saved_model = tf.keras.models.load_model("best_model_SavedModel_format")

# model_2'yi SavedModel sÃ¼rÃ¼mÃ¼yle karÅŸÄ±laÅŸtÄ±rÄ±n (True dÃ¶ndÃ¼rmeli)
model_2_preds = model_2.predict(X_test)
saved_model_preds = loaded_saved_model.predict(X_test)
mae(y_test, saved_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()
```
> True

```python
# HDF5 formatÄ±ndan bir model yÃ¼kleyin
loaded_h5_model = tf.keras.models.load_model("best_model_HDF5_format.h5")

# Model_2'yi yÃ¼klÃ¼ HDF5 sÃ¼rÃ¼mÃ¼yle karÅŸÄ±laÅŸtÄ±rÄ±n (True dÃ¶ndÃ¼rmeli)
h5_model_preds = loaded_h5_model.predict(X_test)
mae(y_test, h5_model_preds.squeeze()).numpy() == mae(y_test, model_2_preds.squeeze()).numpy()
```
> true

## Daha BÃ¼yÃ¼k Bir Ã–rnek

Pekala, TensorFlow'da sinir aÄŸÄ± regresyon modelleri oluÅŸturmanÄ±n temellerini gÃ¶rdÃ¼k.

Bir adÄ±m Ã¶teye gidelim ve daha zengin Ã¶zelliklere sahip bir veri iÃ§in bir model oluÅŸturalÄ±m.

Daha spesifik olarak, yaÅŸ, cinsiyet, vÃ¼cut aÄŸÄ±rlÄ±ÄŸÄ±, Ã§ocuklar, sigara iÃ§me durumu ve yerleÅŸim bÃ¶lgesi gibi bir dizi farklÄ± parametreye dayalÄ± olarak bireyler iÃ§in saÄŸlÄ±k sigortasÄ± maliyetini tahmin etmeye Ã§alÄ±ÅŸacaÄŸÄ±z.

Bunu yapmak iÃ§in, Kaggle'da bulunan ve GitHub'da barÄ±ndÄ±rÄ±lan, herkesin kullanÄ±mÄ±na aÃ§Ä±k TÄ±bbi Maliyet veri kÃ¼mesinden yararlanacaÄŸÄ±z.

```python
# Gerekli kitaplÄ±klarÄ± iÃ§e aktarÄ±n
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt

# Sigorta veri setini okuyun
insurance = pd.read_csv("https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv")

# Sigorta veri setine gÃ¶z atÄ±n
insurance.head()
```
> <img src="https://i.ibb.co/wQhcMF3/5.png" />

SayÄ±sal olmayan sÃ¼tunlarÄ± sayÄ±sal tipe Ã§evirmemiz gerekecek (Ã§Ã¼nkÃ¼ bir sinir aÄŸÄ± sayÄ±sal olmayan girdileri iÅŸleyemez).

Bunu yapmak iÃ§in pandas `get_dummies()` yÃ¶ntemini kullanacaÄŸÄ±z.

One-hot encoding kullanarak kategorik deÄŸiÅŸkenleri (cinsiyet, sigara iÃ§en ve bÃ¶lge sÃ¼tunlarÄ± gibi) sayÄ±sal deÄŸiÅŸkenlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

```python
insurance_one_hot = pd.get_dummies(insurance)
insurance_one_hot.head()
```
> <img src="https://i.ibb.co/fxXyPzk/5.png" />
Åimdi verileri Ã¶zellikler (X) ve etiketler (y) olarak ayÄ±racaÄŸÄ±z.

```python
X = insurance_one_hot.drop("charges", axis=1)
y = insurance_one_hot["charges"]
```
Ve eÄŸitim ve test setleri oluÅŸturun. Bunu manuel olarak yapabiliriz, ancak kolaylaÅŸtÄ±rmak iÃ§in Scikit-Learn'de zaten mevcut olan `train_test_split` iÅŸlevinden yararlanacaÄŸÄ±z.

```python
# EÄŸitim ve test setleri oluÅŸturun
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    test_size=0.2, 
                                                    random_state=42)
``` 

Åimdi bir model oluÅŸturup fitleyebiliriz (bunu model_2 ile aynÄ± yapacaÄŸÄ±z).


```python
tf.random.set_seed(42)

insurance_model = tf.keras.Sequential([
  tf.keras.layers.Dense(1),
  tf.keras.layers.Dense(1)
])

insurance_model.compile(loss=tf.keras.losses.mae,
                        optimizer=tf.keras.optimizers.SGD(),
                        metrics=['mae'])

insurance_model.fit(X_train, y_train, epochs=100, verbose=0)

# Sigorta modelinin sonuÃ§larÄ±nÄ± kontrol edin
insurance_model.evaluate(X_test, y_test)
``` 
> [8628.2392578125, 8628.2392578125]

Modelimiz pek iyi performans gÃ¶stermedi, hadi daha bÃ¼yÃ¼k bir model ile tekrar deneyelim.

3 ÅŸey deneyeceÄŸiz:
- Katman sayÄ±sÄ±nÄ± artÄ±rma (2 -> 3).
- Her katmandaki birim sayÄ±sÄ±nÄ± artÄ±rma (Ã§Ä±ktÄ± katmanÄ± hariÃ§)
- Optimize ediciyi deÄŸiÅŸtirme (SGD'den Adam'a).

DiÄŸer her ÅŸey aynÄ± kalacak.

```python
tf.random.set_seed(42)

# Fazladan bir katman ekleyin ve birim sayÄ±sÄ±nÄ± artÄ±rma
insurance_model_2 = tf.keras.Sequential([
  tf.keras.layers.Dense(100), # 100 units
  tf.keras.layers.Dense(10), # 10 units
  tf.keras.layers.Dense(1) # 1 unit (Ã§Ä±ktÄ± katmanÄ± iÃ§in Ã¶nemlidir)
])

# modeli derleme
insurance_model_2.compile(loss=tf.keras.losses.mae,
                          optimizer=tf.keras.optimizers.Adam(), 
                          metrics=['mae'])

# Modeli sÄ±ÄŸdÄ±r ve history deÄŸiÅŸkenine kaydet
history = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)

# modeli deÄŸerlendirme
insurance_model_2.evaluate(X_test, y_test)
``` 
> [4924.34765625, 4924.34765625]

Ã‡ok daha iyi! Daha bÃ¼yÃ¼k bir model ve Adam optimize edici kullanmak, Ã¶nceki modele gÃ¶re neredeyse yarÄ± yarÄ±ya hatayla sonuÃ§lanÄ±r.

> ğŸ”‘ Not: BirÃ§ok sorun iÃ§in Adam optimize edici harika bir baÅŸlangÄ±Ã§ â€‹â€‹seÃ§imidir. Daha fazlasÄ± iÃ§in [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)

Modelimizin kayÄ±p eÄŸrilerine bir gÃ¶z atalÄ±m, aÅŸaÄŸÄ± yÃ¶nlÃ¼ bir trend gÃ¶rmeliyiz.

```python
pd.DataFrame(history.history).plot()
plt.ylabel("loss")
plt.xlabel("epochs");
``` 
> <img src="https://i.ibb.co/gRJSQLp/5.png" />

Buradan, modelimizin kaybÄ±nÄ±n (ve MAE) her ikisinin de hala azalmakta olduÄŸu gÃ¶rÃ¼lÃ¼yor (bizim durumumuzda, MAE ve kayÄ±p aynÄ±, dolayÄ±sÄ±yla Ã§izgiler birbiriyle Ã¶rtÃ¼ÅŸÃ¼yor).

Bunun bize sÃ¶ylediÄŸi ÅŸey, onu daha uzun sÃ¼re eÄŸitmeye Ã§alÄ±ÅŸÄ±rsak kaybÄ±n dÃ¼ÅŸebileceÄŸidir.

> ğŸ¤” Soru: Ne kadar sÃ¼re eÄŸitim yapmalÄ±sÄ±nÄ±z?

> Hangi sorun Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±za baÄŸlÄ±. Bazen eÄŸitim Ã§ok uzun sÃ¼rmez, bazen beklediÄŸinizden daha uzun sÃ¼rer. YaygÄ±n bir yÃ¶ntem, model eÄŸitiminizi Ã§ok uzun bir sÃ¼re iÃ§in ayarlamaktÄ±r (Ã¶r. 1000'lerce epoch), ancak bunu bir [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) callback deÄŸeri ile ayarlamaktÄ±r, bÃ¶ylece geliÅŸmeyi bÄ±raktÄ±ÄŸÄ±nda otomatik olarak durur. Bunu baÅŸka bir eÄŸitimde gÃ¶receÄŸiz.

YukarÄ±daki modeli biraz daha uzun sÃ¼re eÄŸitelim.

```python
# Biraz daha uzun sÃ¼re antrenman yapmayÄ± deneyin (100 epoch daha)
history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)
``` 

```python
# Toplam 200 dÃ¶nem iÃ§in eÄŸitilen modeli deÄŸerlendirin
insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, y_test)
insurance_model_2_loss, insurance_model_2_mae
``` 
> (3494.728515625, 3494.728515625)

BaÅŸardÄ±k! Fazladan 100 epoch eÄŸitim, hatada yaklaÅŸÄ±k %10'luk bir azalma gÃ¶rÃ¼yoruz.

```python
pd.DataFrame(history_2.history).plot()
plt.ylabel("loss")
plt.xlabel("epochs"); 
``` 
> <img src="https://i.ibb.co/WcxBpnW/5.png" />


## Ã–n Ä°ÅŸleme Verileri (normalleÅŸtirme ve standardizasyon)

Sinir aÄŸlarÄ±yla Ã§alÄ±ÅŸÄ±rken yaygÄ±n bir uygulama, onlara ilettiÄŸiniz tÃ¼m verilerin 0 ila 1 aralÄ±ÄŸÄ±nda olduÄŸundan emin olmaktÄ±r.

Bu uygulamaya normalleÅŸtirme denir (tÃ¼m deÄŸerleri orijinal aralÄ±klarÄ±ndan 0 ile 100.000 arasÄ±nda 0 ile 1 arasÄ±nda olacak ÅŸekilde Ã¶lÃ§eklendirmek).

TÃ¼m verilerinizi birim varyansa ve 0 ortalamaya dÃ¶nÃ¼ÅŸtÃ¼ren baÅŸka bir iÅŸlem Ã§aÄŸrÄ±sÄ± standardizasyonu vardÄ±r.

Bu iki uygulama genellikle bir Ã¶n iÅŸleme hattÄ±nÄ±n (verilerinizi sinir aÄŸlarÄ±yla kullanÄ±ma hazÄ±rlamak iÃ§in bir dizi iÅŸlev) parÃ§asÄ±dÄ±r.

Bunu bilerek, bir sinir aÄŸÄ± iÃ§in verilerinizi Ã¶nceden iÅŸlemek Ã¼zere atacaÄŸÄ±nÄ±z bazÄ± Ã¶nemli adÄ±mlardan bazÄ±larÄ± ÅŸunlardÄ±r:

- TÃ¼m verilerinizi sayÄ±lara Ã§evirmek (bir sinir aÄŸÄ± dizeleri iÅŸleyemez).
- Verilerinizin doÄŸru ÅŸekilde olduÄŸundan emin olun (giriÅŸ ve Ã§Ä±kÄ±ÅŸ ÅŸekillerini doÄŸrulama).
- Ã–zellik Ã¶lÃ§eklendirme:
  - Verileri normalleÅŸtirme (tÃ¼m deÄŸerlerin 0 ile 1 arasÄ±nda olduÄŸundan emin olun). Bu, minimum deÄŸerin Ã§Ä±karÄ±lmasÄ± ve ardÄ±ndan maksimum deÄŸerin minimumdan Ã§Ä±karÄ±lmasÄ±yla yapÄ±lÄ±r. Bu aynÄ± zamanda min-maks Ã¶lÃ§ekleme olarak da adlandÄ±rÄ±lÄ±r.
  - Standardizasyon (tÃ¼m deÄŸerlerin ortalamasÄ±nÄ±n 0 ve varyansÄ±nÄ±n 1 olduÄŸundan emin olun). Bu, ortalama deÄŸerin hedef Ã¶zellikten Ã§Ä±karÄ±lmasÄ± ve ardÄ±ndan standart sapmaya bÃ¶lÃ¼nmesiyle yapÄ±lÄ±r.
  - Hangisini kullanmalÄ±sÄ±nÄ±z?
    - Sinir aÄŸlarÄ±nda, 0 ile 1 arasÄ±ndaki deÄŸerleri tercih etme eÄŸiliminde olduklarÄ± iÃ§in normalleÅŸtirmeyi tercih edeceksiniz (bunu Ã¶zellikle gÃ¶rÃ¼ntÃ¼ iÅŸlemede gÃ¶receksiniz), ancak genellikle bir sinir aÄŸÄ±nÄ±n minimum Ã¶zellik Ã¶lÃ§ekleme ile oldukÃ§a iyi performans gÃ¶sterebileceÄŸini gÃ¶receksiniz.


> ğŸ“– Kaynak: Ã–n iÅŸleme verileri hakkÄ±nda daha fazla bilgi iÃ§in aÅŸaÄŸÄ±daki kaynaklarÄ± okumanÄ±zÄ± tavsiye ederim:

* [Scikit-Learn'Ã¼n Ã¶n iÅŸleme verileriyle ilgili belgeleri.](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data)
* [Jeff Hale'den Scikit-Learn ile Ã–lÃ§eklendirin, StandartlaÅŸtÄ±rÄ±n veya NormalleÅŸtirin.](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)

Verilerimizi `get_dummies()` kullanarak zaten sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼k, nasÄ±l normalleÅŸtireceÄŸimize de bakalÄ±m.


```python
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

insurance = pd.read_csv("https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv")
``` 

Åimdi, daha Ã¶nce olduÄŸu gibi, sayÄ±sal olmayan sÃ¼tunlarÄ± sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekiyor ve bu sefer de sayÄ±sal sÃ¼tunlarÄ± farklÄ± aralÄ±klarla normalleÅŸtireceÄŸiz (hepsinin 0 ile 1 arasÄ±nda olduÄŸundan emin olmak iÃ§in).

Bunu yapmak iÃ§in Scikit-Learn'den birkaÃ§ sÄ±nÄ±f kullanacaÄŸÄ±z:

- make_column_transformer - aÅŸaÄŸÄ±daki dÃ¶nÃ¼ÅŸÃ¼mler iÃ§in Ã§ok adÄ±mlÄ± bir veri Ã¶n iÅŸleme iÅŸlevi oluÅŸturun:
  - MinMaxScaler - tÃ¼m sayÄ±sal sÃ¼tunlarÄ±n normalleÅŸtirildiÄŸinden emin olun (0 ile 1 arasÄ±nda).
  - OneHotEncoder - sayÄ±sal olmayan sÃ¼tunlarÄ± kodlar.


```python
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

# Verilerimizi normalleÅŸtirme/Ã¶n iÅŸleme
ct = make_column_transformer(
    (MinMaxScaler(), ["age", "bmi", "children"]), # tÃ¼m deÄŸerleri 0-1 arasÄ±nda alma
    (OneHotEncoder(handle_unknown="ignore"), ["sex", "smoker", "region"])
)

# X & y oluÅŸtur
X = insurance.drop("charges", axis=1)
y = insurance["charges"]

# Tren ve test setlerimizi oluÅŸturun (Ã¶nceki gibi aynÄ± bÃ¶lÃ¼nmeyi saÄŸlamak iÃ§in rastgele durumu kullanÄ±n)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modeli fit etme
ct.fit(X_train)

# NormalleÅŸtirme (MinMaxScalar) ve o one-hot encoding (OneHotEncoder) ile eÄŸitim ve test verilerini dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
X_train_normal = ct.transform(X_train)
X_test_normal = ct.transform(X_test)
``` 

Verilerimiz ÅŸimdi nasÄ±l gÃ¶rÃ¼nÃ¼yor?


```python
# NormalleÅŸtirilmemiÅŸ ve one-hot encoding olmayan kodlanmÄ±ÅŸ veri Ã¶rneÄŸi
X_train.loc[0]
``` 
> <img src="https://i.ibb.co/0GNc12t/6.png" />


```python
# normalize ve one-hot kodlanmÄ±ÅŸ Ã¶rnek
X_train_normal[0]
``` 
> array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,
       1.        , 0.        , 0.        , 1.        , 0.        ,
       0.        ])



```python
# NormalleÅŸtirilmiÅŸ/one-hot kodlanmÄ±ÅŸ ÅŸeklin fazladan sÃ¼tunlar nedeniyle daha bÃ¼yÃ¼k olduÄŸuna dikkat edin
X_train_normal.shape, X_train.shape
``` 
> ((1070, 11), (1070, 6))

Verilerimiz normalize edilmiÅŸ ve sayÄ±saldÄ±r, hadi modelleyelim.

insurance_model_2 ile aynÄ± modeli kullanacaÄŸÄ±z.

```python
tf.random.set_seed(42)

insurance_model_3 = tf.keras.Sequential([
  tf.keras.layers.Dense(100),
  tf.keras.layers.Dense(10),
  tf.keras.layers.Dense(1)
])

insurance_model_3.compile(loss=tf.keras.losses.mae,
                          optimizer=tf.keras.optimizers.Adam(),
                          metrics=['mae'])

insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0) 

insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)
``` 

Ve son olarak, insurance_model_2 (normalleÅŸtirilmemiÅŸ veriler Ã¼zerinde eÄŸitilmiÅŸ) ve insurance_model_3 (normalleÅŸtirilmiÅŸ veriler Ã¼zerinde eÄŸitilmiÅŸ) sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±ralÄ±m.

```python
# NormalleÅŸtirilmemiÅŸ verilerden ve normalleÅŸtirilmiÅŸ verilerden modelleme sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±n
insurance_model_2_mae, insurance_model_3_mae
``` 

Bundan, verileri normalleÅŸtirmenin, aynÄ± modeli kullanarak verileri normalleÅŸtirmemeye gÃ¶re %10 daha az hatayla sonuÃ§landÄ±ÄŸÄ±nÄ± gÃ¶rebiliriz.

Bu, normalleÅŸtirmenin ana faydalarÄ±ndan biridir: daha hÄ±zlÄ± yakÄ±nsama sÃ¼resi (sÃ¶ylemenin sÃ¼slÃ¼ bir yolu, modeliniz daha hÄ±zlÄ± daha iyi sonuÃ§lara ulaÅŸÄ±r).

insurance_model_2, eÄŸitimini daha uzun sÃ¼re bÄ±rakÄ±rsak, sonunda insurance_model_3 ile aynÄ± sonuÃ§larÄ± elde etmiÅŸ olabilir.

AyrÄ±ca, modellerin mimarilerini deÄŸiÅŸtirecek olursak sonuÃ§lar deÄŸiÅŸebilir, Ã¶rn. katman veya daha fazla katman baÅŸÄ±na daha fazla gizli birim.

Ancak sinir aÄŸÄ± uygulayÄ±cÄ±larÄ± olarak asÄ±l amacÄ±mÄ±z deneyler arasÄ±ndaki sÃ¼reyi azaltmak olduÄŸundan, daha iyi sonuÃ§larÄ± daha erken almamÄ±za yardÄ±mcÄ± olan her ÅŸey bir artÄ±dÄ±r.


