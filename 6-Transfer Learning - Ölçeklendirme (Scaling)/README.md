# Tensorflow ile Transfer Learning - Ã–lÃ§eklendirme (Scaling)

Ã–nceki iki not defterinde (Ã¶zellik Ã§Ä±karma ve ince ayar) transfer learningin gÃ¼cÃ¼nÃ¼ gÃ¶rdÃ¼k.

ArtÄ±k daha kÃ¼Ã§Ã¼k modelleme deneylerimizin iÅŸe yaradÄ±ÄŸÄ±nÄ± biliyoruz, daha fazla veriyle iÅŸleri bir adÄ±m Ã¶teye taÅŸÄ±manÄ±n zamanÄ± geldi.

Bu, makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenmede yaygÄ±n bir uygulamadÄ±r: Daha bÃ¼yÃ¼k miktarda veriye Ã¶lÃ§eklendirmeden Ã¶nce az miktarda veri Ã¼zerinde Ã§alÄ±ÅŸan bir model edinin.

> ğŸ”‘ Not: Makine Ã¶ÄŸrenimi uygulayÄ±cÄ±larÄ±nÄ±n sloganÄ±nÄ± unutmadÄ±nÄ±z mÄ±? "Deney, deney, deney."

Food Vision projemizin hayata geÃ§mesine biraz daha yaklaÅŸmanÄ±n zamanÄ± geldi. Bu not defterinde, Food101 verilerinin 10 sÄ±nÄ±fÄ±nÄ± kullanmaktan, Food101 veri kÃ¼mesindeki tÃ¼m sÄ±nÄ±flarÄ± kullanmaya doÄŸru Ã¶lÃ§eklendireceÄŸiz.

Hedefimiz, orijinal [Food101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf) belgesinin sonuÃ§larÄ±nÄ± %10 veri ile geÃ§mektir.

- Food101 verilerinin %10'unun indirilmesi ve hazÄ±rlanmasÄ± (eÄŸitim verilerinin %10'u)
- Food101 eÄŸitim verilerinin %10'unda bir Ã¶zellik Ã§Ä±karma aktarÄ±mÄ± Ã¶ÄŸrenme modeli eÄŸitimi
- Ã–zellik Ã§Ä±karma modelimizin ince ayarÄ±nÄ± yapma
- EÄŸitilmiÅŸ modelimizi kaydetme ve yÃ¼kleme
- EÄŸitim verilerinin %10'u Ã¼zerinden eÄŸitilen Food Vision modelimizin performansÄ±nÄ±n deÄŸerlendirilmesi
- Modelimizin en yanlÄ±ÅŸ tahminlerini bulma
- Food Vision modelimiz ile Ã¶zel gÄ±da gÃ¶rselleri Ã¼zerinde tahminlerde bulunmak

## YardÄ±mcÄ± FonksiyonlarÄ± OluÅŸturalÄ±m


```python
import datetime

def create_tensorboard_callback(dir_name, experiment_name):
  log_dir = dir_name + "/" + experiment_name + "/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tensorboard_callback = tf.keras.callbacks.TensorBoard(
      log_dir=log_dir
  )
  print(f"{log_dir}")
  return tensorboard_callback
```


```python
import matplotlib.pyplot as plt

def plot_loss_curves(history):
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();
```


```python
import zipfile

def unzip_data(filename):
  zip_ref = zipfile.ZipFile(filename, "r")
  zip_ref.extractall()
  zip_ref.close()
```


```python
def compare_historys(original_history, new_history, initial_epochs=5):
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]

    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]

    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],
              plt.ylim(), label='Start Fine Tuning') 
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
```


```python
import os

def walk_through_dir(dir_path):
  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"'{dirpath}' klasÃ¶rÃ¼nde {len(filenames)} veri var.")
```


```python
import itertools
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix

def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): 
  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] 
  n_classes = cm.shape[0]

  fig, ax = plt.subplots(figsize=figsize)
  cax = ax.matshow(cm, cmap=plt.cm.Blues)
  fig.colorbar(cax)

  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])
  
  ax.set(title="Confusion Matrix",
         xlabel="Predicted label",
         ylabel="True label",
         xticks=np.arange(n_classes), 
         yticks=np.arange(n_classes), 
         xticklabels=labels,
         yticklabels=labels)
  
  ax.xaxis.set_label_position("bottom")
  ax.xaxis.tick_bottom()

  threshold = (cm.max() + cm.min()) / 2.

  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if norm:
      plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)
    else:
      plt.text(j, i, f"{cm[i, j]}",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)

  if savefig:
    fig.savefig("confusion_matrix.png")
```

## 101 Yemek SÄ±nÄ±fÄ±: Daha Az Veriyle Ã‡alÄ±ÅŸmak

Åimdiye kadar kullandÄ±ÄŸÄ±mÄ±z transfer Ã¶ÄŸrenme modelinin 10 Yemek SÄ±nÄ±fÄ± veri seti ile oldukÃ§a iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± onayladÄ±k. Åimdi, tam 101 Yemek SÄ±nÄ±fÄ± ile nasÄ±l gittiklerini gÃ¶rme zamanÄ±.

Orijinal Food101 veri setinde sÄ±nÄ±f baÅŸÄ±na 1000 gÃ¶rÃ¼ntÃ¼ (eÄŸitim setindeki her sÄ±nÄ±ftan 750 ve test setindeki her sÄ±nÄ±ftan 250), toplam 101.000 gÃ¶rÃ¼ntÃ¼ vardÄ±r.



```python
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip 

unzip_data("101_food_classes_10_percent.zip")

train_dir = "101_food_classes_10_percent/train/"
test_dir = "101_food_classes_10_percent/test/"
```

    --2021-07-20 10:29:35--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip
    Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.128, 108.177.98.128, 74.125.197.128, ...
    Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.128|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 1625420029 (1.5G) [application/zip]
    Saving to: â€˜101_food_classes_10_percent.zipâ€™
    
    101_food_classes_10 100%[===================>]   1.51G   147MB/s    in 7.6s    
    
    2021-07-20 10:29:42 (204 MB/s) - â€˜101_food_classes_10_percent.zipâ€™ saved [1625420029/1625420029]
    



```python
walk_through_dir("101_food_classes_10_percent")
```

    '101_food_classes_10_percent' klasÃ¶rÃ¼nde 0 veri var.
    '101_food_classes_10_percent/train' klasÃ¶rÃ¼nde 0 veri var.
    '101_food_classes_10_percent/train/croque_madame' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/frozen_yogurt' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/bruschetta' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/paella' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/dumplings' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/chicken_wings' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/french_onion_soup' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/baklava' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/risotto' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/gyoza' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/tiramisu' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/eggs_benedict' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/churros' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/baby_back_ribs' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/hot_dog' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/sushi' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/macaroni_and_cheese' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/chocolate_mousse' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/steak' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/edamame' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/falafel' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/huevos_rancheros' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/prime_rib' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/clam_chowder' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/lobster_bisque' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/crab_cakes' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/omelette' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/hummus' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pork_chop' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pizza' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/ravioli' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/panna_cotta' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/grilled_cheese_sandwich' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/ice_cream' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/tacos' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/ramen' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/cup_cakes' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/escargots' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/filet_mignon' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/chocolate_cake' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/red_velvet_cake' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/macarons' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/bibimbap' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/poutine' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/greek_salad' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/fried_rice' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/beef_carpaccio' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/bread_pudding' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/tuna_tartare' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/seaweed_salad' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pho' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/foie_gras' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/french_toast' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/fish_and_chips' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/club_sandwich' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/cheese_plate' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/chicken_quesadilla' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/takoyaki' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/mussels' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/beef_tartare' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/lobster_roll_sandwich' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/sashimi' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/strawberry_shortcake' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/chicken_curry' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/nachos' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/onion_rings' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/cheesecake' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/caesar_salad' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/beignets' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/french_fries' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/carrot_cake' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/fried_calamari' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/hot_and_sour_soup' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/garlic_bread' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/shrimp_and_grits' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/caprese_salad' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/donuts' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/spaghetti_carbonara' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pad_thai' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/samosa' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/gnocchi' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/deviled_eggs' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/cannoli' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/waffles' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/miso_soup' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/lasagna' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/apple_pie' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pancakes' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/peking_duck' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/spring_rolls' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/scallops' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/ceviche' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/beet_salad' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/creme_brulee' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/grilled_salmon' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/oysters' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/pulled_pork_sandwich' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/spaghetti_bolognese' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/breakfast_burrito' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/hamburger' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/train/guacamole' klasÃ¶rÃ¼nde 75 veri var.
    '101_food_classes_10_percent/test' klasÃ¶rÃ¼nde 0 veri var.
    '101_food_classes_10_percent/test/croque_madame' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/frozen_yogurt' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/bruschetta' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/paella' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/dumplings' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/chicken_wings' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/french_onion_soup' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/baklava' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/risotto' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/gyoza' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/tiramisu' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/eggs_benedict' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/churros' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/baby_back_ribs' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/hot_dog' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/sushi' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/macaroni_and_cheese' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/chocolate_mousse' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/steak' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/edamame' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/falafel' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/huevos_rancheros' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/prime_rib' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/clam_chowder' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/lobster_bisque' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/crab_cakes' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/omelette' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/hummus' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pork_chop' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pizza' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/ravioli' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/panna_cotta' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/grilled_cheese_sandwich' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/ice_cream' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/tacos' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/ramen' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/cup_cakes' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/escargots' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/filet_mignon' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/chocolate_cake' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/red_velvet_cake' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/macarons' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/bibimbap' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/poutine' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/greek_salad' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/fried_rice' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/beef_carpaccio' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/bread_pudding' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/tuna_tartare' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/seaweed_salad' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pho' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/foie_gras' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/french_toast' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/fish_and_chips' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/club_sandwich' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/cheese_plate' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/chicken_quesadilla' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/takoyaki' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/mussels' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/beef_tartare' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/lobster_roll_sandwich' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/sashimi' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/strawberry_shortcake' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/chicken_curry' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/nachos' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/onion_rings' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/cheesecake' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/caesar_salad' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/beignets' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/french_fries' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/carrot_cake' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/fried_calamari' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/hot_and_sour_soup' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/garlic_bread' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/shrimp_and_grits' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/caprese_salad' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/donuts' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/spaghetti_carbonara' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pad_thai' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/samosa' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/gnocchi' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/deviled_eggs' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/cannoli' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/waffles' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/miso_soup' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/lasagna' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/apple_pie' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pancakes' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/peking_duck' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/spring_rolls' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/scallops' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/ceviche' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/beet_salad' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/creme_brulee' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/grilled_salmon' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/oysters' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/pulled_pork_sandwich' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/spaghetti_bolognese' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/breakfast_burrito' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/hamburger' klasÃ¶rÃ¼nde 250 veri var.
    '101_food_classes_10_percent/test/guacamole' klasÃ¶rÃ¼nde 250 veri var.


GÃ¶rsellerimizi ve etiketlerimizi, dizini modelimize geÃ§irmemizi saÄŸlayan bir TensorFlow veri tÃ¼rÃ¼ olan tf.data.Dataset'e dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in `image_dataset_from_directory()` iÅŸlevini kullanalÄ±m.

Test veri kÃ¼mesi iÃ§in, daha sonra Ã¼zerinde tekrarlanabilir deÄŸerlendirme ve gÃ¶rselleÅŸtirme yapabilmek iÃ§in `shuffle=False` ayarÄ±nÄ± yapacaÄŸÄ±z.



```python
import tensorflow as tf

IMG_SIZE = (224, 224)

train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,
                                                                                label_mode="categorical",
                                                                                image_size=IMG_SIZE)
                                                                                
test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                label_mode="categorical",
                                                                image_size=IMG_SIZE,
                                                                shuffle=False)
```

    Found 7575 files belonging to 101 classes.
    Found 25250 files belonging to 101 classes.


Harika! EÄŸitim setinde sÄ±nÄ±f baÅŸÄ±na 75 gÃ¶rÃ¼ntÃ¼ (75 gÃ¶rÃ¼ntÃ¼ * 101 sÄ±nÄ±f = 7575 gÃ¶rÃ¼ntÃ¼) ve test setinde 25250 gÃ¶rÃ¼ntÃ¼ (250 gÃ¶rÃ¼ntÃ¼ * 101 sÄ±nÄ±f = 25250 gÃ¶rÃ¼ntÃ¼) ile verilerimiz beklendiÄŸi gibi iÃ§e aktarÄ±lmÄ±ÅŸ gibi gÃ¶rÃ¼nÃ¼yor.

## 101 Yemek SÄ±nÄ±fÄ±nÄ±n %10'unda Transfer Ã–ÄŸrenimi ile BÃ¼yÃ¼k Bir Modeli EÄŸitin

GÄ±da gÃ¶rÃ¼ntÃ¼ verilerimiz, modelleme zamanÄ± olarak TensorFlow'a aktarÄ±ldÄ±.

Deneylerimizi hÄ±zlÄ± tutmak iÃ§in, birkaÃ§ dÃ¶nem iÃ§in Ã¶nceden eÄŸitilmiÅŸ bir modelle Ã¶zellik Ã§Ä±karma transferi Ã¶ÄŸrenimini kullanarak baÅŸlayacaÄŸÄ±z ve ardÄ±ndan birkaÃ§ dÃ¶nem iÃ§in daha ince ayar yapacaÄŸÄ±z.

Daha spesifik olarak, hedefimiz, eÄŸitim verilerinin %10'u ve aÅŸaÄŸÄ±daki modelleme kurulumu ile orijinal Food101 belgesindeki (101 sÄ±nÄ±fta %50,76 doÄŸruluk) taban Ã§izgisini geÃ§ip geÃ§emeyeceÄŸimizi gÃ¶rmek olacaktÄ±r:

- EÄŸitim sÄ±rasÄ±nda ilerlememizi kaydetmek iÃ§in bir ModelCheckpoint geri Ã§aÄŸrÄ±sÄ±, bu, her seferinde sÄ±fÄ±rdan eÄŸitim almak zorunda kalmadan daha sonra daha fazla eÄŸitim deneyebileceÄŸimiz anlamÄ±na gelir.
- DoÄŸrudan modele entegre edilmiÅŸ veri bÃ¼yÃ¼tme
Temel modelimiz olarak `tf.keras.applications`'dan Ã¼st katman olmayan EfficientNetB0 mimarisi
- 101 gizli nÃ¶ronlu (gÄ±da sÄ±nÄ±fÄ± sayÄ±sÄ±yla aynÄ±) ve Ã§Ä±ktÄ± katmanÄ± olarak softmax aktivasyonlu bir YoÄŸun katman
Ä°kiden fazla sÄ±nÄ±fla uÄŸraÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in kayÄ±p fonksiyonu olarak kategorik Ã§apraz entropi
- VarsayÄ±lan ayarlarla Adam optimize edici
- Test verilerinin %15'ini deÄŸerlendirirken eÄŸitim verilerine 5 tam geÃ§iÅŸ fit etmek

ModelCheckpoint callback'i oluÅŸturarak baÅŸlayalÄ±m.

Modelimizin gÃ¶rÃ¼nmeyen veriler Ã¼zerinde iyi performans gÃ¶stermesini istediÄŸimizden, onu doÄŸrulama doÄŸruluÄŸu metriÄŸini izleyecek ve bu konuda en iyi puanÄ± alan model aÄŸÄ±rlÄ±klarÄ±nÄ± kaydedecek ÅŸekilde ayarlayacaÄŸÄ±z.


```python
checkpoint_path = "101_classes_10_percent_data_model_checkpoint"
checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                         save_weights_only=True,
                                                         monitor="val_accuracy",
                                                         save_best_only=True) 
```

Kontrol noktasÄ± hazÄ±r. Åimdi Sequential API ile kÃ¼Ã§Ã¼k bir veri bÃ¼yÃ¼tme modeli oluÅŸturalÄ±m. KÃ¼Ã§Ã¼k boyutlu bir eÄŸitim seti ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in bu, modelimizin eÄŸitim verilerine gereÄŸinden fazla uymasÄ±nÄ± Ã¶nlemeye yardÄ±mcÄ± olacaktÄ±r.


```python
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.models import Sequential

data_augmentation = Sequential([
  preprocessing.RandomFlip("horizontal"),
  preprocessing.RandomRotation(0.2),
  preprocessing.RandomHeight(0.2),
  preprocessing.RandomWidth(0.2),
  preprocessing.RandomZoom(0.2),
], name="data_augmentation")
```

GÃ¼zel! Data_augmentation Sequential modelini Functional API modelimize bir katman olarak ekleyebileceÄŸiz. Bu ÅŸekilde, modelimizi daha sonra eÄŸitmeye devam etmek istersek, veri bÃ¼yÃ¼tme zaten yerleÅŸiktir.

Ä°ÅŸlevsel API modellerinden bahsetmiÅŸken, temel modelimiz olarak `tf.keras.applications.EfficientNetB0` kullanarak bir Ã¶zellik Ã§Ä±karma aktarÄ±mÄ± Ã¶ÄŸrenme modeli oluÅŸturmanÄ±n zamanÄ± geldi.

Temel modeli `include_top=False` parametresini kullanarak iÃ§e aktaracaÄŸÄ±z, bÃ¶ylece kendi Ã§Ä±ktÄ± katmanlarÄ±mÄ±zÄ±, Ã¶zellikle `GlobalAveragePooling2D()` (temel modelin Ã§Ä±ktÄ±larÄ±nÄ± Ã§Ä±ktÄ± katmanÄ± tarafÄ±ndan kullanÄ±labilir bir ÅŸekle yoÄŸunlaÅŸtÄ±rÄ±r), ardÄ±ndan bir YoÄŸun katman ekleyebiliriz.


```python
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False

inputs = layers.Input(shape=(224, 224, 3), name="input_layer") 
x = data_augmentation(inputs) 
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D(name="global_average_pooling")(x) 
outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation="softmax", name="output_layer")(x) 
model = tf.keras.Model(inputs, outputs)
```

    Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5
    16711680/16705208 [==============================] - 0s 0us/step



```python
model.summary()
```

    Model: "model"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_layer (InputLayer)     [(None, 224, 224, 3)]     0         
    _________________________________________________________________
    data_augmentation (Sequentia (None, None, None, 3)     0         
    _________________________________________________________________
    efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   
    _________________________________________________________________
    global_average_pooling (Glob (None, 1280)              0         
    _________________________________________________________________
    output_layer (Dense)         (None, 101)               129381    
    =================================================================
    Total params: 4,178,952
    Trainable params: 129,381
    Non-trainable params: 4,049,571
    _________________________________________________________________


Ä°yi gÃ¶rÃ¼nÃ¼yor! Ä°ÅŸlevsel modelimizin 5 katmanÄ± vardÄ±r, ancak bu katmanlarÄ±n her birinin iÃ§inde deÄŸiÅŸen miktarlarda katmanlar vardÄ±r.

Trainable ve non-trainable parametrelerin sayÄ±sÄ±na dikkat edin. GÃ¶rÃ¼nen o ki, eÄŸitilebilir tek parametre output_layer iÃ§inde, ki bu Ã¶zellik Ã§Ä±karmanÄ±n bu ilk Ã§alÄ±ÅŸtÄ±rmasÄ±nda tam olarak peÅŸinde olduÄŸumuz ÅŸey; modelin Ã§Ä±ktÄ±larÄ±nÄ± Ã¶zel verilerimize gÃ¶re ayarlamasÄ±na izin verirken temel modeldeki (EfficientNetb0) tÃ¼m Ã¶ÄŸrenilen kalÄ±plarÄ± dondurma.


```python
# modeli derleme
model.compile(loss="categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

# modeli fit etme
history_all_classes_10_percent = model.fit(train_data_all_10_percent,
                                           epochs=5, 
                                           validation_data=test_data,
                                           validation_steps=int(0.15 * len(test_data)), 
                                           callbacks=[checkpoint_callback]) 
```

    Epoch 1/5
    237/237 [==============================] - 124s 376ms/step - loss: 3.4567 - accuracy: 0.2446 - val_loss: 2.5810 - val_accuracy: 0.4404
    Epoch 2/5
    237/237 [==============================] - 71s 300ms/step - loss: 2.3444 - accuracy: 0.4585 - val_loss: 2.1951 - val_accuracy: 0.4703
    Epoch 3/5
    237/237 [==============================] - 65s 271ms/step - loss: 1.9753 - accuracy: 0.5337 - val_loss: 2.0319 - val_accuracy: 0.4934
    Epoch 4/5
    237/237 [==============================] - 61s 257ms/step - loss: 1.7592 - accuracy: 0.5782 - val_loss: 1.9716 - val_accuracy: 0.4942
    Epoch 5/5
    237/237 [==============================] - 59s 247ms/step - loss: 1.6027 - accuracy: 0.6046 - val_loss: 1.8762 - val_accuracy: 0.5199


GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re verinin %10'u ile taban Ã§izgimizi (orijinal Food101 makalesinden elde edilen sonuÃ§lar) geÃ§tik! 5 dakikadan kÄ±sa bir sÃ¼rede... bu derin Ã¶ÄŸrenmenin gÃ¼cÃ¼dÃ¼r ve daha doÄŸrusu, transfer Ã¶ÄŸreniminin.

KayÄ±p eÄŸrileri nasÄ±l gÃ¶rÃ¼nÃ¼yor?


```python
plot_loss_curves(history_all_classes_10_percent)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_24_0.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_24_1.png)
    


ğŸ¤” Soru: Bu eÄŸriler ne Ã¶neriyor? Ä°pucu: ideal olarak, iki eÄŸri birbirine Ã§ok benzer olmalÄ±dÄ±r.

## Ä°nce Ayar (Fine Tuning)

Ã–zellik Ã§Ä±karma transferi Ã¶ÄŸrenme modelimiz iyi performans gÃ¶steriyor. Neden temel modelde birkaÃ§ katmanda ince ayar yapmaya Ã§alÄ±ÅŸmÄ±yoruz ve herhangi bir iyileÅŸtirme elde edip edemeyeceÄŸimizi gÃ¶rmÃ¼yoruz?

Ä°yi haber ÅŸu ki, `ModelCheckpoint` geri aramasÄ± sayesinde zaten iyi performans gÃ¶steren modelimizin kaydedilmiÅŸ aÄŸÄ±rlÄ±klarÄ±na sahibiz, bÃ¶ylece ince ayar herhangi bir fayda saÄŸlamÄ±yorsa geri dÃ¶nebiliriz.

Temel modelde ince ayar yapmak iÃ§in Ã¶nce `trainable` Ã¶zniteliÄŸini `True` olarak ayarlayacaÄŸÄ±z, tÃ¼m donmuÅŸlarÄ± Ã§Ã¶zeceÄŸiz.

Daha sonra, nispeten kÃ¼Ã§Ã¼k bir eÄŸitim veri setimiz olduÄŸu iÃ§in, son 5 hariÃ§ her katmanÄ± yeniden donduracaÄŸÄ±z ve onlarÄ± eÄŸitilebilir hale getireceÄŸiz.


```python
# Temel modeldeki tÃ¼m katmanlarÄ± Ã§Ã¶z
base_model.trainable = True

# Son 5 hariÃ§ her katmanÄ± yeniden dondur
for layer in base_model.layers[:-5]:
  layer.trainable = False
```

Modelimizdeki katmanlarda yeni bir deÄŸiÅŸiklik yaptÄ±k ve modelimizde her deÄŸiÅŸiklik yaptÄ±ÄŸÄ±mÄ±zda ne yapmamÄ±z gerekiyor? (Yeniden derlemek :) )

Ä°nce ayar yaptÄ±ÄŸÄ±mÄ±z iÃ§in, Ã¶nceki eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klardaki gÃ¼ncellemelerin Ã§ok bÃ¼yÃ¼k olmamasÄ±nÄ± saÄŸlamak iÃ§in 10 kat daha dÃ¼ÅŸÃ¼k bir Ã¶ÄŸrenme oranÄ± kullanacaÄŸÄ±z.


```python
model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(1e-4), # VarsayÄ±landan 10 kat daha dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±
              metrics=['accuracy'])
```

Model yeniden derlendi, istediÄŸimiz katmanlarÄ±n eÄŸitilebilir olduÄŸundan emin olmaya ne dersiniz?


```python
for layer in model.layers:
  print(layer.name, layer.trainable)
```

    input_layer True
    data_augmentation True
    efficientnetb0 True
    global_average_pooling True
    output_layer True



```python
for layer_number, layer in enumerate(base_model.layers):
  print(layer_number, layer.name, layer.trainable)
```

    0 input_1 False
    1 rescaling False
    2 normalization False
    3 stem_conv_pad False
    4 stem_conv False
    5 stem_bn False
    6 stem_activation False
    7 block1a_dwconv False
    8 block1a_bn False
    9 block1a_activation False
    10 block1a_se_squeeze False
    11 block1a_se_reshape False
    12 block1a_se_reduce False
    13 block1a_se_expand False
    14 block1a_se_excite False
    15 block1a_project_conv False
    16 block1a_project_bn False
    17 block2a_expand_conv False
    18 block2a_expand_bn False
    19 block2a_expand_activation False
    20 block2a_dwconv_pad False
    21 block2a_dwconv False
    22 block2a_bn False
    23 block2a_activation False
    24 block2a_se_squeeze False
    25 block2a_se_reshape False
    26 block2a_se_reduce False
    27 block2a_se_expand False
    28 block2a_se_excite False
    29 block2a_project_conv False
    30 block2a_project_bn False
    31 block2b_expand_conv False
    32 block2b_expand_bn False
    33 block2b_expand_activation False
    34 block2b_dwconv False
    35 block2b_bn False
    36 block2b_activation False
    37 block2b_se_squeeze False
    38 block2b_se_reshape False
    39 block2b_se_reduce False
    40 block2b_se_expand False
    41 block2b_se_excite False
    42 block2b_project_conv False
    43 block2b_project_bn False
    44 block2b_drop False
    45 block2b_add False
    46 block3a_expand_conv False
    47 block3a_expand_bn False
    48 block3a_expand_activation False
    49 block3a_dwconv_pad False
    50 block3a_dwconv False
    51 block3a_bn False
    52 block3a_activation False
    53 block3a_se_squeeze False
    54 block3a_se_reshape False
    55 block3a_se_reduce False
    56 block3a_se_expand False
    57 block3a_se_excite False
    58 block3a_project_conv False
    59 block3a_project_bn False
    60 block3b_expand_conv False
    61 block3b_expand_bn False
    62 block3b_expand_activation False
    63 block3b_dwconv False
    64 block3b_bn False
    65 block3b_activation False
    66 block3b_se_squeeze False
    67 block3b_se_reshape False
    68 block3b_se_reduce False
    69 block3b_se_expand False
    70 block3b_se_excite False
    71 block3b_project_conv False
    72 block3b_project_bn False
    73 block3b_drop False
    74 block3b_add False
    75 block4a_expand_conv False
    76 block4a_expand_bn False
    77 block4a_expand_activation False
    78 block4a_dwconv_pad False
    79 block4a_dwconv False
    80 block4a_bn False
    81 block4a_activation False
    82 block4a_se_squeeze False
    83 block4a_se_reshape False
    84 block4a_se_reduce False
    85 block4a_se_expand False
    86 block4a_se_excite False
    87 block4a_project_conv False
    88 block4a_project_bn False
    89 block4b_expand_conv False
    90 block4b_expand_bn False
    91 block4b_expand_activation False
    92 block4b_dwconv False
    93 block4b_bn False
    94 block4b_activation False
    95 block4b_se_squeeze False
    96 block4b_se_reshape False
    97 block4b_se_reduce False
    98 block4b_se_expand False
    99 block4b_se_excite False
    100 block4b_project_conv False
    101 block4b_project_bn False
    102 block4b_drop False
    103 block4b_add False
    104 block4c_expand_conv False
    105 block4c_expand_bn False
    106 block4c_expand_activation False
    107 block4c_dwconv False
    108 block4c_bn False
    109 block4c_activation False
    110 block4c_se_squeeze False
    111 block4c_se_reshape False
    112 block4c_se_reduce False
    113 block4c_se_expand False
    114 block4c_se_excite False
    115 block4c_project_conv False
    116 block4c_project_bn False
    117 block4c_drop False
    118 block4c_add False
    119 block5a_expand_conv False
    120 block5a_expand_bn False
    121 block5a_expand_activation False
    122 block5a_dwconv False
    123 block5a_bn False
    124 block5a_activation False
    125 block5a_se_squeeze False
    126 block5a_se_reshape False
    127 block5a_se_reduce False
    128 block5a_se_expand False
    129 block5a_se_excite False
    130 block5a_project_conv False
    131 block5a_project_bn False
    132 block5b_expand_conv False
    133 block5b_expand_bn False
    134 block5b_expand_activation False
    135 block5b_dwconv False
    136 block5b_bn False
    137 block5b_activation False
    138 block5b_se_squeeze False
    139 block5b_se_reshape False
    140 block5b_se_reduce False
    141 block5b_se_expand False
    142 block5b_se_excite False
    143 block5b_project_conv False
    144 block5b_project_bn False
    145 block5b_drop False
    146 block5b_add False
    147 block5c_expand_conv False
    148 block5c_expand_bn False
    149 block5c_expand_activation False
    150 block5c_dwconv False
    151 block5c_bn False
    152 block5c_activation False
    153 block5c_se_squeeze False
    154 block5c_se_reshape False
    155 block5c_se_reduce False
    156 block5c_se_expand False
    157 block5c_se_excite False
    158 block5c_project_conv False
    159 block5c_project_bn False
    160 block5c_drop False
    161 block5c_add False
    162 block6a_expand_conv False
    163 block6a_expand_bn False
    164 block6a_expand_activation False
    165 block6a_dwconv_pad False
    166 block6a_dwconv False
    167 block6a_bn False
    168 block6a_activation False
    169 block6a_se_squeeze False
    170 block6a_se_reshape False
    171 block6a_se_reduce False
    172 block6a_se_expand False
    173 block6a_se_excite False
    174 block6a_project_conv False
    175 block6a_project_bn False
    176 block6b_expand_conv False
    177 block6b_expand_bn False
    178 block6b_expand_activation False
    179 block6b_dwconv False
    180 block6b_bn False
    181 block6b_activation False
    182 block6b_se_squeeze False
    183 block6b_se_reshape False
    184 block6b_se_reduce False
    185 block6b_se_expand False
    186 block6b_se_excite False
    187 block6b_project_conv False
    188 block6b_project_bn False
    189 block6b_drop False
    190 block6b_add False
    191 block6c_expand_conv False
    192 block6c_expand_bn False
    193 block6c_expand_activation False
    194 block6c_dwconv False
    195 block6c_bn False
    196 block6c_activation False
    197 block6c_se_squeeze False
    198 block6c_se_reshape False
    199 block6c_se_reduce False
    200 block6c_se_expand False
    201 block6c_se_excite False
    202 block6c_project_conv False
    203 block6c_project_bn False
    204 block6c_drop False
    205 block6c_add False
    206 block6d_expand_conv False
    207 block6d_expand_bn False
    208 block6d_expand_activation False
    209 block6d_dwconv False
    210 block6d_bn False
    211 block6d_activation False
    212 block6d_se_squeeze False
    213 block6d_se_reshape False
    214 block6d_se_reduce False
    215 block6d_se_expand False
    216 block6d_se_excite False
    217 block6d_project_conv False
    218 block6d_project_bn False
    219 block6d_drop False
    220 block6d_add False
    221 block7a_expand_conv False
    222 block7a_expand_bn False
    223 block7a_expand_activation False
    224 block7a_dwconv False
    225 block7a_bn False
    226 block7a_activation False
    227 block7a_se_squeeze False
    228 block7a_se_reshape False
    229 block7a_se_reduce False
    230 block7a_se_expand False
    231 block7a_se_excite False
    232 block7a_project_conv True
    233 block7a_project_bn True
    234 top_conv True
    235 top_bn True
    236 top_activation True


MÃ¼kemmel! Modelimize ince ayar yapma zamanÄ±.

Herhangi bir yararÄ±n olup olmadÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in 5 epoch daha yeterli olmalÄ±dÄ±r (ancak her zaman daha fazlasÄ±nÄ± deneyebiliriz).

`Fit()` iÅŸlevindeki `initial_epoch` parametresini kullanarak Ã¶zellik Ã§Ä±karma modelinin kaldÄ±ÄŸÄ± yerden eÄŸitime baÅŸlayacaÄŸÄ±z.


```python
fine_tune_epochs = 10

history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,
                                                     epochs=fine_tune_epochs,
                                                     validation_data=test_data,
                                                     validation_steps=int(0.15 * len(test_data)), 
                                                     initial_epoch=history_all_classes_10_percent.epoch[-1]) 
```

    Epoch 5/10
    237/237 [==============================] - 65s 246ms/step - loss: 1.3694 - accuracy: 0.6510 - val_loss: 1.9126 - val_accuracy: 0.5024
    Epoch 6/10
    237/237 [==============================] - 56s 233ms/step - loss: 1.2323 - accuracy: 0.6706 - val_loss: 1.9015 - val_accuracy: 0.5106
    Epoch 7/10
    237/237 [==============================] - 54s 228ms/step - loss: 1.1418 - accuracy: 0.6969 - val_loss: 1.9327 - val_accuracy: 0.5021
    Epoch 8/10
    237/237 [==============================] - 54s 226ms/step - loss: 1.0874 - accuracy: 0.7119 - val_loss: 1.9087 - val_accuracy: 0.5026
    Epoch 9/10
    237/237 [==============================] - 51s 214ms/step - loss: 1.0345 - accuracy: 0.7236 - val_loss: 1.8899 - val_accuracy: 0.5037
    Epoch 10/10
    237/237 [==============================] - 51s 215ms/step - loss: 0.9691 - accuracy: 0.7391 - val_loss: 1.8552 - val_accuracy: 0.5154


Bir kez daha, eÄŸitim sÄ±rasÄ±nda test verilerinin sadece kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± deÄŸerlendiriyorduk, modelimizin tÃ¼m test verileri Ã¼zerinde nasÄ±l gittiÄŸini Ã¶ÄŸrenelim.


```python
results_all_classes_10_percent_fine_tune = model.evaluate(test_data)
results_all_classes_10_percent_fine_tune
```

    790/790 [==============================] - 90s 113ms/step - loss: 1.6013 - accuracy: 0.5789





    [1.6013119220733643, 0.578930675983429]



Hmm... GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz ince ayardan biraz gÃ¼Ã§ almÄ±ÅŸ.

`Compare_historys()` fonksiyonumuzu kullanarak ve eÄŸitim eÄŸrilerinin ne sÃ¶ylediÄŸini gÃ¶rerek daha iyi bir resim elde edebiliriz.


```python
compare_historys(original_history=history_all_classes_10_percent,
                 new_history=history_all_classes_10_percent_fine_tune,
                 initial_epochs=5)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_38_0.png)
    


Ä°nce ayardan sonra modelimizin eÄŸitim metrikleri Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸti, ancak doÄŸrulama Ã§ok fazla deÄŸil. GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz overfitting oldu.

Yine de sorun deÄŸil, Ã¶nceden eÄŸitilmiÅŸ bir modelin eÄŸitildiÄŸi veriler Ã¶zel verilerinize benzer olduÄŸunda, ince ayarÄ±n fazla uydurmaya yol aÃ§masÄ± Ã§ok sÄ±k gÃ¶rÃ¼lÃ¼r.

Bizim durumumuzda, Ã¶nceden eÄŸitilmiÅŸ modelimiz EfficientNetB0, tÄ±pkÄ± gÄ±da veri setimiz gibi birÃ§ok gerÃ§ek gÄ±da resmini iÃ§eren ImageNet Ã¼zerinde eÄŸitilmiÅŸtir.

Ã–zellik Ã§Ä±karma zaten iyi Ã§alÄ±ÅŸÄ±yorsa, ince ayardan gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z iyileÅŸtirmeler, veri kÃ¼meniz, temel modelinizin Ã¶nceden eÄŸitilmiÅŸ olduÄŸu verilerden Ã¶nemli Ã¶lÃ§Ã¼de farklÄ±ymÄ±ÅŸ gibi bÃ¼yÃ¼k olmayabilir.

## EÄŸitilmiÅŸ Modelimizi Kaydetme

Modelimizi sÄ±fÄ±rdan yeniden eÄŸitmek zorunda kalmamak iÃ§in `save()` yÃ¶ntemini kullanarak dosyaya kaydedelim.


```python
# model.save("drive/My Drive/")
```

## TÃ¼m FarklÄ± SÄ±nÄ±flarda BÃ¼yÃ¼k Modelin PerformansÄ±nÄ±n DeÄŸerlendirilmesi

KullandÄ±ÄŸÄ±mÄ±z deÄŸerlendirme Ã¶lÃ§Ã¼tlerine gÃ¶re oldukÃ§a iyi performans gÃ¶steren, eÄŸitilmiÅŸ ve kaydedilmiÅŸ bir modelimiz var.

Ama metrik ÅŸemalarÄ±, hadi modelimizin performansÄ±nÄ± biraz daha derinlemesine inceleyelim ve bazÄ± gÃ¶rselleÅŸtirmeler yapalÄ±m.

Bunu yapmak iÃ§in, kaydedilen modeli yÃ¼kleyeceÄŸiz ve bunu test veri setinde bazÄ± tahminler yapmak iÃ§in kullanacaÄŸÄ±z.

> ğŸ”‘ Not: Bir makine Ã¶ÄŸrenimi modelini deÄŸerlendirmek, eÄŸitmek kadar Ã¶nemlidir. Metrikler aldatÄ±cÄ± olabilir. Ä°yi gÃ¶rÃ¼nen eÄŸitim numaralarÄ±na aldanmadÄ±ÄŸÄ±nÄ±zdan emin olmak iÃ§in modelinizin performansÄ±nÄ± her zaman gÃ¶rÃ¼nmeyen veriler Ã¼zerinde gÃ¶rselleÅŸtirmelisiniz.


```python
import tensorflow as tf

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip
saved_model_path = "06_101_food_class_10_percent_saved_big_dog_model.zip"
unzip_data(saved_model_path)

model = tf.keras.models.load_model(saved_model_path.split(".")[0]) 
```

YÃ¼klenen modelimizin gerÃ§ekten eÄŸitilmiÅŸ bir model olduÄŸundan emin olmak iÃ§in, performansÄ±nÄ± test veri setinde deÄŸerlendirelim.


```python
loaded_loss, loaded_accuracy = model.evaluate(test_data)
loaded_loss, loaded_accuracy
```

    790/790 [==============================] - 92s 115ms/step - loss: 1.8027 - accuracy: 0.6078





    (1.8027206659317017, 0.6077623963356018)



OlaÄŸanÃ¼stÃ¼! YÃ¼klenen modelimiz, kaydetmeden Ã¶nceki kadar iyi performans gÃ¶steriyor gibi gÃ¶rÃ¼nÃ¼yor. BazÄ± tahminlerde bulunalÄ±m.

## EÄŸitimli Modelimiz ile Tahminler Yapmak

EÄŸitilmiÅŸ modelimizi deÄŸerlendirmek iÃ§in, onunla bazÄ± tahminler yapmamÄ±z ve ardÄ±ndan bu tahminleri test veri seti ile karÅŸÄ±laÅŸtÄ±rmamÄ±z gerekiyor.

Model, test veri setini hiÃ§ gÃ¶rmediÄŸi iÃ§in, bu bize modelin gerÃ§ek dÃ¼nyada eÄŸitildiÄŸi ÅŸeye benzer veriler Ã¼zerinde nasÄ±l performans gÃ¶stereceÄŸine dair bir gÃ¶sterge vermelidir.

EÄŸitilmiÅŸ modelimiz ile tahminler yapmak iÃ§in, test verilerini geÃ§erek `predict()` yÃ¶ntemini kullanabiliriz.

Verilerimiz Ã§ok sÄ±nÄ±flÄ± olduÄŸundan, bunu yapmak muhtemelen her Ã¶rnek iÃ§in bir tensÃ¶r tahmini dÃ¶ndÃ¼rÃ¼r.

BaÅŸka bir deyiÅŸle, eÄŸitilen model bir gÃ¶rÃ¼ntÃ¼yÃ¼ her gÃ¶rdÃ¼ÄŸÃ¼nde, onu eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrendiÄŸi tÃ¼m kalÄ±plarla karÅŸÄ±laÅŸtÄ±racak ve gÃ¶rÃ¼ntÃ¼nÃ¼n o sÄ±nÄ±f olma olasÄ±lÄ±ÄŸÄ±nÄ±n her sÄ±nÄ±f (101'inin tÃ¼mÃ¼) iÃ§in bir Ã§Ä±ktÄ± dÃ¶ndÃ¼recektir.


```python
pred_probs = model.predict(test_data, verbose=1)
```

    790/790 [==============================] - 64s 79ms/step


TÃ¼m test gÃ¶rÃ¼ntÃ¼lerini modelimize ilettik ve her birinde hangi gÄ±da olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼ hakkÄ±nda bir tahminde bulunmasÄ±nÄ± istedik.

Yani test veri setinde 25250 gÃ¶rselimiz olsaydÄ±, sizce kaÃ§ tahminimiz olmalÄ±?



```python
len(pred_probs)
```




    25250



Ve her gÃ¶rÃ¼ntÃ¼ 101 sÄ±nÄ±ftan biri olabilseydi, her gÃ¶rÃ¼ntÃ¼ iÃ§in kaÃ§ tahminimiz olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorsunuz?


```python
pred_probs.shape
```




    (25250, 101)



Sahip olduÄŸumuz ÅŸeye genellikle bir tahmin olasÄ±lÄ±k tensÃ¶rÃ¼ (veya dizi) denir.

BakalÄ±m ilk 10 nasÄ±l gÃ¶rÃ¼nÃ¼yor.


```python
pred_probs[:10]
```




    array([[5.95420077e-02, 3.57419503e-06, 4.13768589e-02, ...,
            1.41386813e-09, 8.35307583e-05, 3.08974274e-03],
           [9.64016676e-01, 1.37532707e-09, 8.47805641e-04, ...,
            5.42872003e-05, 7.83623513e-12, 9.84663906e-10],
           [9.59258676e-01, 3.25335823e-05, 1.48669467e-03, ...,
            7.18913384e-07, 5.43973158e-07, 4.02759651e-05],
           ...,
           [4.73132670e-01, 1.29312355e-07, 1.48055656e-03, ...,
            5.97501639e-04, 6.69690999e-05, 2.34693434e-05],
           [4.45719399e-02, 4.72655188e-07, 1.22585356e-01, ...,
            6.34984963e-06, 7.53185031e-06, 3.67787597e-03],
           [7.24390090e-01, 1.92497107e-09, 5.23109738e-05, ...,
            1.22913450e-03, 1.57926350e-09, 9.63957209e-05]], dtype=float32)



Pekala, elimizde gerÃ§ekten Ã§ok kÃ¼Ã§Ã¼k sayÄ±lar olan bir grup tensÃ¶r var gibi gÃ¶rÃ¼nÃ¼yor, bunlardan birini yakÄ±nlaÅŸtÄ±rmaya ne dersiniz?


```python
print(f"Number of prediction probabilities for sample 0: {len(pred_probs[0])}")
print(f"What prediction probability sample 0 looks like:\n {pred_probs[0]}")
print(f"The class with the highest predicted probability by the model for sample 0: {pred_probs[0].argmax()}")
```

    Number of prediction probabilities for sample 0: 101
    What prediction probability sample 0 looks like:
     [5.9542008e-02 3.5741950e-06 4.1376859e-02 1.0660556e-09 8.1613978e-09
     8.6639664e-09 8.0926822e-07 8.5652499e-07 1.9859017e-05 8.0977776e-07
     3.1727747e-09 9.8673661e-07 2.8532164e-04 7.8049051e-10 7.4230169e-04
     3.8916416e-05 6.4740193e-06 2.4977280e-06 3.7891099e-05 2.0678388e-07
     1.5538422e-05 8.1506943e-07 2.6230446e-06 2.0010630e-07 8.3827456e-07
     5.4215989e-06 3.7390860e-06 1.3150533e-08 2.7761406e-03 2.8051838e-05
     6.8562162e-10 2.5574835e-05 1.6688865e-04 7.6407297e-10 4.0452729e-04
     1.3150634e-08 1.7957379e-06 1.4448218e-06 2.3062859e-02 8.2466784e-07
     8.5365781e-07 1.7138614e-06 7.0525107e-06 1.8402169e-08 2.8553407e-07
     7.9483234e-06 2.0681514e-06 1.8525066e-07 3.3619774e-08 3.1522498e-04
     1.0410913e-05 8.5448539e-07 8.4741873e-01 1.0555415e-05 4.4094671e-07
     3.7404148e-05 3.5306231e-05 3.2489133e-05 6.7314817e-05 1.2852616e-08
     2.6219660e-10 1.0318080e-05 8.5744046e-05 1.0569896e-06 2.1293374e-06
     3.7637557e-05 7.5973162e-08 2.5340563e-04 9.2905600e-07 1.2598126e-04
     6.2621725e-06 1.2458752e-08 4.0519579e-05 6.8727985e-08 1.2546318e-06
     5.2887291e-08 7.5425071e-08 7.5398362e-05 7.7540375e-05 6.4025829e-07
     9.9033400e-07 2.2225820e-05 1.5013893e-05 1.4038504e-07 1.2232545e-05
     1.9044733e-02 4.9999417e-05 4.6226096e-06 1.5388227e-07 3.3824102e-07
     3.9228336e-09 1.6563691e-07 8.1320686e-05 4.8965021e-06 2.4068285e-07
     2.3124028e-05 3.1040650e-04 3.1379946e-05 1.4138681e-09 8.3530758e-05
     3.0897427e-03]
    The class with the highest predicted probability by the model for sample 0: 52


Daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, modelimize geÃ§tiÄŸimiz her gÃ¶rÃ¼ntÃ¼ tensÃ¶rÃ¼ iÃ§in, Ã§Ä±ktÄ± nÃ¶ronlarÄ±nÄ±n sayÄ±sÄ± ve son katmandaki aktivasyon fonksiyonu nedeniyle (`layers.Dense(len(train_data_all_10_percent.class_names), activation="softmax"`) Ã§Ä±ktÄ± verir. 101 sÄ±nÄ±fÄ±n her biri iÃ§in 0 ile 1 arasÄ±nda bir tahmin olasÄ±lÄ±ÄŸÄ± vardÄ±r.

Ve en yÃ¼ksek tahmin olasÄ±lÄ±ÄŸÄ±nÄ±n endeksi, modelin en olasÄ± etiket olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼ ÅŸey olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. Benzer ÅŸekilde, tahmin olasÄ±lÄ±k deÄŸeri ne kadar dÃ¼ÅŸÃ¼kse, model hedef gÃ¶rÃ¼ntÃ¼nÃ¼n o belirli sÄ±nÄ±f olduÄŸunu o kadar az dÃ¼ÅŸÃ¼nÃ¼r.

ğŸ”‘ Not: Softmax aktivasyon fonksiyonunun doÄŸasÄ± gereÄŸi, tek bir Ã¶rnek iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ±n her birinin toplamÄ± 1 (veya en azÄ±ndan 1'e Ã§ok yakÄ±n) olacaktÄ±r. Ã–rneÄŸin. pred_probs[0].sum() = 1.

`argmax()` yÃ¶ntemini kullanarak her tahmin olasÄ±lÄ±k tensÃ¶rÃ¼ndeki maksimum deÄŸerin indeksini bulabiliriz.


```python
pred_classes = pred_probs.argmax(axis=1)
pred_classes[:10]
```




    array([52,  0,  0, 80, 79, 61, 29,  0, 85,  0])



GÃ¼zel! ArtÄ±k test veri kÃ¼memizdeki Ã¶rneklerin her biri iÃ§in tahmin edilen sÄ±nÄ±f indeksine sahibiz.

Modelimizi daha fazla deÄŸerlendirmek iÃ§in bunlarÄ± test veri kÃ¼mesi etiketleriyle karÅŸÄ±laÅŸtÄ±rabileceÄŸiz.

Test veri kÃ¼mesi etiketlerini almak iÃ§in `unbatch()` yÃ¶ntemini kullanarak `test_data` nesnemizi (bir `tf.data.Dataset` biÃ§imindedir) Ã§Ã¶zebiliriz.

Bunu yapmak, test veri setindeki resimlere ve etiketlere eriÅŸmemizi saÄŸlayacaktÄ±r. Etiketler tek sÄ±cak (hot-encoding) kodlanmÄ±ÅŸ biÃ§imde olduÄŸundan, etiketin dizinini dÃ¶ndÃ¼rmek iÃ§in `argmax()` yÃ¶ntemini kullanacaÄŸÄ±z.

> ğŸ”‘ Not: Bu Ã§Ã¶zÃ¼lme, test verisi nesnesini oluÅŸtururken `shuffle=False` yapmamÄ±zÄ±n nedenidir. Aksi takdirde, test veri setini her yÃ¼klediÄŸimizde (tahmin yaparken olduÄŸu gibi), her seferinde karÄ±ÅŸtÄ±rÄ±lacaktÄ±, yani tahminlerimizi etiketlerle karÅŸÄ±laÅŸtÄ±rmaya Ã§alÄ±ÅŸsaydÄ±k, farklÄ± sÄ±rada olacaklardÄ±.


```python
y_labels = []
for images, labels in test_data.unbatch():
  y_labels.append(labels.numpy().argmax())
y_labels[:10]
```




    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]



GÃ¼zel! `test_data` karÄ±ÅŸtÄ±rÄ±lmadÄ±ÄŸÄ±ndan, `y_labels` dizisi, `pred_classes` dizisiyle aynÄ± sÄ±rada geri gelir.

Son kontrol, kaÃ§ etiketimiz olduÄŸunu gÃ¶rmek.


```python
len(y_labels)
```




    25250



BeklendiÄŸi gibi, etiket sayÄ±sÄ± elimizdeki gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±yla eÅŸleÅŸiyor. Modelimizin tahminlerini temel gerÃ§ek etiketleriyle karÅŸÄ±laÅŸtÄ±rma zamanÄ±.

## Model Tahminlerimizi DeÄŸerlendirme

Ã‡ok basit bir deÄŸerlendirme, doÄŸruluk etiketlerini tahmin edilen etiketlerle karÅŸÄ±laÅŸtÄ±ran ve bir doÄŸruluk puanÄ± dÃ¶ndÃ¼ren Scikit-Learn'Ã¼n `accuracy_score()` iÅŸlevini kullanmaktÄ±r.

`y_labels` ve `pred_classes` dizilerimizi doÄŸru bir ÅŸekilde oluÅŸturduysak, bu, daha Ã¶nce kullandÄ±ÄŸÄ±mÄ±z `evaluate()` yÃ¶ntemiyle aynÄ± doÄŸruluk deÄŸerini (veya en azÄ±ndan Ã§ok yakÄ±n) dÃ¶ndÃ¼rmelidir.


```python
from sklearn.metrics import accuracy_score
sklearn_accuracy = accuracy_score(y_labels, pred_classes)
sklearn_accuracy
```




    0.6077623762376237




```python
import numpy as np
print(f"Close? {np.isclose(loaded_accuracy, sklearn_accuracy)} | Difference: {loaded_accuracy - sklearn_accuracy}")
```

    Close? True | Difference: 2.0097978059574473e-08


Tamam, `pred_classes` dizimiz ve `y_labels` dizilerimiz doÄŸru sÄ±rada gÃ¶rÃ¼nÃ¼yor.

KarÄ±ÅŸÄ±klÄ±k matrisi ile biraz daha gÃ¶rsellik katmaya ne dersiniz?

Bunu yapmak iÃ§in, Ã¶nceki bir not defterinde oluÅŸturduÄŸumuz `make_confusion_matrix` iÅŸlevimizi kullanacaÄŸÄ±z.

Åu anda tahminlerimiz ve doÄŸruluk etiketlerimiz tamsayÄ±lar biÃ§imindedir, ancak gerÃ§ek adlarÄ±nÄ± alÄ±rsak anlamak Ã§ok daha kolay olacaktÄ±r. Bunu, `test_data` nesnemizde `class_names` niteliÄŸini kullanarak yapabiliriz.



```python
class_names = test_data.class_names
class_names
```




    ['apple_pie',
     'baby_back_ribs',
     'baklava',
     'beef_carpaccio',
     'beef_tartare',
     'beet_salad',
     'beignets',
     'bibimbap',
     'bread_pudding',
     'breakfast_burrito',
     'bruschetta',
     'caesar_salad',
     'cannoli',
     'caprese_salad',
     'carrot_cake',
     'ceviche',
     'cheese_plate',
     'cheesecake',
     'chicken_curry',
     'chicken_quesadilla',
     'chicken_wings',
     'chocolate_cake',
     'chocolate_mousse',
     'churros',
     'clam_chowder',
     'club_sandwich',
     'crab_cakes',
     'creme_brulee',
     'croque_madame',
     'cup_cakes',
     'deviled_eggs',
     'donuts',
     'dumplings',
     'edamame',
     'eggs_benedict',
     'escargots',
     'falafel',
     'filet_mignon',
     'fish_and_chips',
     'foie_gras',
     'french_fries',
     'french_onion_soup',
     'french_toast',
     'fried_calamari',
     'fried_rice',
     'frozen_yogurt',
     'garlic_bread',
     'gnocchi',
     'greek_salad',
     'grilled_cheese_sandwich',
     'grilled_salmon',
     'guacamole',
     'gyoza',
     'hamburger',
     'hot_and_sour_soup',
     'hot_dog',
     'huevos_rancheros',
     'hummus',
     'ice_cream',
     'lasagna',
     'lobster_bisque',
     'lobster_roll_sandwich',
     'macaroni_and_cheese',
     'macarons',
     'miso_soup',
     'mussels',
     'nachos',
     'omelette',
     'onion_rings',
     'oysters',
     'pad_thai',
     'paella',
     'pancakes',
     'panna_cotta',
     'peking_duck',
     'pho',
     'pizza',
     'pork_chop',
     'poutine',
     'prime_rib',
     'pulled_pork_sandwich',
     'ramen',
     'ravioli',
     'red_velvet_cake',
     'risotto',
     'samosa',
     'sashimi',
     'scallops',
     'seaweed_salad',
     'shrimp_and_grits',
     'spaghetti_bolognese',
     'spaghetti_carbonara',
     'spring_rolls',
     'steak',
     'strawberry_shortcake',
     'sushi',
     'tacos',
     'takoyaki',
     'tiramisu',
     'tuna_tartare',
     'waffles']




```python
make_confusion_matrix(y_true=y_labels,
                      y_pred=pred_classes,
                      classes=class_names,
                      figsize=(100, 100),
                      text_size=20,
                      norm=False,
                      savefig=True)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_69_0.png)
    


Vay! Åimdi bu bÃ¼yÃ¼k bir karÄ±ÅŸÄ±klÄ±k matrisi. Ä°lk baÅŸta biraz Ã¼rkÃ¼tÃ¼cÃ¼ gÃ¶rÃ¼nebilir ama biraz yakÄ±nlaÅŸtÄ±rdÄ±ktan sonra, hangi sÄ±nÄ±flarÄ±n "kafasÄ±nÄ±n karÄ±ÅŸtÄ±ÄŸÄ±" konusunda bize nasÄ±l fikir verdiÄŸini gÃ¶rebiliriz.

Ä°yi haber ÅŸu ki, tahminlerin Ã§oÄŸu sol Ã¼stten saÄŸ alt kÃ¶ÅŸeye doÄŸru, yani doÄŸrular.

Modelin kafasÄ± en Ã§ok, pig_chop Ã¶rnekleri iÃ§in filet_mignon ve tiramisu Ã¶rnekleri iÃ§in Chocolate_cake gibi gÃ¶rsel olarak benzer gÃ¶rÃ¼nen sÄ±nÄ±flarda karÄ±ÅŸÄ±yor gibi gÃ¶rÃ¼nÃ¼yor.

Bir sÄ±nÄ±flandÄ±rma problemi Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, Scikit-Learn'in `classification_report()` iÅŸlevini kullanarak modelimizin tahminlerini daha da deÄŸerlendirebiliriz.



```python
from sklearn.metrics import classification_report
print(classification_report(y_labels, pred_classes))
```

                  precision    recall  f1-score   support
    
               0       0.29      0.20      0.24       250
               1       0.51      0.69      0.59       250
               2       0.56      0.65      0.60       250
               3       0.74      0.53      0.62       250
               4       0.73      0.43      0.54       250
               5       0.34      0.54      0.42       250
               6       0.67      0.79      0.72       250
               7       0.82      0.76      0.79       250
               8       0.40      0.37      0.39       250
               9       0.62      0.44      0.51       250
              10       0.62      0.42      0.50       250
              11       0.84      0.49      0.62       250
              12       0.52      0.74      0.61       250
              13       0.56      0.60      0.58       250
              14       0.56      0.59      0.57       250
              15       0.44      0.32      0.37       250
              16       0.45      0.75      0.57       250
              17       0.37      0.51      0.43       250
              18       0.43      0.60      0.50       250
              19       0.68      0.60      0.64       250
              20       0.68      0.75      0.71       250
              21       0.35      0.64      0.45       250
              22       0.30      0.37      0.33       250
              23       0.66      0.77      0.71       250
              24       0.83      0.72      0.77       250
              25       0.76      0.71      0.73       250
              26       0.51      0.42      0.46       250
              27       0.78      0.72      0.75       250
              28       0.70      0.69      0.69       250
              29       0.70      0.68      0.69       250
              30       0.92      0.63      0.75       250
              31       0.78      0.70      0.74       250
              32       0.75      0.83      0.79       250
              33       0.89      0.98      0.94       250
              34       0.68      0.78      0.72       250
              35       0.78      0.66      0.72       250
              36       0.53      0.56      0.55       250
              37       0.30      0.55      0.39       250
              38       0.78      0.63      0.69       250
              39       0.27      0.33      0.30       250
              40       0.72      0.81      0.76       250
              41       0.81      0.62      0.70       250
              42       0.50      0.58      0.54       250
              43       0.75      0.60      0.67       250
              44       0.74      0.45      0.56       250
              45       0.77      0.85      0.81       250
              46       0.81      0.46      0.58       250
              47       0.44      0.49      0.46       250
              48       0.45      0.81      0.58       250
              49       0.50      0.44      0.47       250
              50       0.54      0.39      0.46       250
              51       0.71      0.86      0.78       250
              52       0.51      0.77      0.61       250
              53       0.67      0.68      0.68       250
              54       0.88      0.75      0.81       250
              55       0.86      0.69      0.76       250
              56       0.56      0.24      0.34       250
              57       0.62      0.45      0.52       250
              58       0.68      0.58      0.62       250
              59       0.70      0.37      0.49       250
              60       0.83      0.59      0.69       250
              61       0.54      0.81      0.65       250
              62       0.72      0.49      0.58       250
              63       0.94      0.86      0.90       250
              64       0.78      0.85      0.81       250
              65       0.82      0.82      0.82       250
              66       0.69      0.32      0.44       250
              67       0.41      0.58      0.48       250
              68       0.90      0.78      0.83       250
              69       0.84      0.82      0.83       250
              70       0.62      0.83      0.71       250
              71       0.81      0.46      0.59       250
              72       0.64      0.65      0.65       250
              73       0.51      0.44      0.47       250
              74       0.72      0.61      0.66       250
              75       0.84      0.90      0.87       250
              76       0.78      0.78      0.78       250
              77       0.36      0.27      0.31       250
              78       0.79      0.74      0.76       250
              79       0.44      0.81      0.57       250
              80       0.57      0.60      0.59       250
              81       0.65      0.70      0.68       250
              82       0.38      0.31      0.34       250
              83       0.58      0.80      0.67       250
              84       0.61      0.38      0.47       250
              85       0.44      0.74      0.55       250
              86       0.71      0.86      0.78       250
              87       0.41      0.39      0.40       250
              88       0.83      0.80      0.81       250
              89       0.71      0.31      0.43       250
              90       0.92      0.69      0.79       250
              91       0.83      0.87      0.85       250
              92       0.68      0.65      0.67       250
              93       0.31      0.38      0.34       250
              94       0.61      0.54      0.57       250
              95       0.74      0.61      0.67       250
              96       0.56      0.29      0.38       250
              97       0.45      0.74      0.56       250
              98       0.47      0.33      0.39       250
              99       0.52      0.27      0.35       250
             100       0.59      0.70      0.64       250
    
        accuracy                           0.61     25250
       macro avg       0.63      0.61      0.61     25250
    weighted avg       0.63      0.61      0.61     25250
    


`classification_report()`, sÄ±nÄ±f baÅŸÄ±na kesinlik, geri Ã§aÄŸÄ±rma ve f1-skorunun Ã§Ä±ktÄ±sÄ±nÄ± verir.

Bir hatÄ±rlatÄ±cÄ±:

- **Precision** - GerÃ§ek pozitiflerin toplam numune sayÄ±sÄ±na oranÄ±. Daha yÃ¼ksek hassasiyet, daha az yanlÄ±ÅŸ pozitife yol aÃ§ar (model 0 olmasÄ± gerektiÄŸinde 1'i tahmin eder).
- **Recall** - GerÃ§ek pozitiflerin toplam gerÃ§ek pozitif ve yanlÄ±ÅŸ negatif sayÄ±sÄ±na oranÄ± (model, 1 olmasÄ± gerektiÄŸinde 0'Ä± tahmin eder). Daha yÃ¼ksek hatÄ±rlama, daha az yanlÄ±ÅŸ negatife yol aÃ§ar.
- **F1 Score **- Kesinlik ve hatÄ±rlamayÄ± tek bir metrikte birleÅŸtirir. 1 en iyisidir, 0 en kÃ¶tÃ¼sÃ¼dÃ¼r.

YukarÄ±daki Ã§Ä±ktÄ± yardÄ±mcÄ± olur, ancak bu kadar Ã§ok sÄ±nÄ±fla anlaÅŸÄ±lmasÄ± biraz zor.

Bir gÃ¶rselleÅŸtirme yardÄ±mÄ±yla bunu kolaylaÅŸtÄ±rÄ±p kolaylaÅŸtÄ±rmayacaÄŸÄ±mÄ±za bakalÄ±m.

Ä°lk olarak, `output_dict=True` ayarÄ±nÄ± yaparak `classification_report()` Ã§Ä±ktÄ±sÄ±nÄ± sÃ¶zlÃ¼k olarak alacaÄŸÄ±z.


```python
classification_report_dict = classification_report(y_labels, pred_classes, output_dict=True)
classification_report_dict
```




    {'0': {'f1-score': 0.24056603773584903,
      'precision': 0.29310344827586204,
      'recall': 0.204,
      'support': 250},
     '1': {'f1-score': 0.5864406779661017,
      'precision': 0.5088235294117647,
      'recall': 0.692,
      'support': 250},
     '10': {'f1-score': 0.5047619047619047,
      'precision': 0.6235294117647059,
      'recall': 0.424,
      'support': 250},
     '100': {'f1-score': 0.641025641025641,
      'precision': 0.5912162162162162,
      'recall': 0.7,
      'support': 250},
     '11': {'f1-score': 0.6161616161616161,
      'precision': 0.8356164383561644,
      'recall': 0.488,
      'support': 250},
     '12': {'f1-score': 0.6105610561056106,
      'precision': 0.5196629213483146,
      'recall': 0.74,
      'support': 250},
     '13': {'f1-score': 0.5775193798449612,
      'precision': 0.5601503759398496,
      'recall': 0.596,
      'support': 250},
     '14': {'f1-score': 0.574757281553398,
      'precision': 0.5584905660377358,
      'recall': 0.592,
      'support': 250},
     '15': {'f1-score': 0.36744186046511623,
      'precision': 0.4388888888888889,
      'recall': 0.316,
      'support': 250},
     '16': {'f1-score': 0.5654135338345864,
      'precision': 0.4530120481927711,
      'recall': 0.752,
      'support': 250},
     '17': {'f1-score': 0.42546063651591287,
      'precision': 0.3659942363112392,
      'recall': 0.508,
      'support': 250},
     '18': {'f1-score': 0.5008403361344538,
      'precision': 0.4318840579710145,
      'recall': 0.596,
      'support': 250},
     '19': {'f1-score': 0.6411889596602972,
      'precision': 0.6832579185520362,
      'recall': 0.604,
      'support': 250},
     '2': {'f1-score': 0.6022304832713754,
      'precision': 0.5625,
      'recall': 0.648,
      'support': 250},
     '20': {'f1-score': 0.7123809523809523,
      'precision': 0.68,
      'recall': 0.748,
      'support': 250},
     '21': {'f1-score': 0.45261669024045265,
      'precision': 0.350109409190372,
      'recall': 0.64,
      'support': 250},
     '22': {'f1-score': 0.3291592128801431,
      'precision': 0.2977346278317152,
      'recall': 0.368,
      'support': 250},
     '23': {'f1-score': 0.7134935304990757,
      'precision': 0.6632302405498282,
      'recall': 0.772,
      'support': 250},
     '24': {'f1-score': 0.7708779443254817,
      'precision': 0.8294930875576036,
      'recall': 0.72,
      'support': 250},
     '25': {'f1-score': 0.734020618556701,
      'precision': 0.7574468085106383,
      'recall': 0.712,
      'support': 250},
     '26': {'f1-score': 0.4625550660792952,
      'precision': 0.5147058823529411,
      'recall': 0.42,
      'support': 250},
     '27': {'f1-score': 0.7494824016563146,
      'precision': 0.776824034334764,
      'recall': 0.724,
      'support': 250},
     '28': {'f1-score': 0.6935483870967742,
      'precision': 0.6991869918699187,
      'recall': 0.688,
      'support': 250},
     '29': {'f1-score': 0.6910569105691057,
      'precision': 0.7024793388429752,
      'recall': 0.68,
      'support': 250},
     '3': {'f1-score': 0.616822429906542,
      'precision': 0.7415730337078652,
      'recall': 0.528,
      'support': 250},
     '30': {'f1-score': 0.7476190476190476,
      'precision': 0.9235294117647059,
      'recall': 0.628,
      'support': 250},
     '31': {'f1-score': 0.7357293868921776,
      'precision': 0.7802690582959642,
      'recall': 0.696,
      'support': 250},
     '32': {'f1-score': 0.7855787476280836,
      'precision': 0.7472924187725631,
      'recall': 0.828,
      'support': 250},
     '33': {'f1-score': 0.9371428571428572,
      'precision': 0.8945454545454545,
      'recall': 0.984,
      'support': 250},
     '34': {'f1-score': 0.7238805970149255,
      'precision': 0.6783216783216783,
      'recall': 0.776,
      'support': 250},
     '35': {'f1-score': 0.715835140997831,
      'precision': 0.7819905213270142,
      'recall': 0.66,
      'support': 250},
     '36': {'f1-score': 0.5475728155339805,
      'precision': 0.5320754716981132,
      'recall': 0.564,
      'support': 250},
     '37': {'f1-score': 0.3870056497175141,
      'precision': 0.29912663755458513,
      'recall': 0.548,
      'support': 250},
     '38': {'f1-score': 0.6946902654867257,
      'precision': 0.7772277227722773,
      'recall': 0.628,
      'support': 250},
     '39': {'f1-score': 0.29749103942652333,
      'precision': 0.2694805194805195,
      'recall': 0.332,
      'support': 250},
     '4': {'f1-score': 0.544080604534005,
      'precision': 0.7346938775510204,
      'recall': 0.432,
      'support': 250},
     '40': {'f1-score': 0.7622641509433963,
      'precision': 0.7214285714285714,
      'recall': 0.808,
      'support': 250},
     '41': {'f1-score': 0.7029478458049886,
      'precision': 0.8115183246073299,
      'recall': 0.62,
      'support': 250},
     '42': {'f1-score': 0.537037037037037,
      'precision': 0.5,
      'recall': 0.58,
      'support': 250},
     '43': {'f1-score': 0.6651884700665188,
      'precision': 0.746268656716418,
      'recall': 0.6,
      'support': 250},
     '44': {'f1-score': 0.5586034912718205,
      'precision': 0.7417218543046358,
      'recall': 0.448,
      'support': 250},
     '45': {'f1-score': 0.8114285714285714,
      'precision': 0.7745454545454545,
      'recall': 0.852,
      'support': 250},
     '46': {'f1-score': 0.5831202046035805,
      'precision': 0.8085106382978723,
      'recall': 0.456,
      'support': 250},
     '47': {'f1-score': 0.4641509433962264,
      'precision': 0.4392857142857143,
      'recall': 0.492,
      'support': 250},
     '48': {'f1-score': 0.577524893314367,
      'precision': 0.4481236203090508,
      'recall': 0.812,
      'support': 250},
     '49': {'f1-score': 0.47234042553191485,
      'precision': 0.5045454545454545,
      'recall': 0.444,
      'support': 250},
     '5': {'f1-score': 0.41860465116279066,
      'precision': 0.34177215189873417,
      'recall': 0.54,
      'support': 250},
     '50': {'f1-score': 0.45581395348837206,
      'precision': 0.5444444444444444,
      'recall': 0.392,
      'support': 250},
     '51': {'f1-score': 0.7783783783783783,
      'precision': 0.7081967213114754,
      'recall': 0.864,
      'support': 250},
     '52': {'f1-score': 0.6124401913875598,
      'precision': 0.5092838196286472,
      'recall': 0.768,
      'support': 250},
     '53': {'f1-score': 0.6759443339960238,
      'precision': 0.6719367588932806,
      'recall': 0.68,
      'support': 250},
     '54': {'f1-score': 0.8103448275862069,
      'precision': 0.8785046728971962,
      'recall': 0.752,
      'support': 250},
     '55': {'f1-score': 0.7644444444444444,
      'precision': 0.86,
      'recall': 0.688,
      'support': 250},
     '56': {'f1-score': 0.3398328690807799,
      'precision': 0.5596330275229358,
      'recall': 0.244,
      'support': 250},
     '57': {'f1-score': 0.5209302325581396,
      'precision': 0.6222222222222222,
      'recall': 0.448,
      'support': 250},
     '58': {'f1-score': 0.6233766233766233,
      'precision': 0.6792452830188679,
      'recall': 0.576,
      'support': 250},
     '59': {'f1-score': 0.486910994764398,
      'precision': 0.7045454545454546,
      'recall': 0.372,
      'support': 250},
     '6': {'f1-score': 0.7229357798165138,
      'precision': 0.6677966101694915,
      'recall': 0.788,
      'support': 250},
     '60': {'f1-score': 0.6885245901639344,
      'precision': 0.8305084745762712,
      'recall': 0.588,
      'support': 250},
     '61': {'f1-score': 0.6495176848874598,
      'precision': 0.543010752688172,
      'recall': 0.808,
      'support': 250},
     '62': {'f1-score': 0.5823389021479712,
      'precision': 0.7218934911242604,
      'recall': 0.488,
      'support': 250},
     '63': {'f1-score': 0.895397489539749,
      'precision': 0.9385964912280702,
      'recall': 0.856,
      'support': 250},
     '64': {'f1-score': 0.8129770992366412,
      'precision': 0.7773722627737226,
      'recall': 0.852,
      'support': 250},
     '65': {'f1-score': 0.82, 'precision': 0.82, 'recall': 0.82, 'support': 250},
     '66': {'f1-score': 0.44141689373297005,
      'precision': 0.6923076923076923,
      'recall': 0.324,
      'support': 250},
     '67': {'f1-score': 0.47840531561461797,
      'precision': 0.4090909090909091,
      'recall': 0.576,
      'support': 250},
     '68': {'f1-score': 0.832618025751073,
      'precision': 0.8981481481481481,
      'recall': 0.776,
      'support': 250},
     '69': {'f1-score': 0.8340080971659919,
      'precision': 0.8442622950819673,
      'recall': 0.824,
      'support': 250},
     '7': {'f1-score': 0.7908902691511386,
      'precision': 0.8197424892703863,
      'recall': 0.764,
      'support': 250},
     '70': {'f1-score': 0.7101200686106347,
      'precision': 0.6216216216216216,
      'recall': 0.828,
      'support': 250},
     '71': {'f1-score': 0.5903307888040712,
      'precision': 0.8111888111888111,
      'recall': 0.464,
      'support': 250},
     '72': {'f1-score': 0.6468253968253969,
      'precision': 0.6417322834645669,
      'recall': 0.652,
      'support': 250},
     '73': {'f1-score': 0.4743589743589744,
      'precision': 0.5091743119266054,
      'recall': 0.444,
      'support': 250},
     '74': {'f1-score': 0.658008658008658,
      'precision': 0.7169811320754716,
      'recall': 0.608,
      'support': 250},
     '75': {'f1-score': 0.8665377176015473,
      'precision': 0.8389513108614233,
      'recall': 0.896,
      'support': 250},
     '76': {'f1-score': 0.7808764940239045,
      'precision': 0.7777777777777778,
      'recall': 0.784,
      'support': 250},
     '77': {'f1-score': 0.30875576036866365,
      'precision': 0.3641304347826087,
      'recall': 0.268,
      'support': 250},
     '78': {'f1-score': 0.7603305785123966,
      'precision': 0.7863247863247863,
      'recall': 0.736,
      'support': 250},
     '79': {'f1-score': 0.571830985915493,
      'precision': 0.44130434782608696,
      'recall': 0.812,
      'support': 250},
     '8': {'f1-score': 0.3866943866943867,
      'precision': 0.4025974025974026,
      'recall': 0.372,
      'support': 250},
     '80': {'f1-score': 0.5870841487279843,
      'precision': 0.5747126436781609,
      'recall': 0.6,
      'support': 250},
     '81': {'f1-score': 0.6756756756756757,
      'precision': 0.6529850746268657,
      'recall': 0.7,
      'support': 250},
     '82': {'f1-score': 0.34285714285714286,
      'precision': 0.3804878048780488,
      'recall': 0.312,
      'support': 250},
     '83': {'f1-score': 0.6711409395973154,
      'precision': 0.5780346820809249,
      'recall': 0.8,
      'support': 250},
     '84': {'f1-score': 0.4653465346534653,
      'precision': 0.6103896103896104,
      'recall': 0.376,
      'support': 250},
     '85': {'f1-score': 0.5525525525525525,
      'precision': 0.4423076923076923,
      'recall': 0.736,
      'support': 250},
     '86': {'f1-score': 0.7783783783783783,
      'precision': 0.7081967213114754,
      'recall': 0.864,
      'support': 250},
     '87': {'f1-score': 0.3975409836065574,
      'precision': 0.40756302521008403,
      'recall': 0.388,
      'support': 250},
     '88': {'f1-score': 0.8130081300813008,
      'precision': 0.8264462809917356,
      'recall': 0.8,
      'support': 250},
     '89': {'f1-score': 0.4301675977653631,
      'precision': 0.7129629629629629,
      'recall': 0.308,
      'support': 250},
     '9': {'f1-score': 0.5117370892018779,
      'precision': 0.6193181818181818,
      'recall': 0.436,
      'support': 250},
     '90': {'f1-score': 0.7881548974943051,
      'precision': 0.9153439153439153,
      'recall': 0.692,
      'support': 250},
     '91': {'f1-score': 0.84765625,
      'precision': 0.8282442748091603,
      'recall': 0.868,
      'support': 250},
     '92': {'f1-score': 0.6652977412731006,
      'precision': 0.6835443037974683,
      'recall': 0.648,
      'support': 250},
     '93': {'f1-score': 0.34234234234234234,
      'precision': 0.3114754098360656,
      'recall': 0.38,
      'support': 250},
     '94': {'f1-score': 0.5714285714285714,
      'precision': 0.6118721461187214,
      'recall': 0.536,
      'support': 250},
     '95': {'f1-score': 0.6710526315789473,
      'precision': 0.7427184466019418,
      'recall': 0.612,
      'support': 250},
     '96': {'f1-score': 0.3809523809523809,
      'precision': 0.5625,
      'recall': 0.288,
      'support': 250},
     '97': {'f1-score': 0.5644916540212443,
      'precision': 0.4547677261613692,
      'recall': 0.744,
      'support': 250},
     '98': {'f1-score': 0.3858823529411765,
      'precision': 0.4685714285714286,
      'recall': 0.328,
      'support': 250},
     '99': {'f1-score': 0.35356200527704484,
      'precision': 0.5193798449612403,
      'recall': 0.268,
      'support': 250},
     'accuracy': 0.6077623762376237,
     'macro avg': {'f1-score': 0.6061252197245781,
      'precision': 0.6328666845830312,
      'recall': 0.6077623762376237,
      'support': 25250},
     'weighted avg': {'f1-score': 0.606125219724578,
      'precision': 0.6328666845830311,
      'recall': 0.6077623762376237,
      'support': 25250}}



Pekala, burada hala birkaÃ§ deÄŸer var, biraz daraltmaya ne dersiniz?

f1-skoru, recall ve precission tek bir metrikte birleÅŸtirdiÄŸinden, buna odaklanalÄ±m.

Bunu ayÄ±klamak iÃ§in `class_f1_scores` adÄ±nda boÅŸ bir sÃ¶zlÃ¼k oluÅŸturacaÄŸÄ±z ve ardÄ±ndan sÄ±nÄ±f adÄ±nÄ± ve `f1-score`'u anahtar olarak, class_f1_scores iÃ§indeki deÄŸer Ã§iftlerini ekleyerek `classification_report_dict` iÃ§indeki her Ã¶ÄŸe arasÄ±nda dolaÅŸacaÄŸÄ±z.



```python
class_f1_scores = {}
for k, v in classification_report_dict.items():
  if k == "accuracy":
    break
  else:
    class_f1_scores[class_names[int(k)]] = v["f1-score"]
class_f1_scores
```




    {'apple_pie': 0.24056603773584903,
     'baby_back_ribs': 0.5864406779661017,
     'baklava': 0.6022304832713754,
     'beef_carpaccio': 0.616822429906542,
     'beef_tartare': 0.544080604534005,
     'beet_salad': 0.41860465116279066,
     'beignets': 0.7229357798165138,
     'bibimbap': 0.7908902691511386,
     'bread_pudding': 0.3866943866943867,
     'breakfast_burrito': 0.5117370892018779,
     'bruschetta': 0.5047619047619047,
     'caesar_salad': 0.6161616161616161,
     'cannoli': 0.6105610561056106,
     'caprese_salad': 0.5775193798449612,
     'carrot_cake': 0.574757281553398,
     'ceviche': 0.36744186046511623,
     'cheese_plate': 0.5654135338345864,
     'cheesecake': 0.42546063651591287,
     'chicken_curry': 0.5008403361344538,
     'chicken_quesadilla': 0.6411889596602972,
     'chicken_wings': 0.7123809523809523,
     'chocolate_cake': 0.45261669024045265,
     'chocolate_mousse': 0.3291592128801431,
     'churros': 0.7134935304990757,
     'clam_chowder': 0.7708779443254817,
     'club_sandwich': 0.734020618556701,
     'crab_cakes': 0.4625550660792952,
     'creme_brulee': 0.7494824016563146,
     'croque_madame': 0.6935483870967742,
     'cup_cakes': 0.6910569105691057,
     'deviled_eggs': 0.7476190476190476,
     'donuts': 0.7357293868921776,
     'dumplings': 0.7855787476280836,
     'edamame': 0.9371428571428572,
     'eggs_benedict': 0.7238805970149255,
     'escargots': 0.715835140997831,
     'falafel': 0.5475728155339805,
     'filet_mignon': 0.3870056497175141,
     'fish_and_chips': 0.6946902654867257,
     'foie_gras': 0.29749103942652333,
     'french_fries': 0.7622641509433963,
     'french_onion_soup': 0.7029478458049886,
     'french_toast': 0.537037037037037,
     'fried_calamari': 0.6651884700665188,
     'fried_rice': 0.5586034912718205,
     'frozen_yogurt': 0.8114285714285714,
     'garlic_bread': 0.5831202046035805,
     'gnocchi': 0.4641509433962264,
     'greek_salad': 0.577524893314367,
     'grilled_cheese_sandwich': 0.47234042553191485,
     'grilled_salmon': 0.45581395348837206,
     'guacamole': 0.7783783783783783,
     'gyoza': 0.6124401913875598,
     'hamburger': 0.6759443339960238,
     'hot_and_sour_soup': 0.8103448275862069,
     'hot_dog': 0.7644444444444444,
     'huevos_rancheros': 0.3398328690807799,
     'hummus': 0.5209302325581396,
     'ice_cream': 0.6233766233766233,
     'lasagna': 0.486910994764398,
     'lobster_bisque': 0.6885245901639344,
     'lobster_roll_sandwich': 0.6495176848874598,
     'macaroni_and_cheese': 0.5823389021479712,
     'macarons': 0.895397489539749,
     'miso_soup': 0.8129770992366412,
     'mussels': 0.82,
     'nachos': 0.44141689373297005,
     'omelette': 0.47840531561461797,
     'onion_rings': 0.832618025751073,
     'oysters': 0.8340080971659919,
     'pad_thai': 0.7101200686106347,
     'paella': 0.5903307888040712,
     'pancakes': 0.6468253968253969,
     'panna_cotta': 0.4743589743589744,
     'peking_duck': 0.658008658008658,
     'pho': 0.8665377176015473,
     'pizza': 0.7808764940239045,
     'pork_chop': 0.30875576036866365,
     'poutine': 0.7603305785123966,
     'prime_rib': 0.571830985915493,
     'pulled_pork_sandwich': 0.5870841487279843,
     'ramen': 0.6756756756756757,
     'ravioli': 0.34285714285714286,
     'red_velvet_cake': 0.6711409395973154,
     'risotto': 0.4653465346534653,
     'samosa': 0.5525525525525525,
     'sashimi': 0.7783783783783783,
     'scallops': 0.3975409836065574,
     'seaweed_salad': 0.8130081300813008,
     'shrimp_and_grits': 0.4301675977653631,
     'spaghetti_bolognese': 0.7881548974943051,
     'spaghetti_carbonara': 0.84765625,
     'spring_rolls': 0.6652977412731006,
     'steak': 0.34234234234234234,
     'strawberry_shortcake': 0.5714285714285714,
     'sushi': 0.6710526315789473,
     'tacos': 0.3809523809523809,
     'takoyaki': 0.5644916540212443,
     'tiramisu': 0.3858823529411765,
     'tuna_tartare': 0.35356200527704484,
     'waffles': 0.641025641025641}



Ä°yi gÃ¶rÃ¼nÃ¼yor!

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re sÃ¶zlÃ¼ÄŸÃ¼mÃ¼z sÄ±nÄ±f isimlerine gÃ¶re sÄ±ralanmÄ±ÅŸ. Ancak, farklÄ± puanlarÄ± gÃ¶rselleÅŸtirmeye Ã§alÄ±ÅŸÄ±yorsak, bir tÃ¼r dÃ¼zende olmalarÄ± daha hoÅŸ gÃ¶rÃ¼nebilir.

class_f1_scores sÃ¶zlÃ¼ÄŸÃ¼mÃ¼zÃ¼ bir panda DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼relim ve artan biÃ§imde sÄ±ralayalÄ±m mÄ±?



```python
import pandas as pd
f1_scores = pd.DataFrame({"class_name": list(class_f1_scores.keys()),
                          "f1-score": list(class_f1_scores.values())}).sort_values("f1-score", ascending=False)
f1_scores
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class_name</th>
      <th>f1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>33</th>
      <td>edamame</td>
      <td>0.937143</td>
    </tr>
    <tr>
      <th>63</th>
      <td>macarons</td>
      <td>0.895397</td>
    </tr>
    <tr>
      <th>75</th>
      <td>pho</td>
      <td>0.866538</td>
    </tr>
    <tr>
      <th>91</th>
      <td>spaghetti_carbonara</td>
      <td>0.847656</td>
    </tr>
    <tr>
      <th>69</th>
      <td>oysters</td>
      <td>0.834008</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>56</th>
      <td>huevos_rancheros</td>
      <td>0.339833</td>
    </tr>
    <tr>
      <th>22</th>
      <td>chocolate_mousse</td>
      <td>0.329159</td>
    </tr>
    <tr>
      <th>77</th>
      <td>pork_chop</td>
      <td>0.308756</td>
    </tr>
    <tr>
      <th>39</th>
      <td>foie_gras</td>
      <td>0.297491</td>
    </tr>
    <tr>
      <th>0</th>
      <td>apple_pie</td>
      <td>0.240566</td>
    </tr>
  </tbody>
</table>
<p>101 rows Ã— 2 columns</p>
</div>




```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(12, 25))
scores = ax.barh(range(len(f1_scores)), f1_scores["f1-score"].values)
ax.set_yticks(range(len(f1_scores)))
ax.set_yticklabels(list(f1_scores["class_name"]))
ax.set_xlabel("f1-score")
ax.set_title("F1-Scores for 10 Different Classes")
ax.invert_yaxis();

def autolabel(rects): 
  for rect in rects:
    width = rect.get_width()
    ax.text(1.03*width, rect.get_y() + rect.get_height()/1.5,
            f"{width:.2f}",
            ha='center', va='bottom')

autolabel(scores)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_78_0.png)
    


Åimdi bu iyi gÃ¶rÃ¼nen bir grafik! Yani, metin konumlandÄ±rma biraz geliÅŸtirilebilir ama ÅŸimdilik idare eder.

Modelimizin tahminlerini gÃ¶rselleÅŸtirmenin bize performansÄ±na dair tamamen yeni bir fikir verdiÄŸini gÃ¶rebiliyor musunuz?

BirkaÃ§ dakika Ã¶nce yalnÄ±zca bir doÄŸruluk puanÄ±mÄ±z vardÄ±, ancak ÅŸimdi modelimizin sÄ±nÄ±f bazÄ±nda ne kadar iyi performans gÃ¶sterdiÄŸinin bir gÃ¶stergesine sahibiz.

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz apple_pie ve ravioli gibi sÄ±nÄ±flarda oldukÃ§a dÃ¼ÅŸÃ¼k performans gÃ¶sterirken, edamame ve pho gibi sÄ±nÄ±flar iÃ§in performans oldukÃ§a yÃ¼ksek.

Bunun gibi bulgular bize deneylerimizde nereye gidebileceÄŸimize dair ipuÃ§larÄ± veriyor. Belki de kÃ¶tÃ¼ performans gÃ¶steren sÄ±nÄ±flar hakkÄ±nda daha fazla veri toplamamÄ±z gerekebilir veya belki de en kÃ¶tÃ¼ performans gÃ¶steren sÄ±nÄ±flar hakkÄ±nda tahminde bulunmak zordur.

## Test GÃ¶rÃ¼ntÃ¼lerinde Tahminleri GÃ¶rselleÅŸtirme

GerÃ§ek test zamanÄ±. Tahminleri gerÃ§ek gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde gÃ¶rselleÅŸtirme. Ä°stediÄŸiniz tÃ¼m metriklere bakabilirsiniz, ancak bazÄ± tahminleri gÃ¶rselleÅŸtirene kadar modelinizin nasÄ±l performans gÃ¶sterdiÄŸini gerÃ§ekten bilemezsiniz.

HalihazÄ±rda, modelimiz seÃ§tiÄŸimiz herhangi bir gÃ¶rÃ¼ntÃ¼ Ã¼zerinde tahminde bulunamaz. GÃ¶rÃ¼ntÃ¼ Ã¶nce bir tensÃ¶re yÃ¼klenmelidir.

Bu nedenle, herhangi bir gÃ¶rÃ¼ntÃ¼ Ã¼zerinde tahminde bulunmaya baÅŸlamak iÃ§in, bir gÃ¶rÃ¼ntÃ¼yÃ¼ bir tensÃ¶re yÃ¼klemek iÃ§in bir fonksiyon oluÅŸturacaÄŸÄ±z.

Spesifik olarak:

- `tf.io.read_file(`) kullanarak bir hedef gÃ¶rÃ¼ntÃ¼ dosya yolunu okuyun.
- `tf.io.decode_image()` kullanarak gÃ¶rÃ¼ntÃ¼yÃ¼ bir TensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n.
- GÃ¶rÃ¼ntÃ¼yÃ¼, `tf.image.resize()` kullanarak modelimizin Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ± (224 x 224) gÃ¶rÃ¼ntÃ¼lerle aynÄ± boyutta olacak ÅŸekilde yeniden boyutlandÄ±rÄ±n.
- Gerekirse 0 ve 1 arasÄ±ndaki tÃ¼m piksel deÄŸerlerini elde etmek iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ Ã¶lÃ§eklendirin.


```python
def load_and_prep_image(filename, img_shape=224, scale=True):
  img = tf.io.read_file(filename)
  img = tf.io.decode_image(img)
  img = tf.image.resize(img, [img_shape, img_shape])
  if scale:
    return img/255.
  else:
    return img
```

GÃ¶rÃ¼ntÃ¼ yÃ¼kleme ve Ã¶n iÅŸleme iÅŸlevi hazÄ±r.

Åimdi bir kod yazalÄ±m:

Test veri kÃ¼mesinden birkaÃ§ rastgele gÃ¶rÃ¼ntÃ¼ yÃ¼kleyin.
Onlarla ilgili tahminlerde bulunun.
Modelin tahmin edilen etiketi, tahmin olasÄ±lÄ±ÄŸÄ± ve kesin doÄŸruluk etiketi ile birlikte orijinal gÃ¶rÃ¼ntÃ¼leri Ã§izin.


```python
import os
import random

plt.figure(figsize=(17, 10))
for i in range(3):
  class_name = random.choice(class_names)
  filename = random.choice(os.listdir(test_dir + "/" + class_name))
  filepath = test_dir + class_name + "/" + filename

  img = load_and_prep_image(filepath, scale=False) 
  pred_prob = model.predict(tf.expand_dims(img, axis=0)) 
  pred_class = class_names[pred_prob.argmax()] 

  plt.subplot(1, 3, i+1)
  plt.imshow(img/255.)
  if class_name == pred_class:
    title_color = "g"
  else:
    title_color = "r"
  plt.title(f"actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}", c=title_color)
  plt.axis(False);
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_83_0.png)
    


Yeterince rastgele Ã¶rneklemden geÃ§tikten sonra, modelin gÃ¶rsel olarak benzer sÄ±nÄ±flarda, baby_back_ribs'in biftekle karÄ±ÅŸtÄ±rÄ±lmasÄ± ve bunun tersi gibi Ã§ok daha kÃ¶tÃ¼ tahminler yapma eÄŸiliminde olduÄŸu netlik kazanmaya baÅŸlar.

## En YanlÄ±ÅŸ Tahminleri Bulma

NasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair iyi bir fikir edinmek iÃ§in modelinizin tahminlerinin en az 100'den fazla rastgele Ã¶rneÄŸini gÃ¶zden geÃ§irmek iyi bir fikirdir.

Bir sÃ¼re sonra, modelin bazÄ± gÃ¶rÃ¼ntÃ¼lerde Ã§ok yÃ¼ksek tahmin olasÄ±lÄ±ÄŸÄ± ile tahmin yaptÄ±ÄŸÄ±nÄ± fark edebilirsiniz, yani tahmininden Ã§ok emin ama yine de etiketi yanlÄ±ÅŸ anlÄ±yor.

Bu en yanlÄ±ÅŸ tahminler, modelinizin performansÄ± hakkÄ±nda daha fazla bilgi edinmenize yardÄ±mcÄ± olabilir.

Ã–yleyse, modelin bir gÃ¶rÃ¼ntÃ¼ iÃ§in yÃ¼ksek bir tahmin olasÄ±lÄ±ÄŸÄ± verdiÄŸi (Ã¶rneÄŸin 0.95+) ancak tahmini yanlÄ±ÅŸ yaptÄ±ÄŸÄ± tÃ¼m tahminleri toplamak iÃ§in bir kod yazalÄ±m.

AÅŸaÄŸÄ±daki adÄ±mlardan geÃ§eceÄŸiz:

1. `list_files()` yÃ¶ntemini kullanarak test veri kÃ¼mesindeki tÃ¼m gÃ¶rÃ¼ntÃ¼ dosyasÄ± yollarÄ±nÄ± alÄ±n.
2. GÃ¶rÃ¼ntÃ¼ dosya yollarÄ±nÄ±n, kesin doÄŸruluk etiketlerinin, tahmin sÄ±nÄ±flarÄ±nÄ±n, maksimum tahmin olasÄ±lÄ±klarÄ±nÄ±n, kesin gerÃ§ek sÄ±nÄ±f adlarÄ±nÄ±n ve tahmin edilen sÄ±nÄ±f adlarÄ±nÄ±n pandas DataFrame'ini oluÅŸturun.
  - **Not:** Mutlaka bÃ¶yle bir DataFrame oluÅŸturmamÄ±z gerekmez, ancak bu, ilerledikÃ§e iÅŸleri gÃ¶rselleÅŸtirmemize yardÄ±mcÄ± olur.
3. TÃ¼m yanlÄ±ÅŸ tahminleri bulmak iÃ§in DataFrame'imizi kullanÄ±n (temel gerÃ§eÄŸin tahminle eÅŸleÅŸmediÄŸi durumlarda).
4. DataFrame'i yanlÄ±ÅŸ tahminlere ve en yÃ¼ksek maksimum tahmin olasÄ±lÄ±klarÄ±na gÃ¶re sÄ±ralayÄ±n.
5. GÃ¶rÃ¼ntÃ¼leri en yÃ¼ksek tahmin olasÄ±lÄ±klarÄ± ile gÃ¶rselleÅŸtirin, ancak yanlÄ±ÅŸ tahmine sahip olun.


```python
# 1.adÄ±m
filepaths = []
for filepath in test_data.list_files("101_food_classes_10_percent/test/*/*.jpg", 
                                     shuffle=False):
  filepaths.append(filepath.numpy())
filepaths[:10]
```




    [b'101_food_classes_10_percent/test/apple_pie/1011328.jpg',
     b'101_food_classes_10_percent/test/apple_pie/101251.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1034399.jpg',
     b'101_food_classes_10_percent/test/apple_pie/103801.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1038694.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1047447.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1068632.jpg',
     b'101_food_classes_10_percent/test/apple_pie/110043.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1106961.jpg',
     b'101_food_classes_10_percent/test/apple_pie/1113017.jpg']



Åimdi tÃ¼m test gÃ¶rÃ¼ntÃ¼ dosya yollarÄ±na sahibiz, bunlarÄ± aÅŸaÄŸÄ±dakilerle birlikte bir DataFrame'de birleÅŸtirelim:

- Temel doÄŸruluk etiketleri (y_labels).
- Modelin Ã¶ngÃ¶rdÃ¼ÄŸÃ¼ sÄ±nÄ±f (pred_classes).
- Maksimum tahmin olasÄ±lÄ±k deÄŸeri (pred_probs.max(axis=1)).
- Temel doÄŸruluk sÄ±nÄ±fÄ± adlarÄ±.
- Ã–ngÃ¶rÃ¼len sÄ±nÄ±f adlarÄ±.




```python
# 2.adÄ±m
import pandas as pd
pred_df = pd.DataFrame({"img_path": filepaths,
                        "y_true": y_labels,
                        "y_pred": pred_classes,
                        "pred_conf": pred_probs.max(axis=1),
                        "y_true_classname": [class_names[i] for i in y_labels],
                        "y_pred_classname": [class_names[i] for i in pred_classes]}) 
pred_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_path</th>
      <th>y_true</th>
      <th>y_pred</th>
      <th>pred_conf</th>
      <th>y_true_classname</th>
      <th>y_pred_classname</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>52</td>
      <td>0.847419</td>
      <td>apple_pie</td>
      <td>gyoza</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>0</td>
      <td>0.964017</td>
      <td>apple_pie</td>
      <td>apple_pie</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>0</td>
      <td>0.959259</td>
      <td>apple_pie</td>
      <td>apple_pie</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>80</td>
      <td>0.658606</td>
      <td>apple_pie</td>
      <td>pulled_pork_sandwich</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>79</td>
      <td>0.367900</td>
      <td>apple_pie</td>
      <td>prime_rib</td>
    </tr>
  </tbody>
</table>
</div>



GÃ¼zel! Tahminin doÄŸru mu yanlÄ±ÅŸ mÄ± olduÄŸunu bize anlatan basit bir sÃ¼tun yapmaya ne dersiniz?


```python
# 3.adÄ±m
pred_df["pred_correct"] = pred_df["y_true"] == pred_df["y_pred"]
pred_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_path</th>
      <th>y_true</th>
      <th>y_pred</th>
      <th>pred_conf</th>
      <th>y_true_classname</th>
      <th>y_pred_classname</th>
      <th>pred_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>52</td>
      <td>0.847419</td>
      <td>apple_pie</td>
      <td>gyoza</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>0</td>
      <td>0.964017</td>
      <td>apple_pie</td>
      <td>apple_pie</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>0</td>
      <td>0.959259</td>
      <td>apple_pie</td>
      <td>apple_pie</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>80</td>
      <td>0.658606</td>
      <td>apple_pie</td>
      <td>pulled_pork_sandwich</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/1...</td>
      <td>0</td>
      <td>79</td>
      <td>0.367900</td>
      <td>apple_pie</td>
      <td>prime_rib</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



Ve ÅŸimdi hangi tahminlerin doÄŸru veya yanlÄ±ÅŸ olduÄŸunu ve tahmin olasÄ±lÄ±klarÄ±yla birlikte bildiÄŸimize gÃ¶re, yanlÄ±ÅŸ tahminleri sÄ±ralayarak ve tahmin olasÄ±lÄ±klarÄ±nÄ± azaltarak "en yanlÄ±ÅŸ" 100 tahmini elde etmeye ne dersiniz?


```python
# 4.adÄ±m
top_100_wrong = pred_df[pred_df["pred_correct"] == False].sort_values("pred_conf", ascending=False)[:100]
top_100_wrong.head(20)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>img_path</th>
      <th>y_true</th>
      <th>y_pred</th>
      <th>pred_conf</th>
      <th>y_true_classname</th>
      <th>y_pred_classname</th>
      <th>pred_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21810</th>
      <td>b'101_food_classes_10_percent/test/scallops/17...</td>
      <td>87</td>
      <td>29</td>
      <td>0.999997</td>
      <td>scallops</td>
      <td>cup_cakes</td>
      <td>False</td>
    </tr>
    <tr>
      <th>231</th>
      <td>b'101_food_classes_10_percent/test/apple_pie/8...</td>
      <td>0</td>
      <td>100</td>
      <td>0.999995</td>
      <td>apple_pie</td>
      <td>waffles</td>
      <td>False</td>
    </tr>
    <tr>
      <th>15359</th>
      <td>b'101_food_classes_10_percent/test/lobster_rol...</td>
      <td>61</td>
      <td>53</td>
      <td>0.999988</td>
      <td>lobster_roll_sandwich</td>
      <td>hamburger</td>
      <td>False</td>
    </tr>
    <tr>
      <th>23539</th>
      <td>b'101_food_classes_10_percent/test/strawberry_...</td>
      <td>94</td>
      <td>83</td>
      <td>0.999987</td>
      <td>strawberry_shortcake</td>
      <td>red_velvet_cake</td>
      <td>False</td>
    </tr>
    <tr>
      <th>21400</th>
      <td>b'101_food_classes_10_percent/test/samosa/3140...</td>
      <td>85</td>
      <td>92</td>
      <td>0.999981</td>
      <td>samosa</td>
      <td>spring_rolls</td>
      <td>False</td>
    </tr>
    <tr>
      <th>24540</th>
      <td>b'101_food_classes_10_percent/test/tiramisu/16...</td>
      <td>98</td>
      <td>83</td>
      <td>0.999947</td>
      <td>tiramisu</td>
      <td>red_velvet_cake</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2511</th>
      <td>b'101_food_classes_10_percent/test/bruschetta/...</td>
      <td>10</td>
      <td>61</td>
      <td>0.999945</td>
      <td>bruschetta</td>
      <td>lobster_roll_sandwich</td>
      <td>False</td>
    </tr>
    <tr>
      <th>5574</th>
      <td>b'101_food_classes_10_percent/test/chocolate_m...</td>
      <td>22</td>
      <td>21</td>
      <td>0.999939</td>
      <td>chocolate_mousse</td>
      <td>chocolate_cake</td>
      <td>False</td>
    </tr>
    <tr>
      <th>17855</th>
      <td>b'101_food_classes_10_percent/test/paella/2314...</td>
      <td>71</td>
      <td>65</td>
      <td>0.999931</td>
      <td>paella</td>
      <td>mussels</td>
      <td>False</td>
    </tr>
    <tr>
      <th>23797</th>
      <td>b'101_food_classes_10_percent/test/sushi/16593...</td>
      <td>95</td>
      <td>86</td>
      <td>0.999904</td>
      <td>sushi</td>
      <td>sashimi</td>
      <td>False</td>
    </tr>
    <tr>
      <th>18001</th>
      <td>b'101_food_classes_10_percent/test/pancakes/10...</td>
      <td>72</td>
      <td>67</td>
      <td>0.999904</td>
      <td>pancakes</td>
      <td>omelette</td>
      <td>False</td>
    </tr>
    <tr>
      <th>11642</th>
      <td>b'101_food_classes_10_percent/test/garlic_brea...</td>
      <td>46</td>
      <td>10</td>
      <td>0.999877</td>
      <td>garlic_bread</td>
      <td>bruschetta</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10847</th>
      <td>b'101_food_classes_10_percent/test/fried_calam...</td>
      <td>43</td>
      <td>68</td>
      <td>0.999872</td>
      <td>fried_calamari</td>
      <td>onion_rings</td>
      <td>False</td>
    </tr>
    <tr>
      <th>23631</th>
      <td>b'101_food_classes_10_percent/test/strawberry_...</td>
      <td>94</td>
      <td>83</td>
      <td>0.999858</td>
      <td>strawberry_shortcake</td>
      <td>red_velvet_cake</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1155</th>
      <td>b'101_food_classes_10_percent/test/beef_tartar...</td>
      <td>4</td>
      <td>5</td>
      <td>0.999858</td>
      <td>beef_tartare</td>
      <td>beet_salad</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10854</th>
      <td>b'101_food_classes_10_percent/test/fried_calam...</td>
      <td>43</td>
      <td>68</td>
      <td>0.999854</td>
      <td>fried_calamari</td>
      <td>onion_rings</td>
      <td>False</td>
    </tr>
    <tr>
      <th>23904</th>
      <td>b'101_food_classes_10_percent/test/sushi/33652...</td>
      <td>95</td>
      <td>86</td>
      <td>0.999823</td>
      <td>sushi</td>
      <td>sashimi</td>
      <td>False</td>
    </tr>
    <tr>
      <th>7316</th>
      <td>b'101_food_classes_10_percent/test/cup_cakes/1...</td>
      <td>29</td>
      <td>83</td>
      <td>0.999816</td>
      <td>cup_cakes</td>
      <td>red_velvet_cake</td>
      <td>False</td>
    </tr>
    <tr>
      <th>13144</th>
      <td>b'101_food_classes_10_percent/test/gyoza/31214...</td>
      <td>52</td>
      <td>92</td>
      <td>0.999799</td>
      <td>gyoza</td>
      <td>spring_rolls</td>
      <td>False</td>
    </tr>
    <tr>
      <th>10880</th>
      <td>b'101_food_classes_10_percent/test/fried_calam...</td>
      <td>43</td>
      <td>68</td>
      <td>0.999778</td>
      <td>fried_calamari</td>
      <td>onion_rings</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>



Ã‡ok ilginÃ§... sadece temel doÄŸruluk sÄ±nÄ±f adÄ± (y_true_classname) ve tahmin sÄ±nÄ±f adÄ± sÃ¼tununu (y_pred_classname) karÅŸÄ±laÅŸtÄ±rarak herhangi bir eÄŸilim fark ettiniz mi?

OnlarÄ± gÃ¶rselleÅŸtirirsek daha kolay olabilir.


```python
images_to_view = 9
start_index = 10 
plt.figure(figsize=(15, 10))
for i, row in enumerate(top_100_wrong[start_index:start_index+images_to_view].itertuples()): 
  plt.subplot(3, 3, i+1)
  img = load_and_prep_image(row[1], scale=True)
  _, _, _, _, pred_prob, y_true, y_pred, _ = row 
  plt.imshow(img)
  plt.title(f"actual: {y_true}, pred: {y_pred} \nprob: {pred_prob:.2f}")
  plt.axis(False)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_94_0.png)
    


Modelin en yanlÄ±ÅŸ tahminlerini incelemek genellikle birkaÃ§ ÅŸeyi anlamaya yardÄ±mcÄ± olabilir:

- BazÄ± etiketler yanlÄ±ÅŸ olabilir - Modelimiz yeterince iyi olursa, aslÄ±nda belirli sÄ±nÄ±flarda Ã§ok iyi tahmin yapmayÄ± Ã¶ÄŸrenebilir. Bu, modelin doÄŸru etiketi Ã¶ngÃ¶rdÃ¼ÄŸÃ¼ bazÄ± gÃ¶rÃ¼ntÃ¼lerin, temel doÄŸruluk etiketinin yanlÄ±ÅŸ olmasÄ± durumunda yanlÄ±ÅŸ olarak gÃ¶sterilebileceÄŸi anlamÄ±na gelir. Durum buysa, modelimizi veri kÃ¼melerimizdeki etiketleri iyileÅŸtirmemize ve dolayÄ±sÄ±yla gelecekteki modelleri potansiyel olarak daha iyi hale getirmemize yardÄ±mcÄ± olmasÄ± iÃ§in sÄ±klÄ±kla kullanabiliriz. Etiketleri geliÅŸtirmeye yardÄ±mcÄ± olmak iÃ§in modeli kullanma sÃ¼recine genellikle [aktif Ã¶ÄŸrenme](https://blog.scaleway.com/active-learning-some-datapoints-are-more-equal-than-others/) denir.
- Daha fazla Ã¶rnek toplanabilir mi? - Belirli bir sÄ±nÄ±f iÃ§in kÃ¶tÃ¼ tahmin edilen yinelenen bir model varsa, daha fazla modelleri geliÅŸtirmek iÃ§in o belirli sÄ±nÄ±ftan farklÄ± senaryolarda daha fazla Ã¶rnek toplamak iyi bir fikir olabilir.

## BÃ¼yÃ¼k Modeli Test GÃ¶rÃ¼ntÃ¼lerinde ve AyrÄ±ca Ã–zel GÄ±da GÃ¶rÃ¼ntÃ¼lerinde Test Edin

Åimdiye kadar test veri setinden modelimizin bazÄ± tahminlerini gÃ¶rselleÅŸtirdik, ancak gerÃ§ek testin zamanÄ± geldi: kendi Ã¶zel yiyecek gÃ¶rÃ¼ntÃ¼lerimiz Ã¼zerinde tahminler yapmak iÃ§in modelimizi kullanacaÄŸÄ±z
Bunun iÃ§in kendi resimlerinizi Google Colab'a yÃ¼klemek veya bir klasÃ¶re koyarak not defterine yÃ¼klemek isteyebilirsiniz.

Benim durumumda, Ã§eÅŸitli yiyeceklerin altÄ± ya da daha fazla gÃ¶rÃ¼ntÃ¼sÃ¼nden oluÅŸan kendi kÃ¼Ã§Ã¼k veri setimi hazÄ±rladÄ±m.

BunlarÄ± indirelim ve unzip edelim.


```python
!gdown --id 12hVGYlCfhagSGjPb80uR0BOjZOHN1SvA
unzip_data("custom_food_images.zip")
```

    Downloading...
    From: https://drive.google.com/uc?id=12hVGYlCfhagSGjPb80uR0BOjZOHN1SvA
    To: /content/custom_food_images.zip
    13.2MB [00:00, 207MB/s]


Harika, bunlarÄ± yÃ¼kleyebilir ve `load_and_prep_image()` iÅŸlevimizi kullanarak tensÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rebiliriz ama Ã¶nce bir gÃ¶rÃ¼ntÃ¼ dosyayollarÄ± listesine ihtiyacÄ±mÄ±z var.


```python
custom_food_images = ["custom_food_images/" + img_path for img_path in os.listdir("custom_food_images")]
custom_food_images
```




    ['custom_food_images/pizza-dad.jpeg',
     'custom_food_images/hamburger.jpeg',
     'custom_food_images/chicken_wings.jpeg',
     'custom_food_images/steak.jpeg',
     'custom_food_images/sushi.jpeg',
     'custom_food_images/ramen.jpeg']



ArtÄ±k daha Ã¶nce resimlerimize yÃ¼klemek iÃ§in kullandÄ±ÄŸÄ±mÄ±za benzer bir kod kullanabilir, eÄŸitimli modelimizi kullanarak her biri iÃ§in bir tahminde bulunabilir ve ardÄ±ndan resmi tahmin edilen sÄ±nÄ±fla birlikte Ã§izebiliriz.


```python
for img in custom_food_images:
  img = load_and_prep_image(img, scale=False) 
  pred_prob = model.predict(tf.expand_dims(img, axis=0))
  pred_class = class_names[pred_prob.argmax()] 
  plt.figure()
  plt.imshow(img/255.)
  plt.title(f"pred: {pred_class}, prob: {pred_prob.max():.2f}")
  plt.axis(False)
```


    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_0.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_1.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_2.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_3.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_4.png)
    



    
![png](TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_files/TensorFlow_ile_Transfer_Learning_%C3%96l%C3%A7eklendirme_%28Scaling_Up%29_101_5.png)
    


Bir makine Ã¶ÄŸrenimi modelinin Ã¶nceden hazÄ±rlanmÄ±ÅŸ bir test veri setinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek harika ama kendi verileriniz Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek akÄ±llara durgunluk veriyor.

Ve tahmin edin ne oldu... modelimiz eÄŸitim gÃ¶rÃ¼ntÃ¼lerinin yalnÄ±zca %10'u ile bu inanÄ±lmaz sonuÃ§larÄ± (temel deÄŸerden %10+ daha iyi) elde etti.
