Bu konuya baÅŸlamadan Ã¶nce aÅŸaÄŸÄ±da bulunan kavramlar Ã§ok iyi bir ÅŸekilde anlaÅŸÄ±lmasÄ± gerekiyor.

## Regresyon Analizi Nedir?

**Regresyon analizi, iki ya da daha Ã§ok nicel deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§mek iÃ§in kullanÄ±lan analiz metodudur.** EÄŸer tek bir deÄŸiÅŸken kullanÄ±larak analiz yapÄ±lÄ±yorsa buna tek deÄŸiÅŸkenli regresyon, birden Ã§ok deÄŸiÅŸken kullanÄ±lÄ±yorsa Ã§ok deÄŸiÅŸkenli regresyon analizi olarak isimlendirilir. Regresyon analizi ile deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin varlÄ±ÄŸÄ±, eÄŸer iliÅŸki var ise bunun gÃ¼cÃ¼ hakkÄ±nda bilgi edinilebilir. 

Ã–rneÄŸin; <br>
Bir daire satÄ±n almayÄ± dÃ¼ÅŸÃ¼nÃ¼yorsunuz. Bu dairenin fiyatÄ±nÄ± belirleyen birden Ã§ok unsur vardÄ±r. Ã–rnek:
- Toplu taÅŸÄ±maya yakÄ±nlÄ±ÄŸÄ±
- ManzarasÄ±
- KaÃ§Ä±ncÄ± katta olduÄŸu
- BinanÄ±n yapÄ±m yÄ±lÄ±

gibi benzeri bir Ã§ok unsur binanÄ±n fiyatÄ±nÄ± belirleyen Ã¶nemli faktÃ¶rlerdir. 

Regresyonda, deÄŸiÅŸkenlerden biri baÄŸÄ±mlÄ± diÄŸerleri baÄŸÄ±msÄ±z deÄŸiÅŸken olmalÄ±dÄ±r. 


## Yapay Sinir AÄŸÄ± Nedir?

Yapay sinir aÄŸlarÄ± (YSA), insan beyninin bilgi iÅŸleme tekniÄŸinden esinlenerek geliÅŸtirilmiÅŸ bir bilgi iÅŸlem teknolojisidir. YSA ile basit biyolojik sinir sisteminin Ã§alÄ±ÅŸma ÅŸekli taklit edilir. Yani biyolojik nÃ¶ron hÃ¼crelerinin ve bu hÃ¼crelerin birbirleri ile arasÄ±nda kurduÄŸu sinaptik baÄŸÄ±n dijital olarak modellenmesidir.

NÃ¶ronlar Ã§eÅŸitli ÅŸekillerde birbirlerine baÄŸlanarak aÄŸlar oluÅŸtururlar. Bu aÄŸlar Ã¶ÄŸrenme, hafÄ±zaya alma ve veriler arasÄ±ndaki iliÅŸkiyi ortaya Ã§Ä±karma kapasitesine sahiptirler. DiÄŸer bir ifadeyle, YSA'lar, normalde bir insanÄ±n dÃ¼ÅŸÃ¼nme ve gÃ¶zlemlemeye yÃ¶nelik doÄŸal yeteneklerini gerektiren problemlere Ã§Ã¶zÃ¼m Ã¼retmektedir. Bir insanÄ±n, dÃ¼ÅŸÃ¼nme ve gÃ¶zlemleme yeteneklerini gerektiren problemlere yÃ¶nelik Ã§Ã¶zÃ¼mler Ã¼retebilmesinin temel sebebi ise insan beyninin ve dolayÄ±sÄ±yla insanÄ±n sahip olduÄŸu yaÅŸayarak veya deneyerek Ã¶ÄŸrenme yeteneÄŸidir.

Yapay Sinir AÄŸlarÄ±nÄ±n AvantajlarÄ±
- Yapay Sinir AÄŸlarÄ± bir Ã§ok hÃ¼creden meydana gelir ve bu hÃ¼creler eÅŸ zamanlÄ± Ã§alÄ±ÅŸarak karmaÅŸÄ±k iÅŸleri gerÃ§ekleÅŸtirir.
- Ã–ÄŸrenme kabiliyeti vardÄ±r ve farklÄ± Ã¶ÄŸrenme algoritmalarÄ±yla Ã¶ÄŸrenebilirler.
- GÃ¶rÃ¼lmemiÅŸ Ã§Ä±ktÄ±lar iÃ§in sonuÃ§ (bilgi) Ã¼retebilirler. GÃ¶zetimsiz Ã¶ÄŸrenim sÃ¶z konusudur.
- Ã–rÃ¼ntÃ¼ tanÄ±ma ve sÄ±nÄ±flandÄ±rma yapabilirler. Eksik Ã¶rÃ¼ntÃ¼leri tamamlayabilirler.
- Hata toleransÄ±na sahiptirler. Eksik veya belirsiz bilgiyle Ã§alÄ±ÅŸabilirler. HatalÄ± durumlarda dereceli bozulma (graceful degradation) gÃ¶sterirler.
- Paralel Ã§alÄ±ÅŸabilmekte ve gerÃ§ek zamanlÄ± bilgiyi iÅŸleyebilmektedirler.

### Yapay Sinir AÄŸlarÄ±nÄ±n SÄ±nÄ±flandÄ±rÄ±lmasÄ±

#### Tek KatmanlÄ± Yapay Sinir AÄŸlarÄ±
Tek katmanlÄ± yapay sinir aÄŸlarÄ± sadece girdi ve Ã§Ä±ktÄ± katmanlarÄ±ndan oluÅŸur. Ã‡Ä±ktÄ± Ã¼niteleri bÃ¼tÃ¼n girdi Ã¼nitelerine (X) baÄŸlanmaktadÄ±r ve her baÄŸlantÄ±nÄ±n bir aÄŸÄ±rlÄ±ÄŸÄ± (W) vardÄ±r. 

#### Ã‡ok KatmanlÄ± Yapay Sinir AÄŸlarÄ±

DoÄŸrusal olmayan problemlerin Ã§Ã¶zÃ¼mÃ¼ iÃ§in uygun bir aÄŸ yapÄ±sÄ±dÄ±r. Bu sebeple daha karÄ±ÅŸÄ±k problemlerin Ã§Ã¶zÃ¼mÃ¼nde kullanÄ±lÄ±r. KarÄ±ÅŸÄ±k problemlerin modeli olmasÄ± aÄŸÄ±n eÄŸitimini zorlaÅŸtÄ±ran bir yapÄ±ya bÃ¼rÃ¼nmesine sebep olur. Tek katmanlÄ± aÄŸ yapÄ±sÄ±na gÃ¶re daha karmaÅŸÄ±k bir yapÄ±dadÄ±r. Fakat problem Ã§Ã¶zÃ¼mlerinde genellikle Ã§ok katmanlÄ± aÄŸ yapÄ±sÄ± kullanÄ±lÄ±r Ã§Ã¼nkÃ¼ tek katmanlÄ± yapÄ±lara gÃ¶re daha baÅŸarÄ±lÄ± sonuÃ§lar verir. Ã‡ok katmanlÄ± yapay sinir aÄŸlarÄ± modellerinde en az 1 adet gizli katman bulunur.

### Yapay Sinir HÃ¼cresi

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/1200px-Neuron_Hand-tuned.svg.png" />

CanlÄ±lardaki sinir hÃ¼crelerinin biyolojik gÃ¶rÃ¼nÃ¼mÃ¼ yukarÄ±da gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ÅŸekildeki gibidir. Ã‡ekirdeÄŸimiz var ve bir akson boyunca iletim yapÄ±lÄ±yor. Burada Ã§Ä±kÄ±ÅŸ terminallerinde dentrit uclarÄ±ndan elde edilen sensÃ¶r verilerimiz Ã§ekirdekte aÄŸÄ±rlandÄ±rÄ±larak akson boyunca iletiliyor ve baÅŸka sinir hÃ¼cresine baÄŸlanÄ±yor. Bu ÅŸekilde sinirler arasÄ± iletiÅŸim saÄŸlanmÄ±ÅŸ oluyor.

Ä°nsandaki bir sinir hÃ¼cresinin matematiksel modeli ise ÅŸu ÅŸekilde gÃ¶sterilebilir:

<img src="https://mesutpiskin.com/blog/wp-content/uploads/2017/08/ysa_matematiksel_modeli.png" />

Dentrit dediÄŸimiz yollar boyunca aÄŸÄ±rlÄ±klarÄ±mÄ±z mevcut ve bu dentritlere giren bir baÅŸka nÃ¶rondan da gelmiÅŸ olabilecek bir giriÅŸ deÄŸerimiz (x0 ) var. GiriÅŸ deÄŸerimiz ve dentritteki aÄŸÄ±rlÄ±ÄŸÄ±mÄ±z(w0) Ã§arpÄ±ldÄ±ktan sonra( w0x0)  sinir hÃ¼cresine iletilir ve sinir hÃ¼cresinde bu Ã§arpma iÅŸlemi yapÄ±lÄ±yor ve tÃ¼m dentritlerden gelen aÄŸÄ±rlÄ±k ile giriÅŸ Ã§arpÄ±mlarÄ± toplanÄ±r. Yani aÄŸÄ±rlÄ±klÄ± toplama iÅŸlemi yapÄ±lÄ±r. ArdÄ±ndan bir bias(b) ile toplandÄ±ktan sonra aktivasyon fonksiyonu ardÄ±ndan Ã§Ä±kÄ±ÅŸa aktarÄ±lÄ±r. Bu Ã§Ä±kÄ±ÅŸ nihai Ã§Ä±kÄ±ÅŸ olabileceÄŸi gibi bir baÅŸka hÃ¼crenin giriÅŸi olabilir. Matematiksel olarak aÄŸÄ±rlÄ±klar ile giriÅŸler Ã§arpÄ±lÄ±r artÄ± bir bias eklenir. BÃ¶ylelikle basit bir matematiksel model elde edilir.

Yapay Sinir AÄŸlarÄ±nda yapÄ±lan temel iÅŸlem; modelin en iyi skoru vereceÄŸi w(aÄŸÄ±rlÄ±k parametresi) ve b(bias deÄŸeri) parametrelerinin hesabÄ±nÄ± yapmaktÄ±r.                     

Her bir sinir hÃ¼cresi aynÄ± ÅŸekilde hesaplanÄ±r ve bunlar birbirine seri ya da paralel ÅŸekilde baÄŸlanÄ±r.

Bir yapay sinir hÃ¼cresi beÅŸ bÃ¶lÃ¼mden oluÅŸmaktadÄ±r;

1. **Girdiler:**<br> Girdiler nÃ¶ronlara gelen verilerdir. Bu girdilerden gelen veriler biyolojik sinir hÃ¼crelerinde olduÄŸu gibi toplanmak Ã¼zere nÃ¶ron Ã§ekirdeÄŸine gÃ¶nderilir.

2. **AÄŸÄ±rlÄ±klar:**<br> Yapay sinir hÃ¼cresine gelen bilgiler girdiler Ã¼zerinden Ã§ekirdeÄŸe ulaÅŸmadan Ã¶nce geldikleri baÄŸlantÄ±larÄ±n aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arpÄ±larak Ã§ekirdeÄŸe iletilir. Bu sayede girdilerin Ã¼retilecek Ã§Ä±ktÄ± Ã¼zerindeki etkisi ayarlanabilinmektedir.

3. **Toplama Fonksiyonu (BirleÅŸtirme Fonksiyonu):**<br> Toplama fonksiyonu bir yapay sinir hÃ¼cresine aÄŸÄ±rlÄ±klarla Ã§arpÄ±larak gelen girdileri toplayarak o hÃ¼crenin net girdisini hesaplayan bir fonksiyondur

4. **Aktivasyon fonksiyonu:**<br> Ã–nceki katmandaki tÃ¼m girdilerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± alan ve daha sonra bir Ã§Ä±kÄ±ÅŸ deÄŸeri (tipik olarak doÄŸrusal olmayan) Ã¼reten ve bir sonraki katmana geÃ§iren bir fonksiyondur. (Ã¶rneÄŸin, ReLU veya sigmoid ).

5. **Ã‡Ä±ktÄ±lar:**<br> Aktivasyon fonksiyonundan Ã§Ä±kan deÄŸer hÃ¼crenin Ã§Ä±ktÄ± deÄŸeri olmaktadÄ±r. Her hÃ¼crenin birden fazla girdisi olmasÄ±na raÄŸmen bir tek Ã§Ä±ktÄ±sÄ± olmaktadÄ±r. Bu Ã§Ä±ktÄ± istenilen sayÄ±da hÃ¼creye baÄŸlanabilir.

### Yapay Sinir AÄŸlarÄ±nÄ± BaÄŸlantÄ±larÄ±na GÃ¶re SÄ±nÄ±flandÄ±rma

Yapay sinir aÄŸlarÄ± kendi arasÄ±nda baÄŸlantÄ±lar iÃ§erir. Bunlar ileri beslemeli ve geri beslemeli aÄŸlar olarak sÄ±nÄ±flandÄ±rÄ±lÄ±rlar.

#### Ä°leri Beslemeli AÄŸlar

<img src="https://i.hizliresim.com/qLLIIK.png" />

- Tek yÃ¶nlÃ¼ bilgi akÄ±ÅŸÄ± sÃ¶z konusudur.
- Bu aÄŸ modelinde Girdi tabakasÄ±ndan alÄ±nan bilgiler Gizli katmana iletilir.
- Gizli ve Ã‡Ä±ktÄ± tabakalarÄ±ndan bilginin iÅŸlenmesi ile Ã§Ä±kÄ±ÅŸ deÄŸeri belirlenir.

#### Geri Beslemeli AÄŸlar

<img src="https://www.derinogrenme.com/wp-content/uploads/2017/02/gsa.png"/>

- Bir geri beslemeli sinir aÄŸÄ±, Ã§Ä±kÄ±ÅŸ ve ara katlardaki Ã§Ä±kÄ±ÅŸlarÄ±n, giriÅŸ birimlerine veya Ã¶nceki ara katmanlara geri beslendiÄŸi bir aÄŸ yapÄ±sÄ±dÄ±r. BÃ¶ylece, giriÅŸler hem ileri yÃ¶nde hem de geri yÃ¶nde aktarÄ±lmÄ±ÅŸ olur.
- Bu Ã§eÅŸit YSAâ€™larÄ±n dinamik hafÄ±zalarÄ± vardÄ±r ve bir andaki Ã§Ä±kÄ±ÅŸ hem o andaki hem de Ã¶nceki giriÅŸleri yansÄ±tÄ±r. Bundan dolayÄ±, Ã¶zellikle Ã¶nceden tahmin uygulamalarÄ± iÃ§in uygundurlar.


## Input ve Output DeÄŸeri
```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# deÄŸerleri oluÅŸturma
X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])

# etiketleri oluÅŸturma
y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])

# hadi ÅŸimdi gÃ¶rselleÅŸtirelim
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

YukarÄ±da ki modellemede X ve y arasÄ±nda ki matematiksel Ã¶rÃ¼ntÃ¼yÃ¼ hesaplayabilir misiniz?

Ã–rneÄŸin; X'e 40 deÄŸerini verirsek y deÄŸeri ne olur ? Ya da y deÄŸerini 30 yapan X deÄŸeri nedir?

Bunu neden elle (klasik) hesaplayalÄ±m. Bu sadece 2 deÄŸiÅŸkeni olan basit bir yapÄ±. Ya 100 deÄŸiÅŸkeni olsaydÄ±? O zamanda elle hesaplayabiliriz cÃ¼mlesini kurabilirmiydik? Tabiki de HAYIR. O zaman bunun iÃ§in neden bir sinir aÄŸÄ± eÄŸitmiyoruz? Hadi baÅŸlayalÄ±m...

```python
""" 
Input  : Modele giren verilerimizin ÅŸekli
Output : Modelimizden Ã§Ä±kmasÄ±nÄ± istediÄŸimiz verilerin ÅŸekli 
Bunlar, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z soruna baÄŸlÄ± olarak farklÄ±lÄ±k gÃ¶sterecektir.
Sinir aÄŸlarÄ± tensor (veya dizi) olarak temsilsil edilir.
"""

# Ã–rnek bir tensÃ¶r oluÅŸturalÄ±m
house_info = tf.constant(["bedroom", "bathroom", "garage"])
house_price = tf.constant([939700])
house_info, house_price
```
> (<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,
 <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)

```python
house_info.shape
```
> TensorShape([3])

```python
# YukarÄ±daki Ã¶rneÄŸi numpy kÃ¼tÃ¼phanesi ile yapmÄ±ÅŸtÄ±k. Bunu tensÃ¶r yapÄ±sÄ±na Ã§evirelim
X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])
y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

TensÃ¶rde oluÅŸturmayÄ± hatÄ±rladÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi yukarÄ±da bahsettiÄŸimiz X ve y 
sorununa dair bir sinir aÄŸÄ± eÄŸitelim. 

AmacÄ±mÄ±z kÄ±saca; verilen X deÄŸerine gÃ¶re y deÄŸerini bulmak. Burada input deÄŸerimiz X, output deÄŸerimiz y'dir. 

```python
# Tek bir X Ã¶rneÄŸinin shape deÄŸeri
input_shape = X[0].shape

# Tek bir y Ã¶rneÄŸinin shape deÄŸeri
output_shape = y[0].shape

# bunlarÄ±n ikisi de skalerdir (shape deÄŸeri yoktur)
input_shape, output_shape
```
> (TensorShape([]), TensorShape([]))

Neden input ve output deÄŸerlimizin bir ÅŸekli yok.

Bunun nedeni, modelimize ne tÃ¼r veriler ilettiÄŸimiz Ã¶nemli deÄŸil, her zaman 
input olarak alacak ve output olarak bir tÃ¼r tensÃ¶r olarak geri dÃ¶necektir.

Ancak bizim durumumuzda veri kÃ¼memiz nedeniyle (sadece 2 kÃ¼Ã§Ã¼k sayÄ± listesi), 
Ã¶zel bir tÃ¼r tensÃ¶re bakÄ±yoruz, daha spesifik olarak bir 
rank'Ä± 0 tensÃ¶r veya bir skaler.

```python
X[0], y[0]
```
> (<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,
 <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)
 
- X[0] = -7.0
- y[0] = 3.0
Bir y deÄŸerini tahmin etmek iÃ§in bir X deÄŸeri kullanÄ±yoruz. Bu bizim modelimizin en basit denklemi. 

Burada anlatmak istediÄŸim nokta; bir input deÄŸeri ile output deÄŸeri kullanmaktÄ±r. Klasik programlama da bir input ve bir fonksiyon kullanarak bir output deÄŸeri elde edersiniz. Bizim sinir aÄŸlarÄ±nda (yada ML) yapmak istediÄŸimiz ÅŸey; bir input ve bir output deÄŸeri vererek arada ki fonksiyonunu kendi Ã¼retmesini istiyoruz.

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png" />

*Konut fiyatlarÄ±nÄ± tahmin etmek iÃ§in bir makine Ã¶ÄŸrenimi algoritmasÄ± oluÅŸturmaya Ã§alÄ±ÅŸÄ±yorsanÄ±z, girdileriniz yatak odasÄ± sayÄ±sÄ±, banyo sayÄ±sÄ± ve garaj sayÄ±sÄ± olabilir ve size 3 (3 farklÄ± Ã¶zellik) girdi ÅŸekli verir. Ve evin fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in Ã§Ä±ktÄ± ÅŸekliniz 1 olur.*

## Modellemedeki AdÄ±mlar

ArtÄ±k elimizde hangi verilere, girdi ve Ã§Ä±ktÄ± ÅŸekillerine sahip olduÄŸumuzu biliyoruz, onu modellemek iÃ§in nasÄ±l bir sinir aÄŸÄ± kuracaÄŸÄ±mÄ±za bakalÄ±m.

TensorFlow'da bir model oluÅŸturmak ve eÄŸitmek iÃ§in tipik olarak 3 temel adÄ±m vardÄ±r.

- **Bir model oluÅŸturma**<br>
Bir sinir aÄŸÄ±nÄ±n katmanlarÄ±nÄ± kendiniz bir araya getirin ([Functional](https://www.tensorflow.org/guide/keras/functional) veya [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'yi kullanarak) veya Ã¶nceden oluÅŸturulmuÅŸ bir modeli iÃ§e aktarÄ±n (transfer learning olarak bilinir). 
- **Model derleme**<br>
Bir model performansÄ±nÄ±n nasÄ±l Ã¶lÃ§Ã¼leceÄŸini (kayÄ±p metrikler) tanÄ±mlamanÄ±n yanÄ± sÄ±ra nasÄ±l iyileÅŸtirileceÄŸini (optimize) tanÄ±mlama. 
- **Model uydurma**<br>
Modelin verilerdeki kalÄ±plarÄ± bulmaya Ã§alÄ±ÅŸmasÄ±na izin vermek (X, y'ye nasÄ±l ulaÅŸÄ±r). 

Regresyon verilerimiz iÃ§in bir model oluÅŸturmak Ã¼zere [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'sini kullanarak bunlarÄ± Ã§alÄ±ÅŸÄ±rken gÃ¶relim. Ve sonra her birinin Ã¼zerinden geÃ§eceÄŸiz.

```python
"""
Biz her modeli Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda model, belirli bir metolojide Ã§alÄ±ÅŸacak.
Ama burada ÅŸu sÄ±kÄ±ntÄ± var: Modeli her run ettiÄŸimizde farklÄ± bir sonuÃ§ alacaÄŸÄ±z.
Ä°ÅŸte burada tf.random.set_seed(number) kullanarak o rastgeleliÄŸi belirli bir
yolla baÄŸlamÄ±ÅŸ oluyoruz. Bu sayede her run ettiÄŸimizde aynÄ± sonucu alacaÄŸÄ±z.
"""
tf.random.set_seed(42)

# Sequential API'yi kullanarak bir model oluÅŸturun
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# Modeli derleme
model.compile(loss=tf.keras.losses.mae, # mean absolute error
              optimizer=tf.keras.optimizers.SGD(), # stochastic gradient descent
              metrics=["mae"])

# modeli fit etme
model.fit(X, y, epochs=5)
```

Ä°ÅŸte bu kadar basit :) 

X'e baÄŸlÄ± bir y deÄŸeri oluÅŸturan bir modeli geliÅŸtirdik.

```python
# X ve y deÄŸerlerini kontrol edelim
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)

```python
# Var olan bir X deÄŸeri ile modelimiz doÄŸru bir y deÄŸeri Ã¼retecek mi?
model.predict([8.0])
```
Ama ama bu niye bÃ¶yle oldu :(  Her ÅŸeyi doÄŸru yaptÄ±k gibi. Modele bir input ve output deÄŸeri verdik. Bunu bir sinir aÄŸÄ±na baÄŸladÄ±k. Fakat doÄŸru sonuÃ§la alakasÄ± bile olmayan bir output deÄŸeri verdi bize. 

> Bu soruya cevap vermeden Ã¶nce size kÄ±sa bir soru sormak istiyorum. TensorFlow iÃ§erisinde hep Keras dediÄŸimiz yapÄ±larÄ± gÃ¶rÃ¼yoruz. Bu keras nedir? [Cevap](https://i.ibb.co/LNScsJd/cevap1.png)


## Bir Model GeliÅŸtirmek

Model istediÄŸimiz sonucu vermeyi bÄ±rakÄ±n, yakÄ±nÄ±na dahi yanaÅŸamadÄ±. Peki burada Ã§Ã¶zÃ¼m ne?

DoÄŸru tahmin ettiniz. Fine tuning yani ince ayar yapmak. Modeli geliÅŸtirmek iÃ§in hangi adÄ±mlarÄ± uyguladÄ±k:

1. **Model oluÅŸturma**<br>
Burada daha fazla katman eklemek, her katmandaki gizli birimlerin (nÃ¶ronlar olarak da adlandÄ±rÄ±lÄ±r) sayÄ±sÄ±nÄ± artÄ±rmak, her katmanÄ±n etkinleÅŸtirme iÅŸlevlerini deÄŸiÅŸtirmek isteyebilirsiniz.
2. **Model derleme**<br>
Optimizasyon fonksiyonunu seÃ§mek veya belki de optimizasyon fonksiyonunun Ã¶ÄŸrenme oranÄ±nÄ± deÄŸiÅŸtirmek isteyebilirsiniz.
3. **Modeli fit etme**<br>
Daha fazla epoch veya daha fazla veri ile daha iyi sonuÃ§lar almak isteyebilirsiniz.

Vay. Az Ã¶nce bir dizi olasÄ± adÄ±mÄ± tanÄ±ttÄ±k. HatÄ±rlanmasÄ± gereken Ã¶nemli ÅŸey, bunlarÄ±n her birini nasÄ±l deÄŸiÅŸtireceÄŸiniz, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z soruna baÄŸlÄ± olacaktÄ±r.

```python
# yukarÄ±da bu yapÄ±yÄ± ayrÄ±ntÄ±sÄ±yla anlattÄ±m
tf.random.set_seed(42)

# bir Ã¶nceki modelin aynÄ±sÄ±nÄ± uygulayalÄ±m
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli aynÄ± ÅŸekilde derleyelim
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# ÅŸimdi fit edelim, ama bu sefer 100 epoch kullanarak
model.fit(X, y, epochs=100)
```
YukarÄ± da ki kod bloÄŸunu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda MAE deÄŸerinin yani kayÄ±p fonksiyonun adÄ±m adÄ±m dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶zlemleyeceksiniz. Ä°ÅŸte bu anda geriye yaslanÄ±p iÅŸlemin bitmesini bekleyebilirsiniz Ã§Ã¼nkÃ¼ bu doÄŸru gittiÄŸinizi gÃ¶steriyor.

YukarÄ±da 5 epoch ile eÄŸittimizde hiÃ§ gÃ¼zel bir tahmin deÄŸeri almadÄ±k. Peki ya ÅŸimdi?

```python
model.predict([8.0])
```
Ä°ÅŸte buuu ğŸ’ª 0.33 lÃ¼k bir sapma var ama modelimiz resmen input ve output deÄŸerlerini ile doÄŸru eÄŸitilmiÅŸ.

Åimdi de modelimizde olmayan bir sayÄ± ile deneme yapalÄ±m. 
Modelimize tekrar gÃ¶z atalÄ±m. Test etmek iÃ§in arada ki baÄŸlantÄ±yÄ± bulmamÄ±z gerekiyor.
```python
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)
 
- -7 --> 3
- -4 --> 6
- -1 --> 9

YukarÄ±da ki eÅŸitliklere baktÄ±ÄŸÄ±mÄ±zda x + 10 = y gibi bir eÅŸitiÄŸin olduÄŸunu hemen anlayabiliriz. Denklemi Ã§Ä±kardÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi dizide olmayan bir sayÄ±da nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶zlemleyebiliriz.

```python
model.predict([20]) # cevabÄ±n 20+10= 30 olmasÄ±nÄ± bekliyoruz
```
HÄ±mm. YaklaÅŸÄ±k bir sonuÃ§ ama tam da istediÄŸimiz bir cevap deÄŸil. Modelimizi bir deÄŸerlendirelim daha sonra nasÄ±l daha iyi sonuÃ§ alacaÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rÃ¼z.
 
 
## Modeli DeÄŸerlendirme

... devam edecek
 









