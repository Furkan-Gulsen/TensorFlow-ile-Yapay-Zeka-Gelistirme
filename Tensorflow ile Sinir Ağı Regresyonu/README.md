Bu konuya baÅŸlamadan Ã¶nce aÅŸaÄŸÄ±da bulunan kavramlar Ã§ok iyi bir ÅŸekilde anlaÅŸÄ±lmasÄ± gerekiyor.

## Regresyon Analizi Nedir?

**Regresyon analizi, iki ya da daha Ã§ok nicel deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§mek iÃ§in kullanÄ±lan analiz metodudur.** EÄŸer tek bir deÄŸiÅŸken kullanÄ±larak analiz yapÄ±lÄ±yorsa buna tek deÄŸiÅŸkenli regresyon, birden Ã§ok deÄŸiÅŸken kullanÄ±lÄ±yorsa Ã§ok deÄŸiÅŸkenli regresyon analizi olarak isimlendirilir. Regresyon analizi ile deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin varlÄ±ÄŸÄ±, eÄŸer iliÅŸki var ise bunun gÃ¼cÃ¼ hakkÄ±nda bilgi edinilebilir. 

Ã–rneÄŸin; <br>
Bir daire satÄ±n almayÄ± dÃ¼ÅŸÃ¼nÃ¼yorsunuz. Bu dairenin fiyatÄ±nÄ± belirleyen birden Ã§ok unsur vardÄ±r. Ã–rnek:
- Toplu taÅŸÄ±maya yakÄ±nlÄ±ÄŸÄ±
- ManzarasÄ±
- KaÃ§Ä±ncÄ± katta olduÄŸu
- BinanÄ±n yapÄ±m yÄ±lÄ±

gibi benzeri bir Ã§ok unsur binanÄ±n fiyatÄ±nÄ± belirleyen Ã¶nemli faktÃ¶rlerdir. 

Regresyonda, deÄŸiÅŸkenlerden biri baÄŸÄ±mlÄ± diÄŸerleri baÄŸÄ±msÄ±z deÄŸiÅŸken olmalÄ±dÄ±r. 


## Yapay Sinir AÄŸÄ± Nedir?

Yapay sinir aÄŸlarÄ± (YSA), insan beyninin bilgi iÅŸleme tekniÄŸinden esinlenerek geliÅŸtirilmiÅŸ bir bilgi iÅŸlem teknolojisidir. YSA ile basit biyolojik sinir sisteminin Ã§alÄ±ÅŸma ÅŸekli taklit edilir. Yani biyolojik nÃ¶ron hÃ¼crelerinin ve bu hÃ¼crelerin birbirleri ile arasÄ±nda kurduÄŸu sinaptik baÄŸÄ±n dijital olarak modellenmesidir.

NÃ¶ronlar Ã§eÅŸitli ÅŸekillerde birbirlerine baÄŸlanarak aÄŸlar oluÅŸtururlar. Bu aÄŸlar Ã¶ÄŸrenme, hafÄ±zaya alma ve veriler arasÄ±ndaki iliÅŸkiyi ortaya Ã§Ä±karma kapasitesine sahiptirler. DiÄŸer bir ifadeyle, YSA'lar, normalde bir insanÄ±n dÃ¼ÅŸÃ¼nme ve gÃ¶zlemlemeye yÃ¶nelik doÄŸal yeteneklerini gerektiren problemlere Ã§Ã¶zÃ¼m Ã¼retmektedir. Bir insanÄ±n, dÃ¼ÅŸÃ¼nme ve gÃ¶zlemleme yeteneklerini gerektiren problemlere yÃ¶nelik Ã§Ã¶zÃ¼mler Ã¼retebilmesinin temel sebebi ise insan beyninin ve dolayÄ±sÄ±yla insanÄ±n sahip olduÄŸu yaÅŸayarak veya deneyerek Ã¶ÄŸrenme yeteneÄŸidir.

Yapay Sinir AÄŸlarÄ±nÄ±n AvantajlarÄ±
- Yapay Sinir AÄŸlarÄ± bir Ã§ok hÃ¼creden meydana gelir ve bu hÃ¼creler eÅŸ zamanlÄ± Ã§alÄ±ÅŸarak karmaÅŸÄ±k iÅŸleri gerÃ§ekleÅŸtirir.
- Ã–ÄŸrenme kabiliyeti vardÄ±r ve farklÄ± Ã¶ÄŸrenme algoritmalarÄ±yla Ã¶ÄŸrenebilirler.
- GÃ¶rÃ¼lmemiÅŸ Ã§Ä±ktÄ±lar iÃ§in sonuÃ§ (bilgi) Ã¼retebilirler. GÃ¶zetimsiz Ã¶ÄŸrenim sÃ¶z konusudur.
- Ã–rÃ¼ntÃ¼ tanÄ±ma ve sÄ±nÄ±flandÄ±rma yapabilirler. Eksik Ã¶rÃ¼ntÃ¼leri tamamlayabilirler.
- Hata toleransÄ±na sahiptirler. Eksik veya belirsiz bilgiyle Ã§alÄ±ÅŸabilirler. HatalÄ± durumlarda dereceli bozulma (graceful degradation) gÃ¶sterirler.
- Paralel Ã§alÄ±ÅŸabilmekte ve gerÃ§ek zamanlÄ± bilgiyi iÅŸleyebilmektedirler.

### Yapay Sinir AÄŸlarÄ±nÄ±n SÄ±nÄ±flandÄ±rÄ±lmasÄ±

#### Tek KatmanlÄ± Yapay Sinir AÄŸlarÄ±
Tek katmanlÄ± yapay sinir aÄŸlarÄ± sadece girdi ve Ã§Ä±ktÄ± katmanlarÄ±ndan oluÅŸur. Ã‡Ä±ktÄ± Ã¼niteleri bÃ¼tÃ¼n girdi Ã¼nitelerine (X) baÄŸlanmaktadÄ±r ve her baÄŸlantÄ±nÄ±n bir aÄŸÄ±rlÄ±ÄŸÄ± (W) vardÄ±r. 

#### Ã‡ok KatmanlÄ± Yapay Sinir AÄŸlarÄ±

DoÄŸrusal olmayan problemlerin Ã§Ã¶zÃ¼mÃ¼ iÃ§in uygun bir aÄŸ yapÄ±sÄ±dÄ±r. Bu sebeple daha karÄ±ÅŸÄ±k problemlerin Ã§Ã¶zÃ¼mÃ¼nde kullanÄ±lÄ±r. KarÄ±ÅŸÄ±k problemlerin modeli olmasÄ± aÄŸÄ±n eÄŸitimini zorlaÅŸtÄ±ran bir yapÄ±ya bÃ¼rÃ¼nmesine sebep olur. Tek katmanlÄ± aÄŸ yapÄ±sÄ±na gÃ¶re daha karmaÅŸÄ±k bir yapÄ±dadÄ±r. Fakat problem Ã§Ã¶zÃ¼mlerinde genellikle Ã§ok katmanlÄ± aÄŸ yapÄ±sÄ± kullanÄ±lÄ±r Ã§Ã¼nkÃ¼ tek katmanlÄ± yapÄ±lara gÃ¶re daha baÅŸarÄ±lÄ± sonuÃ§lar verir. Ã‡ok katmanlÄ± yapay sinir aÄŸlarÄ± modellerinde en az 1 adet gizli katman bulunur.

### Yapay Sinir HÃ¼cresi

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Neuron_Hand-tuned.svg/1200px-Neuron_Hand-tuned.svg.png" />

CanlÄ±lardaki sinir hÃ¼crelerinin biyolojik gÃ¶rÃ¼nÃ¼mÃ¼ yukarÄ±da gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z ÅŸekildeki gibidir. Ã‡ekirdeÄŸimiz var ve bir akson boyunca iletim yapÄ±lÄ±yor. Burada Ã§Ä±kÄ±ÅŸ terminallerinde dentrit uclarÄ±ndan elde edilen sensÃ¶r verilerimiz Ã§ekirdekte aÄŸÄ±rlandÄ±rÄ±larak akson boyunca iletiliyor ve baÅŸka sinir hÃ¼cresine baÄŸlanÄ±yor. Bu ÅŸekilde sinirler arasÄ± iletiÅŸim saÄŸlanmÄ±ÅŸ oluyor.

Ä°nsandaki bir sinir hÃ¼cresinin matematiksel modeli ise ÅŸu ÅŸekilde gÃ¶sterilebilir:

<img src="https://mesutpiskin.com/blog/wp-content/uploads/2017/08/ysa_matematiksel_modeli.png" />

Dentrit dediÄŸimiz yollar boyunca aÄŸÄ±rlÄ±klarÄ±mÄ±z mevcut ve bu dentritlere giren bir baÅŸka nÃ¶rondan da gelmiÅŸ olabilecek bir giriÅŸ deÄŸerimiz (x0 ) var. GiriÅŸ deÄŸerimiz ve dentritteki aÄŸÄ±rlÄ±ÄŸÄ±mÄ±z(w0) Ã§arpÄ±ldÄ±ktan sonra( w0x0)  sinir hÃ¼cresine iletilir ve sinir hÃ¼cresinde bu Ã§arpma iÅŸlemi yapÄ±lÄ±yor ve tÃ¼m dentritlerden gelen aÄŸÄ±rlÄ±k ile giriÅŸ Ã§arpÄ±mlarÄ± toplanÄ±r. Yani aÄŸÄ±rlÄ±klÄ± toplama iÅŸlemi yapÄ±lÄ±r. ArdÄ±ndan bir bias(b) ile toplandÄ±ktan sonra aktivasyon fonksiyonu ardÄ±ndan Ã§Ä±kÄ±ÅŸa aktarÄ±lÄ±r. Bu Ã§Ä±kÄ±ÅŸ nihai Ã§Ä±kÄ±ÅŸ olabileceÄŸi gibi bir baÅŸka hÃ¼crenin giriÅŸi olabilir. Matematiksel olarak aÄŸÄ±rlÄ±klar ile giriÅŸler Ã§arpÄ±lÄ±r artÄ± bir bias eklenir. BÃ¶ylelikle basit bir matematiksel model elde edilir.

Yapay Sinir AÄŸlarÄ±nda yapÄ±lan temel iÅŸlem; modelin en iyi skoru vereceÄŸi w(aÄŸÄ±rlÄ±k parametresi) ve b(bias deÄŸeri) parametrelerinin hesabÄ±nÄ± yapmaktÄ±r.                     

Her bir sinir hÃ¼cresi aynÄ± ÅŸekilde hesaplanÄ±r ve bunlar birbirine seri ya da paralel ÅŸekilde baÄŸlanÄ±r.

Bir yapay sinir hÃ¼cresi beÅŸ bÃ¶lÃ¼mden oluÅŸmaktadÄ±r;

1. **Girdiler:**<br> Girdiler nÃ¶ronlara gelen verilerdir. Bu girdilerden gelen veriler biyolojik sinir hÃ¼crelerinde olduÄŸu gibi toplanmak Ã¼zere nÃ¶ron Ã§ekirdeÄŸine gÃ¶nderilir.

2. **AÄŸÄ±rlÄ±klar:**<br> Yapay sinir hÃ¼cresine gelen bilgiler girdiler Ã¼zerinden Ã§ekirdeÄŸe ulaÅŸmadan Ã¶nce geldikleri baÄŸlantÄ±larÄ±n aÄŸÄ±rlÄ±ÄŸÄ±yla Ã§arpÄ±larak Ã§ekirdeÄŸe iletilir. Bu sayede girdilerin Ã¼retilecek Ã§Ä±ktÄ± Ã¼zerindeki etkisi ayarlanabilinmektedir.

3. **Toplama Fonksiyonu (BirleÅŸtirme Fonksiyonu):**<br> Toplama fonksiyonu bir yapay sinir hÃ¼cresine aÄŸÄ±rlÄ±klarla Ã§arpÄ±larak gelen girdileri toplayarak o hÃ¼crenin net girdisini hesaplayan bir fonksiyondur

4. **Aktivasyon fonksiyonu:**<br> Ã–nceki katmandaki tÃ¼m girdilerin aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ± alan ve daha sonra bir Ã§Ä±kÄ±ÅŸ deÄŸeri (tipik olarak doÄŸrusal olmayan) Ã¼reten ve bir sonraki katmana geÃ§iren bir fonksiyondur. (Ã¶rneÄŸin, ReLU veya sigmoid ).

5. **Ã‡Ä±ktÄ±lar:**<br> Aktivasyon fonksiyonundan Ã§Ä±kan deÄŸer hÃ¼crenin Ã§Ä±ktÄ± deÄŸeri olmaktadÄ±r. Her hÃ¼crenin birden fazla girdisi olmasÄ±na raÄŸmen bir tek Ã§Ä±ktÄ±sÄ± olmaktadÄ±r. Bu Ã§Ä±ktÄ± istenilen sayÄ±da hÃ¼creye baÄŸlanabilir.

### Yapay Sinir AÄŸlarÄ±nÄ± BaÄŸlantÄ±larÄ±na GÃ¶re SÄ±nÄ±flandÄ±rma

Yapay sinir aÄŸlarÄ± kendi arasÄ±nda baÄŸlantÄ±lar iÃ§erir. Bunlar ileri beslemeli ve geri beslemeli aÄŸlar olarak sÄ±nÄ±flandÄ±rÄ±lÄ±rlar.

#### Ä°leri Beslemeli AÄŸlar

<img src="https://i.hizliresim.com/qLLIIK.png" />

- Tek yÃ¶nlÃ¼ bilgi akÄ±ÅŸÄ± sÃ¶z konusudur.
- Bu aÄŸ modelinde Girdi tabakasÄ±ndan alÄ±nan bilgiler Gizli katmana iletilir.
- Gizli ve Ã‡Ä±ktÄ± tabakalarÄ±ndan bilginin iÅŸlenmesi ile Ã§Ä±kÄ±ÅŸ deÄŸeri belirlenir.

#### Geri Beslemeli AÄŸlar

<img src="https://www.derinogrenme.com/wp-content/uploads/2017/02/gsa.png"/>

- Bir geri beslemeli sinir aÄŸÄ±, Ã§Ä±kÄ±ÅŸ ve ara katlardaki Ã§Ä±kÄ±ÅŸlarÄ±n, giriÅŸ birimlerine veya Ã¶nceki ara katmanlara geri beslendiÄŸi bir aÄŸ yapÄ±sÄ±dÄ±r. BÃ¶ylece, giriÅŸler hem ileri yÃ¶nde hem de geri yÃ¶nde aktarÄ±lmÄ±ÅŸ olur.
- Bu Ã§eÅŸit YSAâ€™larÄ±n dinamik hafÄ±zalarÄ± vardÄ±r ve bir andaki Ã§Ä±kÄ±ÅŸ hem o andaki hem de Ã¶nceki giriÅŸleri yansÄ±tÄ±r. Bundan dolayÄ±, Ã¶zellikle Ã¶nceden tahmin uygulamalarÄ± iÃ§in uygundurlar.


## Input ve Output DeÄŸeri
```python
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# deÄŸerleri oluÅŸturma
X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])

# etiketleri oluÅŸturma
y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])

# hadi ÅŸimdi gÃ¶rselleÅŸtirelim
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

YukarÄ±da ki modellemede X ve y arasÄ±nda ki matematiksel Ã¶rÃ¼ntÃ¼yÃ¼ hesaplayabilir misiniz?

Ã–rneÄŸin; X'e 40 deÄŸerini verirsek y deÄŸeri ne olur ? Ya da y deÄŸerini 30 yapan X deÄŸeri nedir?

Bunu neden elle (klasik) hesaplayalÄ±m. Bu sadece 2 deÄŸiÅŸkeni olan basit bir yapÄ±. Ya 100 deÄŸiÅŸkeni olsaydÄ±? O zamanda elle hesaplayabiliriz cÃ¼mlesini kurabilirmiydik? Tabiki de HAYIR. O zaman bunun iÃ§in neden bir sinir aÄŸÄ± eÄŸitmiyoruz? Hadi baÅŸlayalÄ±m...

```python
""" 
Input  : Modele giren verilerimizin ÅŸekli
Output : Modelimizden Ã§Ä±kmasÄ±nÄ± istediÄŸimiz verilerin ÅŸekli 
Bunlar, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z soruna baÄŸlÄ± olarak farklÄ±lÄ±k gÃ¶sterecektir.
Sinir aÄŸlarÄ± tensor (veya dizi) olarak temsilsil edilir.
"""

# Ã–rnek bir tensÃ¶r oluÅŸturalÄ±m
house_info = tf.constant(["bedroom", "bathroom", "garage"])
house_price = tf.constant([939700])
house_info, house_price
```
> (<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,
 <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)

```python
house_info.shape
```
> TensorShape([3])

```python
# YukarÄ±daki Ã¶rneÄŸi numpy kÃ¼tÃ¼phanesi ile yapmÄ±ÅŸtÄ±k. Bunu tensÃ¶r yapÄ±sÄ±na Ã§evirelim
X = tf.constant([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])
y = tf.constant([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])
plt.scatter(X, y);
```
> <img src="https://i.ibb.co/M9y3mmD/chapter1-img1.png" />

TensÃ¶rde oluÅŸturmayÄ± hatÄ±rladÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi yukarÄ±da bahsettiÄŸimiz X ve y 
sorununa dair bir sinir aÄŸÄ± eÄŸitelim. 

AmacÄ±mÄ±z kÄ±saca; verilen X deÄŸerine gÃ¶re y deÄŸerini bulmak. Burada input deÄŸerimiz X, output deÄŸerimiz y'dir. 

```python
# Tek bir X Ã¶rneÄŸinin shape deÄŸeri
input_shape = X[0].shape

# Tek bir y Ã¶rneÄŸinin shape deÄŸeri
output_shape = y[0].shape

# bunlarÄ±n ikisi de skalerdir (shape deÄŸeri yoktur)
input_shape, output_shape
```
> (TensorShape([]), TensorShape([]))

Neden input ve output deÄŸerlimizin bir ÅŸekli yok.

Bunun nedeni, modelimize ne tÃ¼r veriler ilettiÄŸimiz Ã¶nemli deÄŸil, her zaman 
input olarak alacak ve output olarak bir tÃ¼r tensÃ¶r olarak geri dÃ¶necektir.

Ancak bizim durumumuzda veri kÃ¼memiz nedeniyle (sadece 2 kÃ¼Ã§Ã¼k sayÄ± listesi), 
Ã¶zel bir tÃ¼r tensÃ¶re bakÄ±yoruz, daha spesifik olarak bir 
rank'Ä± 0 tensÃ¶r veya bir skaler.

```python
X[0], y[0]
```
> (<tf.Tensor: shape=(), dtype=float32, numpy=-7.0>,
 <tf.Tensor: shape=(), dtype=float32, numpy=3.0>)
 
- X[0] = -7.0
- y[0] = 3.0
Bir y deÄŸerini tahmin etmek iÃ§in bir X deÄŸeri kullanÄ±yoruz. Bu bizim modelimizin en basit denklemi. 

Burada anlatmak istediÄŸim nokta; bir input deÄŸeri ile output deÄŸeri kullanmaktÄ±r. Klasik programlama da bir input ve bir fonksiyon kullanarak bir output deÄŸeri elde edersiniz. Bizim sinir aÄŸlarÄ±nda (yada ML) yapmak istediÄŸimiz ÅŸey; bir input ve bir output deÄŸeri vererek arada ki fonksiyonunu kendi Ã¼retmesini istiyoruz.

<img src="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/01-input-and-output-shapes-housing-prices.png" />

*Konut fiyatlarÄ±nÄ± tahmin etmek iÃ§in bir makine Ã¶ÄŸrenimi algoritmasÄ± oluÅŸturmaya Ã§alÄ±ÅŸÄ±yorsanÄ±z, girdileriniz yatak odasÄ± sayÄ±sÄ±, banyo sayÄ±sÄ± ve garaj sayÄ±sÄ± olabilir ve size 3 (3 farklÄ± Ã¶zellik) girdi ÅŸekli verir. Ve evin fiyatÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in Ã§Ä±ktÄ± ÅŸekliniz 1 olur.*

## Modellemedeki AdÄ±mlar

ArtÄ±k elimizde hangi verilere, girdi ve Ã§Ä±ktÄ± ÅŸekillerine sahip olduÄŸumuzu biliyoruz, onu modellemek iÃ§in nasÄ±l bir sinir aÄŸÄ± kuracaÄŸÄ±mÄ±za bakalÄ±m.

TensorFlow'da bir model oluÅŸturmak ve eÄŸitmek iÃ§in tipik olarak 3 temel adÄ±m vardÄ±r.

- **Bir model oluÅŸturma**<br>
Bir sinir aÄŸÄ±nÄ±n katmanlarÄ±nÄ± kendiniz bir araya getirin ([Functional](https://www.tensorflow.org/guide/keras/functional) veya [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'yi kullanarak) veya Ã¶nceden oluÅŸturulmuÅŸ bir modeli iÃ§e aktarÄ±n (transfer learning olarak bilinir). 
- **Model derleme**<br>
Bir model performansÄ±nÄ±n nasÄ±l Ã¶lÃ§Ã¼leceÄŸini (kayÄ±p metrikler) tanÄ±mlamanÄ±n yanÄ± sÄ±ra nasÄ±l iyileÅŸtirileceÄŸini (optimize) tanÄ±mlama. 
- **Model uydurma**<br>
Modelin verilerdeki kalÄ±plarÄ± bulmaya Ã§alÄ±ÅŸmasÄ±na izin vermek (X, y'ye nasÄ±l ulaÅŸÄ±r). 

Regresyon verilerimiz iÃ§in bir model oluÅŸturmak Ã¼zere [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)'sini kullanarak bunlarÄ± Ã§alÄ±ÅŸÄ±rken gÃ¶relim. Ve sonra her birinin Ã¼zerinden geÃ§eceÄŸiz.

```python
"""
Biz her modeli Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda model, belirli bir metolojide Ã§alÄ±ÅŸacak.
Ama burada ÅŸu sÄ±kÄ±ntÄ± var: Modeli her run ettiÄŸimizde farklÄ± bir sonuÃ§ alacaÄŸÄ±z.
Ä°ÅŸte burada tf.random.set_seed(number) kullanarak o rastgeleliÄŸi belirli bir
yolla baÄŸlamÄ±ÅŸ oluyoruz. Bu sayede her run ettiÄŸimizde aynÄ± sonucu alacaÄŸÄ±z.
"""
tf.random.set_seed(42)

# Sequential API'yi kullanarak bir model oluÅŸturun
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# Modeli derleme
model.compile(loss=tf.keras.losses.mae, # mean absolute error
              optimizer=tf.keras.optimizers.SGD(), # stochastic gradient descent
              metrics=["mae"])

# modeli fit etme
model.fit(X, y, epochs=5)
```

Ä°ÅŸte bu kadar basit :) 

X'e baÄŸlÄ± bir y deÄŸeri oluÅŸturan bir modeli geliÅŸtirdik.

```python
# X ve y deÄŸerlerini kontrol edelim
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)

```python
# Var olan bir X deÄŸeri ile modelimiz doÄŸru bir y deÄŸeri Ã¼retecek mi?
model.predict([8.0])
```
Ama ama bu niye bÃ¶yle oldu :(  Her ÅŸeyi doÄŸru yaptÄ±k gibi. Modele bir input ve output deÄŸeri verdik. Bunu bir sinir aÄŸÄ±na baÄŸladÄ±k. Fakat doÄŸru sonuÃ§la alakasÄ± bile olmayan bir output deÄŸeri verdi bize. 

> Bu soruya cevap vermeden Ã¶nce size kÄ±sa bir soru sormak istiyorum. TensorFlow iÃ§erisinde hep Keras dediÄŸimiz yapÄ±larÄ± gÃ¶rÃ¼yoruz. Bu keras nedir? [Cevap](https://i.ibb.co/LNScsJd/cevap1.png)


## Bir Model GeliÅŸtirmek

Model istediÄŸimiz sonucu vermeyi bÄ±rakÄ±n, yakÄ±nÄ±na dahi yanaÅŸamadÄ±. Peki burada Ã§Ã¶zÃ¼m ne?

DoÄŸru tahmin ettiniz. Fine tuning yani ince ayar yapmak. Modeli geliÅŸtirmek iÃ§in hangi adÄ±mlarÄ± uyguladÄ±k:

1. **Model oluÅŸturma**<br>
Burada daha fazla katman eklemek, her katmandaki gizli birimlerin (nÃ¶ronlar olarak da adlandÄ±rÄ±lÄ±r) sayÄ±sÄ±nÄ± artÄ±rmak, her katmanÄ±n etkinleÅŸtirme iÅŸlevlerini deÄŸiÅŸtirmek isteyebilirsiniz.
2. **Model derleme**<br>
Optimizasyon fonksiyonunu seÃ§mek veya belki de optimizasyon fonksiyonunun Ã¶ÄŸrenme oranÄ±nÄ± deÄŸiÅŸtirmek isteyebilirsiniz.
3. **Modeli fit etme**<br>
Daha fazla epoch veya daha fazla veri ile daha iyi sonuÃ§lar almak isteyebilirsiniz.

Vay. Az Ã¶nce bir dizi olasÄ± adÄ±mÄ± tanÄ±ttÄ±k. HatÄ±rlanmasÄ± gereken Ã¶nemli ÅŸey, bunlarÄ±n her birini nasÄ±l deÄŸiÅŸtireceÄŸiniz, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z soruna baÄŸlÄ± olacaktÄ±r.

```python
# yukarÄ±da bu yapÄ±yÄ± ayrÄ±ntÄ±sÄ±yla anlattÄ±m
tf.random.set_seed(42)

# bir Ã¶nceki modelin aynÄ±sÄ±nÄ± uygulayalÄ±m
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli aynÄ± ÅŸekilde derleyelim
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# ÅŸimdi fit edelim, ama bu sefer 100 epoch kullanarak
model.fit(X, y, epochs=100)
```
YukarÄ± da ki kod bloÄŸunu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda MAE deÄŸerinin yani kayÄ±p fonksiyonun adÄ±m adÄ±m dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ gÃ¶zlemleyeceksiniz. Ä°ÅŸte bu anda geriye yaslanÄ±p iÅŸlemin bitmesini bekleyebilirsiniz Ã§Ã¼nkÃ¼ bu doÄŸru gittiÄŸinizi gÃ¶steriyor.

YukarÄ±da 5 epoch ile eÄŸittimizde hiÃ§ gÃ¼zel bir tahmin deÄŸeri almadÄ±k. Peki ya ÅŸimdi?

```python
model.predict([8.0])
```
Ä°ÅŸte buuu ğŸ’ª 0.33 lÃ¼k bir sapma var ama modelimiz resmen input ve output deÄŸerlerini ile doÄŸru eÄŸitilmiÅŸ.

Åimdi de modelimizde olmayan bir sayÄ± ile deneme yapalÄ±m. 
Modelimize tekrar gÃ¶z atalÄ±m. Test etmek iÃ§in arada ki baÄŸlantÄ±yÄ± bulmamÄ±z gerekiyor.
```python
X, y
```
> (<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,
 <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)
 
- -7 --> 3
- -4 --> 6
- -1 --> 9

YukarÄ±da ki eÅŸitliklere baktÄ±ÄŸÄ±mÄ±zda x + 10 = y gibi bir eÅŸitiÄŸin olduÄŸunu hemen anlayabiliriz. Denklemi Ã§Ä±kardÄ±ÄŸÄ±mÄ±za gÃ¶re ÅŸimdi dizide olmayan bir sayÄ±da nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶zlemleyebiliriz.

```python
model.predict([20]) # cevabÄ±n 20+10= 30 olmasÄ±nÄ± bekliyoruz
```
HÄ±mm. YaklaÅŸÄ±k bir sonuÃ§ ama tam da istediÄŸimiz bir cevap deÄŸil. Modelimizi bir deÄŸerlendirelim daha sonra nasÄ±l daha iyi sonuÃ§ alacaÄŸÄ±mÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼rÃ¼z.
 
 
## Modeli DeÄŸerlendirme

Sinir aÄŸÄ± oluÅŸtururken takip edilen tipik bir akÄ±ÅŸ var:
```
Bir model yarat -> Onu deÄŸerlendir -> Bir model yarat -> Onu deÄŸerlendir -> Bir model yarat -> Onu deÄŸerlendir ...
```
Fine tuning (ince ayarlama), sÄ±fÄ±rdan bir model oluÅŸturmak deÄŸil, mevcut bir model Ã¼zerinde ayarlamalar yapmaktÄ±r.

Modeli deÄŸerlendirirken yapÄ±lacak en gÃ¼zel davranÄ±ÅŸlardan bazÄ±larÄ± ÅŸunlardÄ±r:
- GÃ¶rselleÅŸtirin
- GÃ¶rselleÅŸtirin
- GÃ¶rselleÅŸtirin

LÃ¼tfen modeli gÃ¶rselleÅŸtirin. GÃ¶rselleÅŸtirmeniz gereken bazÄ± fikirler:
- Veriler - hangi verilerle Ã§alÄ±ÅŸÄ±yorsunuz? NasÄ±l gÃ¶rÃ¼nÃ¼yor?
- Modelin kendisi - mimari neye benziyor? FarklÄ± ÅŸekiller nelerdir?
- Bir modelin eÄŸitimi - bir model Ã¶ÄŸrenirken nasÄ±l performans gÃ¶sterir?
- Bir modelin tahminleri - bir modelin tahminleri temel gerÃ§eÄŸe (orijinal etiketler) karÅŸÄ± nasÄ±l sÄ±ralanÄ±r?

GÃ¶rselleÅŸtirmeyi 1 adÄ±m sonraya erteliyoruz Ã§Ã¼nkÃ¼ yukarÄ±da eÄŸittiÄŸimiz model tam da istediÄŸimiz sonucu vermedi. Bu yÃ¼zden yukarÄ±da ki modeli daha fazla veri ile tekrar eÄŸitmek iyi olabilir.

```python
# Daha bÃ¼yÃ¼k bir veriseti yaratma
X = np.arange(-100, 100, 4)
X
```
> array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,
        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,
        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,
         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,
         76,   80,   84,   88,   92,   96])

```python
# ÅŸimdi de etiketlerini oluÅŸturalÄ±m
y = np.arange(-90, 110, 4)
y
```
> array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,
       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,
        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,
        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])

`x + 10 = y` eÅŸitliÄŸi saÄŸladÄ±k gibi duruyor. 

### Verileri Train ve Test Olarak AyÄ±rma

Bir makine Ã¶ÄŸrenimi projesindeki diÄŸer en yaygÄ±n ve Ã¶nemli adÄ±mlardan biri, bir eÄŸitim ve test seti (ve gerektiÄŸinde bir doÄŸrulama seti) oluÅŸturmaktÄ±r.

Her set belirli bir amaca hizmet eder:

- **EÄŸitim seti**<br>
Model, genellikle mevcut toplam verilerin (epoch boyunca Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z ders materyalleri gibi) %70-80'i olan bu verilerden Ã¶ÄŸrenir.
- **DoÄŸrulama seti**<br> 
Model, genellikle mevcut toplam verilerin %10-15'i olan bu verilere gÃ¶re ayarlanÄ±r (final sÄ±navÄ±ndan Ã¶nce girdiÄŸiniz alÄ±ÅŸtÄ±rma sÄ±navÄ± gibi).
- **Test seti**<br>
Model, Ã¶ÄŸrendiklerini test etmek iÃ§in bu veriler Ã¼zerinde deÄŸerlendirilir, genellikle mevcut toplam verilerin %10-15'i kadardÄ±r (dÃ¶nem sonunda girdiÄŸiniz final sÄ±navÄ± gibi).

Åimdilik sadece bir eÄŸitim ve test seti kullanacaÄŸÄ±z, bu, modelimizin Ã¶ÄŸrenilmesi ve deÄŸerlendirilmesi iÃ§in bir veri setimiz olacaÄŸÄ± anlamÄ±na geliyor.

X ve y dizilerimizi bÃ¶lerek bunlarÄ± oluÅŸturabiliriz.

> ğŸ”‘ Not: GerÃ§ek dÃ¼nya verileriyle uÄŸraÅŸÄ±rken, bu adÄ±m tipik olarak bir projenin hemen baÅŸlangÄ±cÄ±nda yapÄ±lÄ±r (test seti her zaman diÄŸer tÃ¼m verilerden ayrÄ± tutulmalÄ±dÄ±r). Modelimizin eÄŸitim verilerini Ã¶ÄŸrenmesini ve ardÄ±ndan gÃ¶rÃ¼nmeyen Ã¶rneklere ne kadar iyi genelleÅŸtiÄŸine dair bir gÃ¶sterge elde etmek iÃ§in test verileri Ã¼zerinde deÄŸerlendirmesini istiyoruz.

```python
# verisetimizin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne bakalÄ±m
len(X)
```
> 50


```python
# verileri train ve test olarak ayÄ±ralÄ±m
X_train = X[:40] # verilerin %80'ine denk geliyor
y_train = y[:40]

X_test = X[40:]
y_test = y[40:]

len(X_train), len(X_test)
```
> (40, 10)


### Verileri GÃ¶rselleÅŸtirme

ArtÄ±k eÄŸitim ve test verilerimiz var, artÄ±k bunu gÃ¶rselleÅŸtirmek iyi bir fikir.

Neyin ne olduÄŸunu ayÄ±rt etmek iÃ§in gÃ¼zel renklerle Ã§izelim.

```python
plt.figure(figsize=(10, 7))
# train verileri mavi olsun
plt.scatter(X_train, y_train, c='b', label='Training data')
# test verileri yeÅŸil olsun
plt.scatter(X_test, y_test, c='g', label='Testing data')
plt.legend();
```
> <img src="https://i.ibb.co/xDL5jBD/indir.png" />

GÃ¼zel! Verilerinizi, modelinizi, herhangi bir ÅŸeyi gÃ¶rselleÅŸtirebildiÄŸiniz her an, bu iyi bir fikirdir.

Bu grafiÄŸi gÃ¶z Ã¶nÃ¼nde bulundurarak, yeÅŸil noktalarÄ± (X_test) Ã§izmek iÃ§in mavi noktalardaki (X_train) deseni Ã¶ÄŸrenen bir model oluÅŸturmaya Ã§alÄ±ÅŸacaÄŸÄ±z.

```python
tf.random.set_seed(42)

# bir model yaratma
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli derleme
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# modeli fit etme
# model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)
```

### Modeli GÃ¶rselleÅŸtirme

Bir model oluÅŸturduktan sonra, ona bir gÃ¶z atmak isteyebilirsiniz (Ã¶zellikle daha Ã¶nce Ã§ok model oluÅŸturmadÄ±ysanÄ±z).

Modelinizin katmanlarÄ±nÄ± ve ÅŸekillerini, Ã¼zerinde Summary()'i arayarak inceleyebilirsiniz.

ğŸ”‘ Not: Bir modeli gÃ¶rselleÅŸtirmek, Ã¶zellikle girdi ve Ã§Ä±ktÄ± ÅŸekli uyumsuzluklarÄ±yla karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda faydalÄ±dÄ±r.

```python
# Ã§alÄ±ÅŸmayacak (modeli fit etmedik)
model.summary()
```
> ValueError

Sizce yukarÄ±da ki hatanÄ±n sebebi modeli fit etmememiz mi? HÄ±mm. Hata mesajÄ±nÄ± okuduÄŸumuzda `input_shape` deÄŸerinin olmadÄ±ÄŸÄ±nÄ± sÃ¶ylÃ¼yor. 

`Input_shape` deÄŸeri ilk katmana girilir. Åimdi deneyelim ve bakalÄ±m hata gideriliyor mu?


```python
tf.random.set_seed(42)

# bir model yaratma
model = tf.keras.Sequential([
  tf.keras.layers.Dense(1, input_shape=[1])
])

# modeli derleme
model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=["mae"])

# modeli fit etme
# model.fit(X_train, y_train, epochs=100) # commented out on purpose (not fitting it just yet)
```

```python
model.summary()
```
> <img src="https://i.ibb.co/8cZRccR/Ekran-g-r-nt-s-2021-07-04-120440.png" />

Modelimizde `summary()` iÅŸlevini Ã§aÄŸÄ±rmak bize iÃ§erdiÄŸi katmanlarÄ±, Ã§Ä±ktÄ± ÅŸeklini ve parametre sayÄ±sÄ±nÄ± gÃ¶sterir.

- **Toplam parametreler**<br>
Modeldeki toplam parametre sayÄ±sÄ±.
- **EÄŸitilebilir parametreler**<br>
Bunlar, modelin eÄŸitirken gÃ¼ncelleyebileceÄŸi parametrelerdir (kalÄ±plardÄ±r).
- **EÄŸitilemez parametreler**<br>
Bu parametreler eÄŸitim sÄ±rasÄ±nda gÃ¼ncellenmez (bu, transfer learninig sÄ±rasÄ±nda diÄŸer modellerden Ã¶nceden Ã¶ÄŸrenilmiÅŸ kalÄ±plarÄ± getirdiÄŸinizde tipiktir).

> ğŸ“– Kaynak: Bir katmandaki eÄŸitilebilir parametrelere daha derinlemesine bir genel bakÄ±ÅŸ iÃ§in [MIT'nin derin Ã¶ÄŸrenme videosuna](https://www.youtube.com/watch?v=njKP3FqW3Sk) giriÅŸine gÃ¶z atÄ±n.

> ğŸ›  AlÄ±ÅŸtÄ±rma: Dense katmandaki gizli birimlerin sayÄ±sÄ±yla oynamayÄ± deneyin (Ã¶rn. `Dense(2)`, `Dense(3)`). Bu, Toplam/EÄŸitilebilir parametreleri nasÄ±l deÄŸiÅŸtirir? DeÄŸiÅŸikliÄŸe neyin sebep olduÄŸunu araÅŸtÄ±rÄ±n.

Åimdilik, bu parametreler hakkÄ±nda dÃ¼ÅŸÃ¼nmeniz gereken tek ÅŸey, bunlarÄ±n verilerdeki Ã¶ÄŸrenilebilir kalÄ±plarÄ±dÄ±r.

Modelimizi eÄŸitim verileriyle fir edelim ÅŸimdi.


```python
# modeli eÄŸitim verileriyle fit etme
model.fit(X_train, y_train, epochs=100, verbose=0)
```

Ã–zetin yanÄ± sÄ±ra plot_model() kullanarak modelin 2D grafiÄŸini de gÃ¶rÃ¼ntÃ¼leyebilirsiniz.

```python
from tensorflow.keras.utils import plot_model

plot_model(model, show_shapes=True)
```
> <img src="https://i.ibb.co/8cZRccR/Ekran-g-r-nt-s-2021-07-04-120440.png" />

Bizim durumumuzda, kullandÄ±ÄŸÄ±mÄ±z modelin yalnÄ±zca bir girdisi ve bir Ã§Ä±ktÄ±sÄ± var, ancak daha karmaÅŸÄ±k modelleri gÃ¶rselleÅŸtirmek hata ayÄ±klama iÃ§in Ã§ok yardÄ±mcÄ± olabilir.

### Tahminleri GÃ¶rselleÅŸtirme

Åimdi eÄŸitilmiÅŸ bir modelimiz var, hadi bazÄ± tahminleri gÃ¶rselleÅŸtirelim.

Tahminleri gÃ¶rselleÅŸtirmek iÃ§in, onlarÄ± temel gerÃ§ek etiketlerine gÃ¶re planlamak her zaman iyi bir fikirdir.

Bunu genellikle y_test ve y_pred (gerÃ§ek ve tahminler) ÅŸeklinde gÃ¶rÃ¼rsÃ¼nÃ¼z.

Ä°lk olarak, test verileri (X_test) Ã¼zerinde bazÄ± tahminler yapacaÄŸÄ±z, modelin test verilerini hiÃ§ gÃ¶rmediÄŸini unutmayÄ±n.


```python
# modeli predict edelim (X_test verileri ile)
y_preds = model.predict(X_test)

# tahminleri gÃ¶relim
y_preds
```
> array([[53.57109 ],
       [57.05633 ],
       [60.541573],
       [64.02681 ],
       [67.512054],
       [70.99729 ],
       [74.48254 ],
       [77.96777 ],
       [81.45301 ],
       [84.938255]], dtype=float32)

BunlarÄ± gerÃ§ek deÄŸerler ile karÅŸÄ±laÅŸtÄ±rÄ±p modelin doÄŸruluÄŸunu anlamak iÃ§in bir fonksiyon yaratalÄ±m:

```python
def plot_predictions(train_data=X_train, 
                     train_labels=y_train, 
                     test_data=X_test, 
                     test_labels=y_test, 
                     predictions=y_preds):
  """
  EÄŸitim verilerini, test verilerini gÃ¶rselleÅŸtirir ve tahminleri karÅŸÄ±laÅŸtÄ±rÄ±r.
  """
  plt.figure(figsize=(10, 7))
  # train verileri mavi olsun
  plt.scatter(train_data, train_labels, c="b", label="Training data")
  # test verileri yeÅŸil olsun
  plt.scatter(test_data, test_labels, c="g", label="Testing data")
  # tahmin deÄŸerleri kÄ±rmÄ±zÄ± olsun
  plt.scatter(test_data, predictions, c="r", label="Predictions")
  plt.legend();
  
plot_predictions(train_data=X_train,
                 train_labels=y_train,
                 test_data=X_test,
                 test_labels=y_test,
                 predictions=y_preds)
```
> <img src="https://i.ibb.co/Vv70dWN/indir-2.png" />

### Tahminleri DeÄŸerlendirme

GÃ¶rselleÅŸtirmelerin yanÄ± sÄ±ra deÄŸerlendirme metrikleri, modelinizi deÄŸerlendirmek iÃ§in alternatif en iyi seÃ§eneÄŸinizdir.

Ãœzerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z soruna baÄŸlÄ± olarak, farklÄ± modellerin farklÄ± deÄŸerlendirme Ã¶lÃ§Ã¼tleri vardÄ±r.

Regresyon problemleri iÃ§in kullanÄ±lan ana metriklerden ikisi ÅŸunlardÄ±r:

- **Mean absolute error (MAE)**<br>
Tahminlerin her biri arasÄ±ndaki ortalama fark.
- **Mean squared error (MSE)**<br>
Tahminler arasÄ±ndaki kare ortalama fark.

Bu deÄŸerlerin her biri ne kadar dÃ¼ÅŸÃ¼kse, o kadar iyidir.

AyrÄ±ca, derleme adÄ±mÄ± sÄ±rasÄ±nda herhangi bir Ã¶lÃ§Ã¼m ayarÄ±nÄ±n yanÄ± sÄ±ra modelin kaybÄ±nÄ± dÃ¶ndÃ¼recek olan `model.evaluate()` Ã¶ÄŸesini de kullanabilirsiniz.

```python
model.evaluate(X_test, y_test)
```
> [18.74532699584961, 18.74532699584961]

Biz MAE(`metrics=['MAE']`) deÄŸerini kullandÄ±ÄŸÄ±mÄ±z iÃ§in evaluate fonksiyonu bize MAE deÄŸerini dÃ¶ndÃ¼recektir.

TensorFlow'da ayrÄ±ca MSE ve MAE iÃ§in ayrÄ± olarak fonksiyonlar vardÄ±r. Bunlar deÄŸerlendirme iÃ§in ayrÄ±ca kullanÄ±labilir.


```python
# MAE deÄŸerini fonksiyon ile hesaplama
mae = tf.metrics.mean_absolute_error(y_true=y_test, 
                                     y_pred=y_preds)
mae
```
> <tf.Tensor: shape=(10,), dtype=float32, numpy=
array([34.42891 , 30.943668, 27.45843 , 23.97319 , 20.487946, 17.202168,
       14.510478, 12.419336, 11.018796, 10.212349], dtype=float32)>

Aaa. Neden bir Ã§Ä±ktÄ± yerine on farklÄ± Ã§Ä±ktÄ± aldÄ±k?

Bunun nedeni, y_test ve y_preds tensorlerinin farklÄ± ÅŸekillerde olmasÄ±ndan kaynaklanÄ±yor.

```python
# y etiket tensorÃ¼nÃ¼ kontrol edelim
y_test
```
> array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])

```python
# tahminleri kontrol edelim
y_preds
```
> array([[53.57109 ],
       [57.05633 ],
       [60.541573],
       [64.02681 ],
       [67.512054],
       [70.99729 ],
       [74.48254 ],
       [77.96777 ],
       [81.45301 ],
       [84.938255]], dtype=float32)

```python
# tesorlerin ÅŸekillerini kontrol edelim
y_test.shape, y_preds.shape
```
> ((10,), (10, 1))

HatÄ±rlarsanÄ±z en baÅŸta Input ve Outpu deÄŸerlerini konuÅŸmuÅŸduk. Ve o sorun geldi Ã§attÄ±. Bu deÄŸerlerin aynÄ± ÅŸekillere sahip olmasoÄ± gerekiyor yoksa deÄŸerlendirmemiz imkansÄ±z.

`squeeze()` kullanarak bunu dÃ¼zeltebiliriz, 1 boyutunu y_preds tensÃ¶rÃ¼mÃ¼zden kaldÄ±racak ve onu y_test ile aynÄ± ÅŸekle getirecektir.

```python
# squeeze() kullanmadan Ã¶nce
y_preds.shape
```
> (10, 1)


```python
# squeeze() kullandÄ±ktan sonra
y_preds.squeeze().shape
```
> (10, )

```python
# verilere  ayrÄ±ntÄ±lÄ± bakalÄ±m
y_test, y_preds.squeeze()
```
> (array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106]),
 array([53.57109 , 57.05633 , 60.541573, 64.02681 , 67.512054, 70.99729 ,
        74.48254 , 77.96777 , 81.45301 , 84.938255], dtype=float32))

TamamdÄ±r, ÅŸimdi y_test ve y_preds tensorlerÄ±mÄ±zÄ± nasÄ±l aynÄ± ÅŸekle getireceÄŸimizi biliyoruz, hadi deÄŸerlendirme metriklerimizi kullanalÄ±m.

```python
# MAE deÄŸerini hesaplama
mae = tf.metrics.mean_absolute_error(y_true=y_test, 
                                     y_pred=y_preds.squeeze())

# MSE deÄŸerini hesaplama
mse = tf.metrics.mean_squared_error(y_true=y_test,
                                    y_pred=y_preds.squeeze())
mse, mae
```
> (<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>, <tf.Tensor: shape=(), dtype=float32, numpy=353.57336> )

MAE'yi saf TensorFlow iÅŸlevlerini kullanarak da hesaplayabiliriz.

```python
tf.reduce_mean(tf.abs(y_test-y_preds.squeeze()))
```
> <tf.Tensor: shape=(), dtype=float64, numpy=18.745327377319335>

Yine, tekrar kullanabileceÄŸinizi (veya kendinizi tekrar tekrar kullanÄ±rken bulabileceÄŸinizi) dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z herhangi bir ÅŸeyi iÅŸlevsel hale getirmek iyi bir fikirdir.

DeÄŸerlendirme metriklerimiz iÃ§in fonksiyonlar yaratalÄ±m

```python
def mae(y_test, y_pred):
  """
  y_test ve y_preds arasÄ±ndaki ortalama mutlak hatayÄ± hesaplar.
  """
  return tf.metrics.mean_absolute_error(y_test,
                                        y_pred)
  
def mse(y_test, y_pred):
  """
  y_test ve y_preds arasÄ±ndaki ortalama karesel hatayÄ± hesaplar
  """
  return tf.metrics.mean_squared_error(y_test,
                                       y_pred)
```

### Bir Modeli GeliÅŸtirmek Ä°Ã§in Denemeler Yapmak

DeÄŸerlendirme metriklerini ve modelinizin yaptÄ±ÄŸÄ± tahminleri gÃ¶rdÃ¼kten sonra, muhtemelen modeli geliÅŸtirmek isteyeceksiniz.

Yine, bunu yapmanÄ±n birÃ§ok farklÄ± yolu vardÄ±r, ancak bunlardan baÅŸlÄ±ca 3 tanesi ÅŸunlardÄ±r:

- **Daha fazla veri elde edin**<br>
Modeliniz iÃ§in daha fazla Ã¶rnek alÄ±n (kalÄ±plarÄ± Ã¶ÄŸrenmek iÃ§in daha fazla fÄ±rsat).
- **Modelinizi bÃ¼yÃ¼tÃ¼n (daha karmaÅŸÄ±k bir model kullanÄ±n)**<br>
Bu, her katmanda daha fazla katman veya daha fazla gizli birim ÅŸeklinde olabilir.
- **Daha uzun sÃ¼re eÄŸitin**<br>
Modelinize verilerdeki kalÄ±plarÄ± bulma ÅŸansÄ± verin.

Veri kÃ¼memizi oluÅŸturduÄŸumuzdan, kolayca daha fazla veri Ã¼retebiliyorduk, ancak gerÃ§ek dÃ¼nya veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken durum her zaman bÃ¶yle olmuyor.

Åimdi 2 ve 3'Ã¼ kullanarak modelimizi nasÄ±l geliÅŸtirebileceÄŸimize bir gÃ¶z atalÄ±m.

Bunu yapmak iÃ§in 3 model oluÅŸturacaÄŸÄ±z ve sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z:

- `model_1` - orijinal modelle aynÄ±, 1 katman, 100 epoch iÃ§in eÄŸitilmiÅŸ.
- `model_2` - 100 epoch iÃ§in eÄŸitilmiÅŸ 2 katman.
- `model_3` - 500 epoch iÃ§in eÄŸitilmiÅŸ 2 katman.

`Model_1` 


```python
tf.random.set_seed(42)

# Orijinal modeli Ã§oÄŸaltÄ±yoruz
model_1 = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

# modeli derleme
model_1.compile(loss=tf.keras.losses.mae,
                optimizer=tf.keras.optimizers.SGD(),
                metrics=['mae'])

# modeli fit etme
model_1.fit(X_train, y_train, epochs=100, verbose=0)
```

```python
# tahminleri model_1 iÃ§in gÃ¶rselleÅŸtirelim
y_preds_1 = model_1.predict(X_test)
plot_predictions(predictions=y_preds_1)
```
> <img src="https://i.ibb.co/Vv70dWN/indir-2.png" />


```python
mae_1 = mae(y_test, y_preds_1.squeeze()).numpy()
mse_1 = mse(y_test, y_preds_1.squeeze()).numpy()
mae_1, mse_1
```
> (18.745327, 353.57336)



```python

```




```python

```



```python

```



```python

```



```python

```



```python

```



```python

```




