# EvriÅŸimsel Sinir AÄŸlarÄ± (CNN)

EvriÅŸimli sinir aÄŸlarÄ± gÃ¶rÃ¼ntÃ¼lerle Ã§ok iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan, onlar hakkÄ±nda daha fazla bilgi edinmek iÃ§in bir gÃ¶rÃ¼ntÃ¼ veri kÃ¼mesiyle baÅŸlayacaÄŸÄ±z. Ã‡alÄ±ÅŸacaÄŸÄ±mÄ±z gÃ¶rseller, 101.001 gÃ¶rselden, 101 farklÄ± kategoriden oluÅŸtan [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) veri setindenden alÄ±nmÄ±ÅŸtÄ±r.

BaÅŸlangÄ±Ã§ iÃ§in, kategorilerden sadece ikisini kullanacaÄŸÄ±z: pizza ve biftek.

> ğŸ”‘ Not: KullandÄ±ÄŸÄ±mÄ±z verileri hazÄ±rlamak iÃ§in gÃ¶rÃ¼ntÃ¼leri farklÄ± alt kÃ¼me klasÃ¶rlerine taÅŸÄ±ma gibi Ã¶n iÅŸleme adÄ±mlarÄ± yapÄ±lmÄ±ÅŸtÄ±r.


```python
# google drive dosyalarÄ±na eriÅŸmek iÃ§in yetki istiyoruz
from google.colab import drive
drive.mount("/content/gdrive")
```

    Mounted at /content/gdrive



```python
# zip ÅŸeklinde olan dosyayÄ± unzipliyoruz
import zipfile

# zip'in path adresi
zir_path = "/content/gdrive/MyDrive/Colab Notebooks/TensorFlow Developer Certificate/egÌ†itimler/pizza_steak.zip"
zip_ref = zipfile.ZipFile(zir_path, "r")
zip_ref.extractall()
zip_ref.close()
```

> Not: Google Colab kullanÄ±yorsanÄ±z ve Ã§alÄ±ÅŸma zamanÄ±nÄ±zÄ±n baÄŸlantÄ±sÄ± kesilirse, dosyalarÄ± yeniden indirmeniz gerekebilir. Bunu, yukarÄ±daki hÃ¼creyi yeniden Ã§alÄ±ÅŸtÄ±rarak yapabilirsiniz.

## Verileri Ä°nceleyin

Herhangi bir makine Ã¶ÄŸrenimi projesinin baÅŸlangÄ±cÄ±nda Ã§ok Ã¶nemli bir adÄ±m, verilerle bir olmaktÄ±r. Bu genellikle, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z verileri anlamak iÃ§in bol miktarda gÃ¶rselleÅŸtirme ve klasÃ¶r taramasÄ± anlamÄ±na gelir. Bunu sÃ¶ylerken, az Ã¶nce indirdiÄŸimiz verileri inceleyelim.

Dosya yapÄ±sÄ±, resimlerle Ã§alÄ±ÅŸmak iÃ§in kullanabileceÄŸiniz tipik bir biÃ§imde biÃ§imlendirilmiÅŸtir.

Daha spesifik olarak:

EÄŸitim veri kÃ¼mesindeki tÃ¼m gÃ¶rÃ¼ntÃ¼leri iÃ§eren ve her biri o sÄ±nÄ±fÄ±n gÃ¶rÃ¼ntÃ¼lerini iÃ§eren belirli bir sÄ±nÄ±ftan sonra adlandÄ±rÄ±lan alt dizinleri iÃ§eren bir train dizini.

Train dizini ile aynÄ± yapÄ±ya sahip bir test dizini.


```
pizza_steak 
â””â”€â”€â”€train 
â”‚   â””â”€â”€â”€pizza
â”‚   â”‚   â”‚   1008104.jpg
â”‚   â”‚   â”‚   1638227.jpg
â”‚   â”‚   â”‚   ...      
â”‚   â””â”€â”€â”€steak
â”‚       â”‚   1000205.jpg
â”‚       â”‚   1647351.jpg
â”‚       â”‚   ...
â”‚   
â””â”€â”€â”€test 
â”‚   â””â”€â”€â”€pizza
â”‚   â”‚   â”‚   1001116.jpg
â”‚   â”‚   â”‚   1507019.jpg
â”‚   â”‚   â”‚   ...      
â”‚   â””â”€â”€â”€steak
â”‚       â”‚   100274.jpg
â”‚       â”‚   1653815.jpg
â”‚       â”‚   ...    
```

Ä°ndirdiÄŸimiz dizinlerin her birini inceleyelim. Bunu yapmak iÃ§in, liste anlamÄ±na gelen `ls` komutunu kullanabiliriz.



```python
!ls pizza_steak
```

    test  train


Train ve test klasÃ¶rlerimizi gÃ¶rÃ¼yoruz. BakalÄ±m iÃ§lerinde ne varmÄ±ÅŸ.


```python
!ls pizza_steak/train/
```

    pizza  steak


Peki ya steak iÃ§erisinde ne var?


```python
!ls pizza_steak/train/steak/
```

    1000205.jpg  1647351.jpg  2238681.jpg  2824680.jpg  3375959.jpg  417368.jpg
    100135.jpg   1650002.jpg  2238802.jpg  2825100.jpg  3381560.jpg  4176.jpg
    101312.jpg   165639.jpg   2254705.jpg  2826987.jpg  3382936.jpg  42125.jpg
    1021458.jpg  1658186.jpg  225990.jpg   2832499.jpg  3386119.jpg  421476.jpg
    1032846.jpg  1658443.jpg  2260231.jpg  2832960.jpg  3388717.jpg  421561.jpg
    10380.jpg    165964.jpg   2268692.jpg  285045.jpg   3389138.jpg  438871.jpg
    1049459.jpg  167069.jpg   2271133.jpg  285147.jpg   3393547.jpg  43924.jpg
    1053665.jpg  1675632.jpg  227576.jpg   2855315.jpg  3393688.jpg  440188.jpg
    1068516.jpg  1678108.jpg  2283057.jpg  2856066.jpg  3396589.jpg  442757.jpg
    1068975.jpg  168006.jpg   2286639.jpg  2859933.jpg  339891.jpg	 443210.jpg
    1081258.jpg  1682496.jpg  2287136.jpg  286219.jpg   3417789.jpg  444064.jpg
    1090122.jpg  1684438.jpg  2291292.jpg  2862562.jpg  3425047.jpg  444709.jpg
    1093966.jpg  168775.jpg   229323.jpg   2865730.jpg  3434983.jpg  447557.jpg
    1098844.jpg  1697339.jpg  2300534.jpg  2878151.jpg  3435358.jpg  461187.jpg
    1100074.jpg  1710569.jpg  2300845.jpg  2880035.jpg  3438319.jpg  461689.jpg
    1105280.jpg  1714605.jpg  231296.jpg   2881783.jpg  3444407.jpg  465494.jpg
    1117936.jpg  1724387.jpg  2315295.jpg  2884233.jpg  345734.jpg	 468384.jpg
    1126126.jpg  1724717.jpg  2323132.jpg  2890573.jpg  3460673.jpg  477486.jpg
    114601.jpg   172936.jpg   2324994.jpg  2893832.jpg  3465327.jpg  482022.jpg
    1147047.jpg  1736543.jpg  2327701.jpg  2893892.jpg  3466159.jpg  482465.jpg
    1147883.jpg  1736968.jpg  2331076.jpg  2907177.jpg  3469024.jpg  483788.jpg
    1155665.jpg  1746626.jpg  233964.jpg   290850.jpg   3470083.jpg  493029.jpg
    1163977.jpg  1752330.jpg  2344227.jpg  2909031.jpg  3476564.jpg  503589.jpg
    1190233.jpg  1761285.jpg  234626.jpg   2910418.jpg  3478318.jpg  510757.jpg
    1208405.jpg  176508.jpg   234704.jpg   2912290.jpg  3488748.jpg  513129.jpg
    1209120.jpg  1772039.jpg  2357281.jpg  2916448.jpg  3492328.jpg  513842.jpg
    1212161.jpg  1777107.jpg  2361812.jpg  2916967.jpg  3518960.jpg  523535.jpg
    1213988.jpg  1787505.jpg  2365287.jpg  2927833.jpg  3522209.jpg  525041.jpg
    1219039.jpg  179293.jpg   2374582.jpg  2928643.jpg  3524429.jpg  534560.jpg
    1225762.jpg  1816235.jpg  239025.jpg   2929179.jpg  3528458.jpg  534633.jpg
    1230968.jpg  1822407.jpg  2390628.jpg  2936477.jpg  3531805.jpg  536535.jpg
    1236155.jpg  1823263.jpg  2392910.jpg  2938012.jpg  3536023.jpg  541410.jpg
    1241193.jpg  1826066.jpg  2394465.jpg  2938151.jpg  3538682.jpg  543691.jpg
    1248337.jpg  1828502.jpg  2395127.jpg  2939678.jpg  3540750.jpg  560503.jpg
    1257104.jpg  1828969.jpg  2396291.jpg  2940544.jpg  354329.jpg	 561972.jpg
    126345.jpg   1829045.jpg  2400975.jpg  2940621.jpg  3547166.jpg  56240.jpg
    1264050.jpg  1829088.jpg  2403776.jpg  2949079.jpg  3553911.jpg  56409.jpg
    1264154.jpg  1836332.jpg  2403907.jpg  295491.jpg   3556871.jpg  564530.jpg
    1264858.jpg  1839025.jpg  240435.jpg   296268.jpg   355715.jpg	 568972.jpg
    127029.jpg   1839481.jpg  2404695.jpg  2964732.jpg  356234.jpg	 576725.jpg
    1289900.jpg  183995.jpg   2404884.jpg  2965021.jpg  3571963.jpg  588739.jpg
    1290362.jpg  184110.jpg   2407770.jpg  2966859.jpg  3576078.jpg  590142.jpg
    1295457.jpg  184226.jpg   2412263.jpg  2977966.jpg  3577618.jpg  60633.jpg
    1312841.jpg  1846706.jpg  2425062.jpg  2979061.jpg  3577732.jpg  60655.jpg
    1313316.jpg  1849364.jpg  2425389.jpg  2983260.jpg  3578934.jpg  606820.jpg
    1324791.jpg  1849463.jpg  2435316.jpg  2984311.jpg  358042.jpg	 612551.jpg
    1327567.jpg  1849542.jpg  2437268.jpg  2988960.jpg  358045.jpg	 614975.jpg
    1327667.jpg  1853564.jpg  2437843.jpg  2989882.jpg  3591821.jpg  616809.jpg
    1333055.jpg  1869467.jpg  2440131.jpg  2995169.jpg  359330.jpg	 628628.jpg
    1334054.jpg  1870942.jpg  2443168.jpg  2996324.jpg  3601483.jpg  632427.jpg
    1335556.jpg  187303.jpg   2446660.jpg  3000131.jpg  3606642.jpg  636594.jpg
    1337814.jpg  187521.jpg   2455944.jpg  3002350.jpg  3609394.jpg  637374.jpg
    1340977.jpg  1888450.jpg  2458401.jpg  3007772.jpg  361067.jpg	 640539.jpg
    1343209.jpg  1889336.jpg  2487306.jpg  3008192.jpg  3613455.jpg  644777.jpg
    134369.jpg   1907039.jpg  248841.jpg   3009617.jpg  3621464.jpg  644867.jpg
    1344105.jpg  1925230.jpg  2489716.jpg  3011642.jpg  3621562.jpg  658189.jpg
    134598.jpg   1927984.jpg  2490489.jpg  3020591.jpg  3621565.jpg  660900.jpg
    1346387.jpg  1930577.jpg  2495884.jpg  3030578.jpg  3623556.jpg  663014.jpg
    1348047.jpg  1937872.jpg  2495903.jpg  3047807.jpg  3640915.jpg  664545.jpg
    1351372.jpg  1941807.jpg  2499364.jpg  3059843.jpg  3643951.jpg  667075.jpg
    1362989.jpg  1942333.jpg  2500292.jpg  3074367.jpg  3653129.jpg  669180.jpg
    1367035.jpg  1945132.jpg  2509017.jpg  3082120.jpg  3656752.jpg  669960.jpg
    1371177.jpg  1961025.jpg  250978.jpg   3094354.jpg  3663518.jpg  6709.jpg
    1375640.jpg  1966300.jpg  2514432.jpg  3095301.jpg  3663800.jpg  674001.jpg
    1382427.jpg  1966967.jpg  2526838.jpg  3099645.jpg  3664376.jpg  676189.jpg
    1392718.jpg  1969596.jpg  252858.jpg   3100476.jpg  3670607.jpg  681609.jpg
    1395906.jpg  1971757.jpg  2532239.jpg  3110387.jpg  3671021.jpg  6926.jpg
    1400760.jpg  1976160.jpg  2534567.jpg  3113772.jpg  3671877.jpg  703556.jpg
    1403005.jpg  1984271.jpg  2535431.jpg  3116018.jpg  368073.jpg	 703909.jpg
    1404770.jpg  1987213.jpg  2535456.jpg  3128952.jpg  368162.jpg	 704316.jpg
    140832.jpg   1987639.jpg  2538000.jpg  3130412.jpg  368170.jpg	 714298.jpg
    141056.jpg   1995118.jpg  2543081.jpg  3136.jpg     3693649.jpg  720060.jpg
    141135.jpg   1995252.jpg  2544643.jpg  313851.jpg   3700079.jpg  726083.jpg
    1413972.jpg  199754.jpg   2547797.jpg  3140083.jpg  3704103.jpg  728020.jpg
    1421393.jpg  2002400.jpg  2548974.jpg  3140147.jpg  3707493.jpg  732986.jpg
    1428947.jpg  2011264.jpg  2549316.jpg  3142045.jpg  3716881.jpg  734445.jpg
    1433912.jpg  2012996.jpg  2561199.jpg  3142618.jpg  3724677.jpg  735441.jpg
    143490.jpg   2013535.jpg  2563233.jpg  3142674.jpg  3727036.jpg  740090.jpg
    1445352.jpg  2017387.jpg  256592.jpg   3143192.jpg  3727491.jpg  745189.jpg
    1446401.jpg  2018173.jpg  2568848.jpg  314359.jpg   3736065.jpg  752203.jpg
    1453991.jpg  2020613.jpg  2573392.jpg  3157832.jpg  37384.jpg	 75537.jpg
    1456841.jpg  2032669.jpg  2592401.jpg  3159818.jpg  3743286.jpg  756655.jpg
    146833.jpg   203450.jpg   2599817.jpg  3162376.jpg  3745515.jpg  762210.jpg
    1476404.jpg  2034628.jpg  2603058.jpg  3168620.jpg  3750472.jpg  763690.jpg
    1485083.jpg  2036920.jpg  2606444.jpg  3171085.jpg  3752362.jpg  767442.jpg
    1487113.jpg  2038418.jpg  2614189.jpg  317206.jpg   3766099.jpg  786409.jpg
    148916.jpg   2042975.jpg  2614649.jpg  3173444.jpg  3770370.jpg  80215.jpg
    149087.jpg   2045647.jpg  2615718.jpg  3180182.jpg  377190.jpg	 802348.jpg
    1493169.jpg  2050584.jpg  2619625.jpg  31881.jpg    3777020.jpg  804684.jpg
    149682.jpg   2052542.jpg  2622140.jpg  3191589.jpg  3777482.jpg  812163.jpg
    1508094.jpg  2056627.jpg  262321.jpg   3204977.jpg  3781152.jpg  813486.jpg
    1512226.jpg  2062248.jpg  2625330.jpg  320658.jpg   3787809.jpg  819027.jpg
    1512347.jpg  2081995.jpg  2628106.jpg  3209173.jpg  3788729.jpg  822550.jpg
    1524526.jpg  2087958.jpg  2629750.jpg  3223400.jpg  3790962.jpg  823766.jpg
    1530833.jpg  2088030.jpg  2643906.jpg  3223601.jpg  3792514.jpg  827764.jpg
    1539499.jpg  2088195.jpg  2644457.jpg  3241894.jpg  379737.jpg	 830007.jpg
    1541672.jpg  2090493.jpg  2648423.jpg  3245533.jpg  3807440.jpg  838344.jpg
    1548239.jpg  2090504.jpg  2651300.jpg  3245622.jpg  381162.jpg	 853327.jpg
    1550997.jpg  2125877.jpg  2653594.jpg  3247009.jpg  3812039.jpg  854150.jpg
    1552530.jpg  2129685.jpg  2661577.jpg  3253588.jpg  3829392.jpg  864997.jpg
    15580.jpg    2133717.jpg  2668916.jpg  3260624.jpg  3830872.jpg  885571.jpg
    1559052.jpg  2136662.jpg  268444.jpg   326587.jpg   38442.jpg	 907107.jpg
    1563266.jpg  213765.jpg   2691461.jpg  32693.jpg    3855584.jpg  908261.jpg
    1567554.jpg  2138335.jpg  2706403.jpg  3271253.jpg  3857508.jpg  910672.jpg
    1575322.jpg  2140776.jpg  270687.jpg   3274423.jpg  386335.jpg	 911803.jpg
    1588879.jpg  214320.jpg   2707522.jpg  3280453.jpg  3867460.jpg  91432.jpg
    1594719.jpg  2146963.jpg  2711806.jpg  3298495.jpg  3868959.jpg  914570.jpg
    1595869.jpg  215222.jpg   2716993.jpg  330182.jpg   3869679.jpg  922752.jpg
    1598345.jpg  2154126.jpg  2724554.jpg  3306627.jpg  388776.jpg	 923772.jpg
    1598885.jpg  2154779.jpg  2738227.jpg  3315727.jpg  3890465.jpg  926414.jpg
    1600179.jpg  2159975.jpg  2748917.jpg  331860.jpg   3894222.jpg  931356.jpg
    1600794.jpg  2163079.jpg  2760475.jpg  332232.jpg   3895825.jpg  937133.jpg
    160552.jpg   217250.jpg   2761427.jpg  3322909.jpg  389739.jpg	 945791.jpg
    1606596.jpg  2172600.jpg  2765887.jpg  332557.jpg   3916407.jpg  947877.jpg
    1615395.jpg  2173084.jpg  2768451.jpg  3326734.jpg  393349.jpg	 952407.jpg
    1618011.jpg  217996.jpg   2771149.jpg  3330642.jpg  393494.jpg	 952437.jpg
    1619357.jpg  2193684.jpg  2779040.jpg  3333128.jpg  398288.jpg	 955466.jpg
    1621763.jpg  220341.jpg   2788312.jpg  3333735.jpg  40094.jpg	 9555.jpg
    1623325.jpg  22080.jpg	  2788759.jpg  3334973.jpg  401094.jpg	 961341.jpg
    1624450.jpg  2216146.jpg  2796102.jpg  3335013.jpg  401144.jpg	 97656.jpg
    1624747.jpg  2222018.jpg  280284.jpg   3335267.jpg  401651.jpg	 979110.jpg
    1628861.jpg  2223787.jpg  2807888.jpg  3346787.jpg  405173.jpg	 980247.jpg
    1632774.jpg  2230959.jpg  2815172.jpg  3364420.jpg  405794.jpg	 982988.jpg
    1636831.jpg  2232310.jpg  2818805.jpg  336637.jpg   40762.jpg	 987732.jpg
    1645470.jpg  2233395.jpg  2823872.jpg  3372616.jpg  413325.jpg	 996684.jpg


En sevdiÄŸimiz: Bol bol veri :) Ã‡ok gÃ¶rÃ¼ntÃ¼ var ama ben yine de bunlarÄ±n kesin bir miktarÄ±nÄ± istiyorum. GÃ¶rÃ¼ntÃ¼lerin saysÄ±sÄ±nÄ± bulalÄ±m.


```python
import os

for dirpath, dirnames, filenames in os.walk("pizza_steak"):
  print(f"'{dirpath}' klasÃ¶rÃ¼nde {len(filenames)} veri var.")
```

    'pizza_steak' klasÃ¶rÃ¼nde 1 veri var.
    'pizza_steak/test' klasÃ¶rÃ¼nde 1 veri var.
    'pizza_steak/test/pizza' klasÃ¶rÃ¼nde 250 veri var.
    'pizza_steak/test/steak' klasÃ¶rÃ¼nde 250 veri var.
    'pizza_steak/train' klasÃ¶rÃ¼nde 1 veri var.
    'pizza_steak/train/pizza' klasÃ¶rÃ¼nde 750 veri var.
    'pizza_steak/train/steak' klasÃ¶rÃ¼nde 750 veri var.



```python
# Bir dosyada kaÃ§ tane resim olduÄŸunu bulmanÄ±n baÅŸka bir yolu
num_steak_images_train = len(os.listdir("pizza_steak/train/steak"))
num_steak_images_train
```




    750




```python
# Class adlarÄ±nÄ± alalÄ±m
import pathlib
import numpy as np
data_dir = pathlib.Path("pizza_steak/train/")
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)
```

    ['.DS_Store' 'pizza' 'steak']


Pekala, elimizde 750 train gÃ¶rseli ve 250 adet pizza ve biftek gÃ¶rseli iÃ§eren bir verisetimiz var.

BazÄ±larÄ±na bakalÄ±m.

> ğŸ¤” Not: Verilerle Ã§alÄ±ÅŸÄ±rken, mÃ¼mkÃ¼n olduÄŸunca gÃ¶rselleÅŸtirmek her zaman iyidir. Bir projenin ilk birkaÃ§ adÄ±mÄ±nÄ± verilerle bir bÃ¼tÃ¼n olarak ele alÄ±n. GÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin.


```python
# Bir resmi gÃ¶rÃ¼ntÃ¼leyelim
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

def view_random_image(target_dir, target_class):
  target_folder = target_dir+target_class

  # random bir gÃ¶rsel path'i
  random_image = random.sample(os.listdir(target_folder), 1)

  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"Image shape: {img.shape}") # show the shape of the image

  return img
```


```python
img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="steak")
```

    Image shape: (512, 512, 3)



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_17_1.png)
    


FarklÄ± sÄ±nÄ±flardan bir dÃ¼zine kadar gÃ¶rÃ¼ntÃ¼yÃ¼ inceledikten sonra, neyle Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z hakkÄ±nda bir fikir edinmeye baÅŸlayabilirsiniz. Food101 veri setinin tamamÄ±, 101 farklÄ± sÄ±nÄ±ftan benzer gÃ¶rÃ¼ntÃ¼lerden oluÅŸuyor. GÃ¶rÃ¼ntÃ¼ ÅŸeklini, Ã§izilen gÃ¶rÃ¼ntÃ¼nÃ¼n yanÄ±na yazdÄ±rdÄ±ÄŸÄ±mÄ±zÄ± fark etmiÅŸ olabilirsiniz. Bunun nedeni, bilgisayarÄ±mÄ±zÄ±n gÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶rme biÃ§iminin bÃ¼yÃ¼k bir dizi (tensÃ¶r) biÃ§iminde olmasÄ±dÄ±r.



```python
img
```




    array([[[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]],
    
           [[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]],
    
           [[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]],
    
           ...,
    
           [[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]],
    
           [[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]],
    
           [[0, 0, 2],
            [0, 0, 2],
            [0, 0, 2],
            ...,
            [0, 0, 2],
            [0, 0, 2],
            [0, 0, 2]]], dtype=uint8)




```python
# gÃ¶rÃ¼ntÃ¼nÃ¼n ÅŸeklini yazdÄ±ralÄ±m
img.shape
```




    (512, 512, 3)



GÃ¶rÃ¼ntÃ¼ ÅŸekline daha yakÄ±ndan baktÄ±ÄŸÄ±nÄ±zda, formda olduÄŸunu gÃ¶receksiniz (GeniÅŸlik, YÃ¼kseklik, Renk KanallarÄ±).

Bizim durumumuzda geniÅŸlik ve yÃ¼kseklik deÄŸiÅŸkendir ancak renkli gÃ¶rÃ¼ntÃ¼lerle uÄŸraÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in renk kanallarÄ± deÄŸeri her zaman 3'tÃ¼r. Bu, farklÄ± kÄ±rmÄ±zÄ±, yeÅŸil ve mavi (RGB) piksel deÄŸerleri iÃ§indir.

img dizisindeki tÃ¼m deÄŸerlerin 0 ile 255 arasÄ±nda olduÄŸunu fark edeceksiniz. Bunun nedeni, kÄ±rmÄ±zÄ±, yeÅŸil ve mavi deÄŸerlerin olasÄ± aralÄ±ÄŸÄ±nÄ±n bu olmasÄ±dÄ±r.

Ã–rneÄŸin, kÄ±rmÄ±zÄ±=0, yeÅŸil=0, mavi=255 deÄŸerine sahip bir piksel mavi gÃ¶rÃ¼necektir.

> ğŸ”‘ Not: Daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, sinir aÄŸlarÄ± dahil birÃ§ok makine Ã¶ÄŸrenimi modeli, birlikte Ã§alÄ±ÅŸtÄ±klarÄ± deÄŸerlerin 0 ile 1 arasÄ±nda olmasÄ±nÄ± tercih eder. Bunu bilerek, gÃ¶rÃ¼ntÃ¼lerle Ã§alÄ±ÅŸmak iÃ§in en yaygÄ±n Ã¶n iÅŸleme adÄ±mlarÄ±ndan biri Ã¶lÃ§eklendirmektir (ayrÄ±ca gÃ¶rÃ¼ntÃ¼ dizilerini 255'e bÃ¶lerek piksel deÄŸerlerini normalleÅŸtirme olarak adlandÄ±rÄ±lÄ±r.


```python
# 0 ve 1 arasÄ±ndaki tÃ¼m piksel deÄŸerlerini alÄ±n
img/255. 
```




    array([[[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]],
    
           [[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]],
    
           [[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]],
    
           ...,
    
           [[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]],
    
           [[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]],
    
           [[0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            ...,
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314],
            [0.        , 0.        , 0.00784314]]])



## Bir EvriÅŸimsel Sinir AÄŸÄ±nÄ±n Mimarisi

CNN, birÃ§ok farklÄ± ÅŸekilde oluÅŸturulabilmeleri nedeniyle diÄŸer derin Ã¶ÄŸrenme sinir aÄŸlarÄ±ndan farklÄ± deÄŸildir. AÅŸaÄŸÄ±da gÃ¶rdÃ¼kleriniz, geleneksel bir CNN'de bulmayÄ± umduÄŸunuz bazÄ± bileÅŸenlerdir.

EvriÅŸimli bir sinir aÄŸÄ±nÄ±n bileÅŸenleri:
- **Input Image** <br>
KalÄ±plarÄ± keÅŸfetmek istediÄŸiniz gÃ¶rÃ¼ntÃ¼leri hedefleyin
- **Input Layer** <br>
Hedef gÃ¶rÃ¼ntÃ¼leri alÄ±r ve daha sonraki katmanlar iÃ§in Ã¶nceden iÅŸler
- **Convolution Layer** <br>
Hedef gÃ¶rÃ¼ntÃ¼lerden en Ã¶nemli Ã¶zellikleri Ã§Ä±karÄ±r/Ã¶ÄŸrenir
- **Hidden Activation** <br>
Ã–ÄŸrenilen Ã¶zelliklere doÄŸrusal olmayanlara ekler (dÃ¼z olmayan Ã§izgiler)
- **Pooling layer** <br>
Ã–ÄŸrenilmiÅŸ gÃ¶rÃ¼ntÃ¼ Ã¶zelliklerinin boyutsallÄ±ÄŸÄ±nÄ± eÄŸitir
- **Fully Connected Layer** <br>
EvriÅŸim katmanlarÄ±ndan Ã¶ÄŸrenilen Ã¶zellikleri daha da iyileÅŸtirir
- **Output layer** <br>
Ã–ÄŸrenilen Ã¶zellikleri alÄ±r ve bunlarÄ± hedef etiketler ÅŸeklinde verir
- **Output activation** <br>
Ã‡Ä±ktÄ± katmanÄ±na doÄŸrusal olmayanlar ekler


### Ã–rnek

Verilerimizi inceledik ve sÄ±nÄ±f baÅŸÄ±na 750 train resminin yanÄ± sÄ±ra 250 test resmi olduÄŸunu ve hepsinin farklÄ± ÅŸekillerde olduÄŸunu gÃ¶rdÃ¼k.

DoÄŸrudan derinlere atlamanÄ±n zamanÄ± geldi.

Orijinal veri seti yazarlarÄ±nÄ±n makalesini okuduÄŸumuzda, bir Random Forest makine Ã¶ÄŸrenme modeli kullandÄ±klarÄ±nÄ± ve iÃ§lerinde hangi farklÄ± yiyeceklerin farklÄ± gÃ¶rÃ¼ntÃ¼lere sahip olduÄŸunu tahmin etmede ortalama %50,76 doÄŸruluk elde ettiklerini gÃ¶rÃ¼yoruz.

Åu andan itibaren, bu %50,76 bizim temelimiz olacak.

> ğŸ”‘ Not: Temel, denemek ve geÃ§mek istediÄŸiniz bir puan veya deÄŸerlendirme metriÄŸidir. Genellikle basit bir modelle baÅŸlayacak, bir temel oluÅŸturacak ve modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± artÄ±rarak onu yenmeye Ã§alÄ±ÅŸacaksÄ±nÄ±z. Makine Ã¶ÄŸrenimini Ã¶ÄŸrenmenin gerÃ§ekten eÄŸlenceli bir yolu, sonuÃ§larÄ± yayÄ±nlanmÄ±ÅŸ bir tÃ¼r modeli yenmeye Ã§alÄ±ÅŸmaktÄ±r.

AÅŸaÄŸÄ±daki hÃ¼credeki kod, pizza ve biftek veri setimizi yukarÄ±da listelenen bileÅŸenleri kullanarak bir evriÅŸimsel sinir aÄŸÄ± (CNN) ile modellemek iÃ§in uÃ§tan uca bir ÅŸekilde Ã§oÄŸalÄ±r.

AnlamayacaÄŸÄ±nÄ±z yerler olabilir fakat kodu iyice analiz ettiken sonra ne yapmak istediÄŸimi  anlayacaÄŸÄ±nÄ±zdan eminim. 

> ğŸ“– Kaynak: AÅŸaÄŸÄ±da kullandÄ±ÄŸÄ±mÄ±z mimari, 2014 ImageNet sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ±nda 2. olan evriÅŸimli bir sinir aÄŸÄ± olan VGG-16'nÄ±n kÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ bir versiyonudur.


```python
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

tf.random.set_seed(42)

# Ã–n iÅŸleme verileri (1 ile 0 arasÄ±ndaki tÃ¼m piksel deÄŸerlerini alÄ±n, 
# ayrÄ±ca Ã¶lÃ§ekleme/normalleÅŸtirme olarak da adlandÄ±rÄ±lÄ±r)
train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# Train ve test dizinlerini kurun
train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"

# Dizinlerdeki verileri iÃ§e aktarÄ±n
train_data = train_datagen.flow_from_directory(train_dir,
                                               # bir seferde iÅŸlenecek gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±
                                               batch_size=32, 
                                               # tÃ¼m gÃ¶rÃ¼ntÃ¼leri 224 x 224'e dÃ¶nÃ¼ÅŸtÃ¼r
                                               target_size=(224, 224), 
                                               # Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z problemin tÃ¼rÃ¼
                                               class_mode="binary", 
                                               seed=42)

valid_data = valid_datagen.flow_from_directory(test_dir,
                                               batch_size=32,
                                               target_size=(224, 224),
                                               class_mode="binary",
                                               seed=42)

# CNN modeli yaratma (https://poloclub.github.io/cnn-explainer/)
model_1 = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(filters=10, 
                         kernel_size=3,
                         activation="relu", 
                         input_shape=(224, 224, 3)), 
  tf.keras.layers.Conv2D(10, 3, activation="relu"),
  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size ayrÄ±ca (2, 2) olabilir
                            padding="valid"),
  tf.keras.layers.Conv2D(10, 3, activation="relu"),
  tf.keras.layers.Conv2D(10, 3, activation="relu"), 
  tf.keras.layers.MaxPool2D(2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(1, activation="sigmoid") # binary aktivasyon Ã§Ä±ktÄ±sÄ±
])

# modeli derleme
model_1.compile(loss="binary_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

# modeli fit etme
history_1 = model_1.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=valid_data,
                        validation_steps=len(valid_data))
```

    Found 1500 images belonging to 2 classes.
    Found 500 images belonging to 2 classes.
    Epoch 1/5
    47/47 [==============================] - 41s 200ms/step - loss: 0.5977 - accuracy: 0.6667 - val_loss: 0.4103 - val_accuracy: 0.8240
    Epoch 2/5
    47/47 [==============================] - 9s 186ms/step - loss: 0.4253 - accuracy: 0.8147 - val_loss: 0.3645 - val_accuracy: 0.8420
    Epoch 3/5
    47/47 [==============================] - 9s 189ms/step - loss: 0.3926 - accuracy: 0.8327 - val_loss: 0.3142 - val_accuracy: 0.8680
    Epoch 4/5
    47/47 [==============================] - 9s 189ms/step - loss: 0.3635 - accuracy: 0.8473 - val_loss: 0.3409 - val_accuracy: 0.8500
    Epoch 5/5
    47/47 [==============================] - 9s 194ms/step - loss: 0.3058 - accuracy: 0.8740 - val_loss: 0.2852 - val_accuracy: 0.8880


> ğŸ¤” Not: YukarÄ±daki hÃ¼crenin Ã§alÄ±ÅŸmasÄ± epoch baÅŸÄ±na ~12 saniyeden uzun sÃ¼rÃ¼yorsa GPU hÄ±zlandÄ±rÄ±cÄ± kullanmÄ±yor olabilirsiniz. Colab dizÃ¼stÃ¼ bilgisayar kullanÄ±yorsanÄ±z, Ã‡alÄ±ÅŸma ZamanÄ± -> Ã‡alÄ±ÅŸma ZamanÄ± TÃ¼rÃ¼nÃ¼ DeÄŸiÅŸtir -> DonanÄ±m HÄ±zlandÄ±rÄ±cÄ±'ya gidip "GPU"yu seÃ§erek bir GPU hÄ±zlandÄ±rÄ±cÄ±ya eriÅŸebilirsiniz. Bunu yaptÄ±ktan sonra, Ã§alÄ±ÅŸma zamanÄ± tÃ¼rÃ¼nÃ¼ deÄŸiÅŸtirmek Colab'Ä±n sÄ±fÄ±rlanmasÄ±na neden olacaÄŸÄ±ndan yukarÄ±daki hÃ¼crelerin tÃ¼mÃ¼nÃ¼ yeniden Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekebilir.

GÃ¼zel! 5 epoch sonra modelimiz %50,76 doÄŸruluk temel puanÄ±nÄ± geÃ§ti (modelimiz train setinde ~%85 doÄŸruluk ve test setinde ~%85 doÄŸruluk elde etti).

Ancak, modelimiz Food101 veri setindeki 101 sÄ±nÄ±fÄ±n tÃ¼mÃ¼ yerine yalnÄ±zca ikili sÄ±nÄ±flandÄ±rma probleminden geÃ§ti, bu nedenle bu Ã¶lÃ§Ã¼mleri doÄŸrudan karÅŸÄ±laÅŸtÄ±ramÄ±yoruz. Bununla birlikte, ÅŸu ana kadarki sonuÃ§lar modelimizin bir ÅŸeyler Ã¶ÄŸrendiÄŸini gÃ¶steriyor.

> ğŸ›  AlÄ±ÅŸtÄ±rma: YukarÄ±daki hÃ¼credeki ana kod bloklarÄ±nÄ±n her birinin Ã¼zerinden geÃ§in, her birinin ne yaptÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorsunuz? Emin deÄŸilseniz sorun deÄŸil, bunu yakÄ±nda halledeceÄŸiz. Bu arada, [CNN aÃ§Ä±klayÄ±cÄ± web](https://poloclub.github.io/cnn-explainer/) sitesinde 10 dakika oynayarak vakit geÃ§irin. Web sayfasÄ±nÄ±n Ã¼st kÄ±smÄ±ndaki katman adlarÄ± hakkÄ±nda ne fark ediyorsunuz?

HalihazÄ±rda bir modeli fit ettiÄŸimize gÃ¶re, mimarisine bir gÃ¶z atalÄ±m.


```python
model_1.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d (Conv2D)              (None, 222, 222, 10)      280       
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 220, 220, 10)      910       
    _________________________________________________________________
    max_pooling2d (MaxPooling2D) (None, 110, 110, 10)      0         
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 108, 108, 10)      910       
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 106, 106, 10)      910       
    _________________________________________________________________
    max_pooling2d_1 (MaxPooling2 (None, 53, 53, 10)        0         
    _________________________________________________________________
    flatten (Flatten)            (None, 28090)             0         
    _________________________________________________________________
    dense (Dense)                (None, 1)                 28091     
    =================================================================
    Total params: 31,101
    Trainable params: 31,101
    Non-trainable params: 0
    _________________________________________________________________


Model_1 katmanlarÄ±nÄ±n adlarÄ± ve CNN aÃ§Ä±klayÄ±cÄ± web sitesinin en Ã¼stÃ¼ndeki katman adlarÄ± hakkÄ±nda ne fark ediyorsunuz?

Size kÃ¼Ã§Ã¼k bir sÄ±r vereyim: Model demolarÄ± iÃ§in kullandÄ±klarÄ± mimariyi aynen kopyaladÄ±k.

Åimdi burada anlatmadÄ±ÄŸÄ±mÄ±z birkaÃ§ yeni ÅŸey var:
- **ImageDataGenerator** sÄ±nÄ±fÄ± ve yeniden Ã¶lÃ§eklendirme parametresi
- **flow_from_directory()** yÃ¶ntemi
- **batch_size** parametresi
- **target_size** parametresi
- **Conv2D katmanlarÄ±** (ve bunlarla birlikte gelen parametreler)
- **MaxPool2D katmanlarÄ±** (ve parametreleri).
- fit() iÅŸlevindeki **step_per_epoch** ve **validation_steps** parametreleri

BunlarÄ±n her birine derinlemesine iÅŸlemeden Ã¶nce, daha Ã¶nce Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z bir modeli verilerimizle fit etmeye Ã§alÄ±ÅŸÄ±rsak ne olacaÄŸÄ±nÄ± gÃ¶relim.

## Daha Ã–nce OlduÄŸu Gibi AynÄ± Modeli Kullanma

Sinir aÄŸlarÄ±nÄ±n birÃ§ok farklÄ± soruna nasÄ±l uyarlanabileceÄŸini Ã¶rneklemek iÃ§in, daha Ã¶nce oluÅŸturduÄŸumuz bir ikili sÄ±nÄ±flandÄ±rma modelinin verilerimizle nasÄ±l Ã§alÄ±ÅŸabileceÄŸini gÃ¶relim.

Ä°ki ÅŸeyi deÄŸiÅŸtirmek dÄ±ÅŸÄ±nda Ã¶nceki modelimizde aynÄ± parametrelerin hepsini kullanabiliriz:

- **Veriler** <br>
ArtÄ±k noktalar yerine resimlerle Ã§alÄ±ÅŸÄ±yoruz.
- **Input Shape** <br>
Sinir aÄŸÄ±mÄ±za Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gÃ¶rÃ¼ntÃ¼lerin ÅŸeklini sÃ¶ylemeliyiz. <br>
YaygÄ±n bir uygulama, gÃ¶rÃ¼ntÃ¼leri tek bir boyuta yeniden ÅŸekillendirmektir. Bizim durumumuzda, gÃ¶rÃ¼ntÃ¼leri (224, 224, 3) olarak yeniden boyutlandÄ±racaÄŸÄ±z; bu, kÄ±rmÄ±zÄ±, yeÅŸil, mavi renk kanallarÄ± iÃ§in 224 piksel yÃ¼kseklik ve geniÅŸlik ve 3 derinlik anlamÄ±na gelir.


```python
tf.random.set_seed(42)

model_2 = tf.keras.Sequential([
  tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
  tf.keras.layers.Dense(4, activation='relu'),
  tf.keras.layers.Dense(4, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

# modeli derleme
model_2.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

#  modeli fit etme
history_2 = model_2.fit(train_data,
                        # yukarÄ±da oluÅŸturulan eÄŸitim verilerinin aynÄ±sÄ±nÄ± kullanÄ±yoruz
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        # yukarÄ±da oluÅŸturulan aynÄ± doÄŸrulama verilerini kullanÄ±yoruz
                        validation_data=valid_data,
                        validation_steps=len(valid_data))
```

    Epoch 1/5
    47/47 [==============================] - 9s 189ms/step - loss: 1.0323 - accuracy: 0.5027 - val_loss: 0.6932 - val_accuracy: 0.5000
    Epoch 2/5
    47/47 [==============================] - 9s 184ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000
    Epoch 3/5
    47/47 [==============================] - 8s 173ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000
    Epoch 4/5
    47/47 [==============================] - 8s 172ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000
    Epoch 5/5
    47/47 [==============================] - 8s 172ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000


Hmmm... modelimiz Ã§alÄ±ÅŸtÄ± ama hiÃ§bir ÅŸey Ã¶ÄŸrenmiÅŸ gibi gÃ¶rÃ¼nmÃ¼yor.

Mimariyi gÃ¶relim.



```python
model_2.summary()
```

    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    flatten_1 (Flatten)          (None, 150528)            0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 4)                 602116    
    _________________________________________________________________
    dense_2 (Dense)              (None, 4)                 20        
    _________________________________________________________________
    dense_3 (Dense)              (None, 1)                 5         
    =================================================================
    Total params: 602,141
    Trainable params: 602,141
    Non-trainable params: 0
    _________________________________________________________________


Vay. Buradaki en dikkat Ã§ekici ÅŸeylerden biri, model_2'ye kÄ±yasla model_1'deki Ã§ok daha fazla parametre sayÄ±sÄ±dÄ±r.

model_2, 602.141 eÄŸitilebilir parametreye sahipken, model_1 yalnÄ±zca 31.101'e sahiptir. Ve bu farklÄ±lÄ±ÄŸa raÄŸmen, model_1 hala model_2'ye gÃ¶re daha performanslÄ± sonuÃ§ Ã¼retir.

> ğŸ”‘ Not: EÄŸitilebilir parametreleri, bir modelin verilerden Ã¶ÄŸrenebileceÄŸi kalÄ±plar olarak dÃ¼ÅŸÃ¼nebilirsiniz. Sezgisel olarak, daha fazlasÄ±nÄ±n daha iyi olduÄŸunu dÃ¼ÅŸÃ¼nebilirsiniz. Ve bazÄ± durumlarda Ã¶yle. Ancak bu durumda, buradaki fark, kullandÄ±ÄŸÄ±mÄ±z iki farklÄ± model stilindedir. Bir dizi yoÄŸun katman birbirine baÄŸlÄ± bir dizi farklÄ± Ã¶ÄŸrenilebilir parametreye ve dolayÄ±sÄ±yla daha fazla sayÄ±da olasÄ± Ã¶ÄŸrenilebilir Ã¶rÃ¼ntÃ¼ye sahip olduÄŸunda, evriÅŸimli bir sinir aÄŸÄ± bir gÃ¶rÃ¼ntÃ¼deki en Ã¶nemli Ã¶rÃ¼ntÃ¼leri ayÄ±rmaya ve Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r. DolayÄ±sÄ±yla, evriÅŸimli sinir aÄŸÄ±mÄ±zda daha az Ã¶ÄŸrenilebilir parametreler olsa da, bunlar genellikle bir gÃ¶rÃ¼ntÃ¼deki farklÄ± Ã¶zellikler arasÄ±nda ÅŸifre Ã§Ã¶zmede daha faydalÄ±dÄ±r.

Ã–nceki modelimiz Ã§alÄ±ÅŸmadÄ±ÄŸÄ±na gÃ¶re, onu nasÄ±l Ã§alÄ±ÅŸtÄ±rabileceÄŸimize dair bir fikriniz var mÄ±? Katman sayÄ±sÄ±nÄ± artÄ±rmaya ne dersiniz? Ve belki de her katmandaki nÃ¶ron sayÄ±sÄ±nÄ± artÄ±rabilir mi?

Daha spesifik olarak, her yoÄŸun katmandaki nÃ¶ron sayÄ±sÄ±nÄ± (gizli birimler olarak da adlandÄ±rÄ±lÄ±r) 4'ten 100'e Ã§Ä±karacaÄŸÄ±z ve fazladan bir katman ekleyeceÄŸiz.

ğŸ”‘ Not: Fazladan katman eklemek veya her katmandaki nÃ¶ron sayÄ±sÄ±nÄ± artÄ±rmak, genellikle modelinizin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± artÄ±rmak olarak adlandÄ±rÄ±lÄ±r.


```python
tf.random.set_seed(42)

# model yaratma
model_3 = tf.keras.Sequential([
  tf.keras.layers.Flatten(input_shape=(224, 224, 3)),
  tf.keras.layers.Dense(100, activation='relu'),# nÃ¶ron sayÄ±sÄ±nÄ± 4'ten 100'e Ã§Ä±karÄ±yoruz (her katman iÃ§in)
  tf.keras.layers.Dense(100, activation='relu'),
  tf.keras.layers.Dense(100, activation='relu'), # ekstradan bir katman ekliyoruz
  tf.keras.layers.Dense(1, activation='sigmoid')
])

# modeli derleme
model_3.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

#  modeli fit etme
history_3 = model_3.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=valid_data,
                        validation_steps=len(valid_data))
```

    Epoch 1/5
    47/47 [==============================] - 9s 176ms/step - loss: 4.9315 - accuracy: 0.6160 - val_loss: 0.5567 - val_accuracy: 0.7120
    Epoch 2/5
    47/47 [==============================] - 8s 171ms/step - loss: 0.7969 - accuracy: 0.6973 - val_loss: 0.5401 - val_accuracy: 0.7260
    Epoch 3/5
    47/47 [==============================] - 9s 183ms/step - loss: 0.6629 - accuracy: 0.7220 - val_loss: 0.4935 - val_accuracy: 0.7840
    Epoch 4/5
    47/47 [==============================] - 9s 185ms/step - loss: 0.5487 - accuracy: 0.7660 - val_loss: 0.4388 - val_accuracy: 0.7760
    Epoch 5/5
    47/47 [==============================] - 9s 184ms/step - loss: 0.4576 - accuracy: 0.7947 - val_loss: 0.4313 - val_accuracy: 0.7920


Vay! GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz yeniden Ã¶ÄŸreniyor. EÄŸitim setinde ~%70 doÄŸruluk ve doÄŸrulama setinde ~%70 doÄŸruluk elde etti.

Mimari nasÄ±l gÃ¶rÃ¼nÃ¼yor?


```python
model_3.summary()
```

    Model: "sequential_2"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    flatten_2 (Flatten)          (None, 150528)            0         
    _________________________________________________________________
    dense_4 (Dense)              (None, 100)               15052900  
    _________________________________________________________________
    dense_5 (Dense)              (None, 100)               10100     
    _________________________________________________________________
    dense_6 (Dense)              (None, 100)               10100     
    _________________________________________________________________
    dense_7 (Dense)              (None, 1)                 101       
    =================================================================
    Total params: 15,073,201
    Trainable params: 15,073,201
    Non-trainable params: 0
    _________________________________________________________________


EÄŸitilebilir parametrelerin sayÄ±sÄ± model_2'den bile daha fazla arttÄ±. Ve 500 kata yakÄ±n (~15.000.000 vs. ~31.000) daha fazla eÄŸitilebilir parametreyle bile, model_3 hala model_1'i geÃ§emiyor.

Bu, evriÅŸimli sinir aÄŸlarÄ±nÄ±n gÃ¼cÃ¼nÃ¼ ve daha az parametre kullanmasÄ±na raÄŸmen kalÄ±plarÄ± Ã¶ÄŸrenme yeteneklerini gÃ¶steriyor.

## Ä°kili sÄ±nÄ±flandÄ±rma: Modelde Derinlemesine Ã‡alÄ±ÅŸalÄ±m

1. Verilerle bÃ¼tÃ¼nleÅŸin (gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin...)
2. Verileri Ã¶nceden iÅŸleyin (bir model iÃ§in hazÄ±rlayÄ±n)
3. Bir model oluÅŸturun (bir temel ile baÅŸlayÄ±n)
4. Modeli fit edin
5. Modeli deÄŸerlendirin
6. FarklÄ± parametreleri ayarlayÄ±n ve modeli iyileÅŸtirin (temel Ã§izginizi geÃ§meye Ã§alÄ±ÅŸÄ±n)
7. Memnun kalana kadar tekrarlayÄ±n

Her birinin Ã¼zerinden geÃ§elim.

### 1.Verileri Ä°Ã§e AktarÄ±n ve Verilerle BÃ¼tÃ¼nleÅŸin

Ne tÃ¼r bir veriyle uÄŸraÅŸÄ±rsanÄ±z uÄŸraÅŸÄ±n, kendi zihinsel veri modelinizi oluÅŸturmaya baÅŸlamak iÃ§in en az 10-100 Ã¶rneÄŸi gÃ¶rselleÅŸtirmek iyi bir fikirdir.

Bizim durumumuzda, biftek gÃ¶rÃ¼ntÃ¼lerinin daha koyu renklere sahip olma eÄŸiliminde olduÄŸunu, pizza gÃ¶rÃ¼ntÃ¼lerinin ise ortada belirgin bir dairesel ÅŸekle sahip olma eÄŸiliminde olduÄŸunu fark edebiliriz. Bunlar, sinir aÄŸÄ±mÄ±zÄ±n yakaladÄ±ÄŸÄ± kalÄ±plar olabilir.

AyrÄ±ca, bazÄ± verilerinizin bozuk olup olmadÄ±ÄŸÄ±nÄ± (Ã¶rneÄŸin, yanlÄ±ÅŸ etikete sahip olup olmadÄ±ÄŸÄ±nÄ±) fark eder ve bunlarÄ± dÃ¼zeltmek iÃ§in izleyebileceÄŸiniz yollarÄ± dÃ¼ÅŸÃ¼nmeye baÅŸlarsÄ±nÄ±z.


```python
plt.figure()
plt.subplot(1, 2, 1)
steak_img = view_random_image("pizza_steak/train/", "steak")
plt.subplot(1, 2, 2)
pizza_img = view_random_image("pizza_steak/train/", "pizza")
```

    Image shape: (384, 512, 3)
    Image shape: (512, 512, 3)



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_40_1.png)
    


### 2.Verileri Ã–nceden Ä°ÅŸleyin

Bir makine Ã¶ÄŸrenimi projesi iÃ§in en Ã¶nemli adÄ±mlardan biri eÄŸitim ve test seti oluÅŸturmaktÄ±r.

Bizim durumumuzda, verilerimiz zaten eÄŸitim ve test setlerine bÃ¶lÃ¼nmÃ¼ÅŸtÃ¼r. Buradaki baÅŸka bir seÃ§enek de bir doÄŸrulama seti oluÅŸturmak olabilir, ancak ÅŸimdilik bunu bÄ±rakacaÄŸÄ±z.

Bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma projesi iÃ§in, verilerinizin her sÄ±nÄ±f iÃ§in her birinde alt klasÃ¶rler bulunan train ve test dizinlerine ayrÄ±lmasÄ± standarttÄ±r.

BaÅŸlamak iÃ§in eÄŸitim ve test dizini yollarÄ±nÄ± tanÄ±mlÄ±yoruz.


```python
train_dir = "pizza_steak/train/"
test_dir = "pizza_steak/test/"
```

Bir sonraki adÄ±mÄ±mÄ±z, verilerimizi yÄ±ÄŸÄ±nlara dÃ¶nÃ¼ÅŸtÃ¼rmektir.

Toplu iÅŸ, bir modelin eÄŸitim sÄ±rasÄ±nda baktÄ±ÄŸÄ± veri kÃ¼mesinin kÃ¼Ã§Ã¼k bir alt kÃ¼mesidir. Ã–rneÄŸin, bir seferde 10.000 gÃ¶rÃ¼ntÃ¼ye bakmak ve kalÄ±plarÄ± anlamaya Ã§alÄ±ÅŸmak yerine, bir model bir seferde yalnÄ±zca 32 gÃ¶rÃ¼ntÃ¼ye bakabilir.

Bunu birkaÃ§ nedenden dolayÄ± yapar:

- 10.000 gÃ¶rÃ¼ntÃ¼ (veya daha fazla) iÅŸlemcinizin (GPU) belleÄŸine sÄ±ÄŸmayabilir.
- 10.000 gÃ¶rÃ¼ntÃ¼deki kalÄ±plarÄ± tek bir vuruÅŸta Ã¶ÄŸrenmeye Ã§alÄ±ÅŸmak, modelin Ã§ok iyi Ã¶ÄŸrenememesine neden olabilir.

Neden 32?

32'lik bir epoch bÃ¼yÃ¼klÃ¼ÄŸÃ¼ saÄŸlÄ±ÄŸÄ±nÄ±z iÃ§in iyidir.

HayÄ±r, gerÃ§ekten, kullanabileceÄŸiniz birÃ§ok farklÄ± parti boyutu vardÄ±r, ancak 32'nin birÃ§ok farklÄ± kullanÄ±m durumunda Ã§ok etkili olduÄŸu kanÄ±tlanmÄ±ÅŸtÄ±r ve Ã§oÄŸu zaman birÃ§ok veri Ã¶n iÅŸleme iÅŸlevi iÃ§in varsayÄ±landÄ±r.

Verilerimizi toplu iÅŸlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in Ã¶nce veri kÃ¼melerimizin her biri iÃ§in bir ImageDataGenerator Ã¶rneÄŸi oluÅŸturacaÄŸÄ±z.


```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)
```

ImageDataGenerator sÄ±nÄ±fÄ±, gÃ¶rÃ¼ntÃ¼lerimizi yÄ±ÄŸÄ±nlar halinde hazÄ±rlamamÄ±za ve modele yÃ¼klenirken Ã¼zerlerinde dÃ¶nÃ¼ÅŸÃ¼mler gerÃ§ekleÅŸtirmemize yardÄ±mcÄ± olur.

Yeniden Ã¶lÃ§eklendirme parametresini fark etmiÅŸ olabilirsiniz. Bu, yaptÄ±ÄŸÄ±mÄ±z dÃ¶nÃ¼ÅŸÃ¼mlerin bir Ã¶rneÄŸidir.

Daha Ã¶nce bir gÃ¶rÃ¼ntÃ¼yÃ¼ nasÄ±l iÃ§e aktardÄ±ÄŸÄ±mÄ±zÄ± ve piksel deÄŸerlerinin 0 ile 255 arasÄ±nda olduÄŸunu hatÄ±rlÄ±yor musunuz?

1/255 ile birlikte yeniden Ã¶lÃ§eklendirme parametresi. "tÃ¼m piksel deÄŸerlerini 255'e bÃ¶l" demek gibidir. Bu, tÃ¼m gÃ¶rÃ¼ntÃ¼nÃ¼n iÃ§e aktarÄ±lmasÄ±yla ve piksel deÄŸerlerinin normalleÅŸtirilmesiyle sonuÃ§lanÄ±r (0 ile 1 arasÄ±nda dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r).

> ğŸ”‘ Not: Veri bÃ¼yÃ¼tme ve daha fazla dÃ¶nÃ¼ÅŸtÃ¼rme seÃ§eneÄŸi iÃ§in (bunu daha sonra gÃ¶receÄŸiz), [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) belgelerine bakÄ±n.

Åimdi birkaÃ§ ImageDataGenerator Ã¶rneÄŸimiz var, gÃ¶rÃ¼ntÃ¼lerimizi flow_from_directory yÃ¶ntemini kullanarak ilgili dizinlerinden yÃ¼kleyebiliriz.


```python
train_data = train_datagen.flow_from_directory(directory=train_dir,
                                               target_size=(224, 224),
                                               class_mode='binary',
                                               batch_size=32)

test_data = test_datagen.flow_from_directory(directory=test_dir,
                                             target_size=(224, 224),
                                             class_mode='binary',
                                             batch_size=32)
```

    Found 1500 images belonging to 2 classes.
    Found 500 images belonging to 2 classes.


OlaÄŸanÃ¼stÃ¼! GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re eÄŸitim veri setimizde 2 sÄ±nÄ±fa (pizza ve steak) ait 1500 gÃ¶rÃ¼ntÃ¼ var ve test veri setimizde 2 sÄ±nÄ±fa ait 500 gÃ¶rÃ¼ntÃ¼ var.

Buraya bazÄ± ÅŸeyler:

- Dizinlerimizin nasÄ±l yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±na baÄŸlÄ± olarak, sÄ±nÄ±flar, `train_dir` ve `test_dir` iÃ§indeki alt dizin adlarÄ±ndan anlaÅŸÄ±lÄ±r.
- `target_size` parametresi, resimlerimizin giriÅŸ boyutunu (yÃ¼kseklik, geniÅŸlik) biÃ§iminde tanÄ±mlar.
- `'binary'`nin class_mode deÄŸeri, sÄ±nÄ±flandÄ±rma problem tÃ¼rÃ¼mÃ¼zÃ¼ tanÄ±mlar. Ä°kiden fazla sÄ±nÄ±fÄ±mÄ±z olsaydÄ±, `'categorical'` kullanÄ±rdÄ±k.
- `batch_size`, her toplu iÅŸte kaÃ§ tane resim olacaÄŸÄ±nÄ± tanÄ±mlar, biz varsayÄ±lanla aynÄ± olan 32'yi kullandÄ±k.

Train_data nesnesini inceleyerek toplu resimlerimize ve etiketlerimize gÃ¶z atabiliriz.


```python
images, labels = train_data.next()
len(images), len(labels)
```




    (32, 32)



Harika, gÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re resimlerimiz ve etiketlerimiz 32'lik gruplar halinde.

BakalÄ±m resimler nasÄ±l gÃ¶rÃ¼nÃ¼yor.


```python
images[:2], images[0].shape
```




    (array([[[[0.47058827, 0.40784317, 0.34509805],
              [0.4784314 , 0.427451  , 0.3647059 ],
              [0.48627454, 0.43529415, 0.37254903],
              ...,
              [0.8313726 , 0.70980394, 0.48627454],
              [0.8431373 , 0.73333335, 0.5372549 ],
              [0.87843144, 0.7725491 , 0.5882353 ]],
     
             [[0.50980395, 0.427451  , 0.36078432],
              [0.5058824 , 0.42352945, 0.35686275],
              [0.5137255 , 0.4431373 , 0.3647059 ],
              ...,
              [0.82745105, 0.7058824 , 0.48235297],
              [0.82745105, 0.70980394, 0.5058824 ],
              [0.8431373 , 0.73333335, 0.5372549 ]],
     
             [[0.5254902 , 0.427451  , 0.34901962],
              [0.5372549 , 0.43921572, 0.36078432],
              [0.5372549 , 0.45098042, 0.36078432],
              ...,
              [0.82745105, 0.7019608 , 0.4784314 ],
              [0.82745105, 0.7058824 , 0.49411768],
              [0.8352942 , 0.7176471 , 0.5137255 ]],
     
             ...,
     
             [[0.77647066, 0.5647059 , 0.2901961 ],
              [0.7803922 , 0.53333336, 0.22352943],
              [0.79215693, 0.5176471 , 0.18039216],
              ...,
              [0.30588236, 0.2784314 , 0.24705884],
              [0.24705884, 0.23137257, 0.19607845],
              [0.2784314 , 0.27450982, 0.25490198]],
     
             [[0.7843138 , 0.57254905, 0.29803923],
              [0.79215693, 0.54509807, 0.24313727],
              [0.8000001 , 0.5254902 , 0.18823531],
              ...,
              [0.2627451 , 0.23529413, 0.20392159],
              [0.24313727, 0.227451  , 0.19215688],
              [0.26666668, 0.2627451 , 0.24313727]],
     
             [[0.7960785 , 0.59607846, 0.3372549 ],
              [0.7960785 , 0.5647059 , 0.26666668],
              [0.81568635, 0.54901963, 0.22352943],
              ...,
              [0.23529413, 0.19607845, 0.16078432],
              [0.3019608 , 0.26666668, 0.24705884],
              [0.26666668, 0.2509804 , 0.24705884]]],
     
     
            [[[0.38823533, 0.4666667 , 0.36078432],
              [0.3921569 , 0.46274513, 0.36078432],
              [0.38431376, 0.454902  , 0.36078432],
              ...,
              [0.5294118 , 0.627451  , 0.54509807],
              [0.5294118 , 0.627451  , 0.54509807],
              [0.5411765 , 0.6392157 , 0.5568628 ]],
     
             [[0.38431376, 0.454902  , 0.3529412 ],
              [0.3921569 , 0.46274513, 0.36078432],
              [0.39607847, 0.4666667 , 0.37254903],
              ...,
              [0.54509807, 0.6431373 , 0.5686275 ],
              [0.5529412 , 0.6509804 , 0.5764706 ],
              [0.5647059 , 0.6627451 , 0.5882353 ]],
     
             [[0.3921569 , 0.46274513, 0.36078432],
              [0.38431376, 0.454902  , 0.3529412 ],
              [0.4039216 , 0.47450984, 0.3803922 ],
              ...,
              [0.5764706 , 0.67058825, 0.6156863 ],
              [0.5647059 , 0.6666667 , 0.6156863 ],
              [0.5647059 , 0.6666667 , 0.6156863 ]],
     
             ...,
     
             [[0.47058827, 0.5647059 , 0.4784314 ],
              [0.4784314 , 0.5764706 , 0.4901961 ],
              [0.48235297, 0.5803922 , 0.49803925],
              ...,
              [0.39607847, 0.42352945, 0.3019608 ],
              [0.37647063, 0.40000004, 0.2901961 ],
              [0.3803922 , 0.4039216 , 0.3019608 ]],
     
             [[0.45098042, 0.5529412 , 0.454902  ],
              [0.46274513, 0.5647059 , 0.4666667 ],
              [0.47058827, 0.57254905, 0.47450984],
              ...,
              [0.40784317, 0.43529415, 0.3137255 ],
              [0.39607847, 0.41960788, 0.31764707],
              [0.38823533, 0.40784317, 0.31764707]],
     
             [[0.47450984, 0.5764706 , 0.47058827],
              [0.47058827, 0.57254905, 0.4666667 ],
              [0.46274513, 0.5647059 , 0.4666667 ],
              ...,
              [0.4039216 , 0.427451  , 0.31764707],
              [0.3921569 , 0.4156863 , 0.3137255 ],
              [0.4039216 , 0.42352945, 0.3372549 ]]]], dtype=float32),
     (224, 224, 3))



Yeniden Ã¶lÃ§eklendirme parametremiz nedeniyle, gÃ¶rÃ¼ntÃ¼ler artÄ±k 0 ile 1 arasÄ±nda deÄŸerlere sahip (224, 224, 3) ÅŸekil tensÃ¶rlerindedir.

Peki ya etiketler?



```python
labels
```




    array([1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,
           1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.],
          dtype=float32)



`class_mode` parametresinin `'binary'` olmasÄ± nedeniyle etiketlerimiz 0 (pizza) veya 1 (biftek) ÅŸeklindedir.

ArtÄ±k verilerimiz hazÄ±r olduÄŸuna gÃ¶re, modelimiz gÃ¶rÃ¼ntÃ¼ tensÃ¶rleri ve etiketler arasÄ±ndaki kalÄ±plarÄ± bulmaya Ã§alÄ±ÅŸacak.

### 3.Bir Model OluÅŸturun

VarsayÄ±lan model mimarinizin ne olmasÄ± gerektiÄŸini merak ediyor olabilirsiniz.

Ve gerÃ§ek ÅŸu ki, bu sorunun birÃ§ok olasÄ± cevabÄ± var.

BilgisayarlÄ± gÃ¶rme modelleri iÃ§in basit bir buluÅŸsal yÃ¶ntem, ImageNet'te en iyi performansÄ± gÃ¶steren model mimarisini kullanmaktÄ±r (farklÄ± bilgisayarlÄ± gÃ¶rme modellerini kÄ±yaslamak iÃ§in Ã§eÅŸitli gÃ¶rÃ¼ntÃ¼lerden oluÅŸan geniÅŸ bir koleksiyon).

Bununla birlikte, baÅŸlangÄ±Ã§ â€‹â€‹olarak, geliÅŸtirmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z temel bir sonuÃ§ elde etmek iÃ§in daha kÃ¼Ã§Ã¼k bir model oluÅŸturmak iyidir.

> ğŸ”‘ Not: Derin Ã¶ÄŸrenmede daha kÃ¼Ã§Ã¼k bir model genellikle son teknolojiden (SOTA) daha az katmana sahip bir modele atÄ±fta bulunur. Ã–rneÄŸin, daha kÃ¼Ã§Ã¼k bir model 3-4 katmana sahip olabilirken, ResNet50 gibi son teknoloji bir model 50'den fazla katmana sahip olabilir.

Bizim durumumuzda, [CNN aÃ§Ä±klayÄ±cÄ± web sitesinde](https://poloclub.github.io/cnn-explainer/) (yukarÄ±dan model_1) bulunabilecek modelin daha kÃ¼Ã§Ã¼k bir versiyonunu alalÄ±m ve 3 katmanlÄ± bir evriÅŸimli sinir aÄŸÄ± oluÅŸturalÄ±m.


```python
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation
from tensorflow.keras import Sequential
```


```python
# Bir model oluÅŸturma
model_4 = Sequential([
  Conv2D(filters=10, 
         kernel_size=3, 
         strides=1,
         padding='valid',
         activation='relu', 
         input_shape=(224, 224, 3)), # input layer 
  Conv2D(10, 3, activation='relu'),
  Conv2D(10, 3, activation='relu'),
  Flatten(),
  Dense(1, activation='sigmoid') # output layer
])
```

Harika! KullanÄ±ma hazÄ±r basit bir evriÅŸimsel sinir aÄŸÄ± mimarimiz var. Tipik model yapÄ±sÄ±nÄ± benzer:
```
# Basic structure of CNN
Input -> Conv + ReLU layers (non-linearities) -> Pooling layer -> Fully connected (dense layer) as Output
```

Conv2D katmanÄ±nÄ±n bazÄ± bileÅŸenlerini tartÄ±ÅŸalÄ±m:

- **"Conv2D"** <br>
Girdilerimizin iki boyutlu (yÃ¼kseklik ve geniÅŸlik) olduÄŸu anlamÄ±na gelir, 3 renk kanalÄ± olmasÄ±na raÄŸmen, kÄ±vrÄ±mlar her kanalda ayrÄ± ayrÄ± Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
- **filters**<br> 
Bunlar, resimlerimiz Ã¼zerinde hareket edecek olan "Ã¶zellik Ã§Ä±karÄ±cÄ±larÄ±n" sayÄ±sÄ±dÄ±r.
- **kernel_size**<br> 
Filtrelerimizin boyutu, Ã¶rneÄŸin bir kernel_size (3, 3) (veya sadece 3), her filtrenin 3x3 boyutuna sahip olacaÄŸÄ±, yani her seferinde 3x3 piksellik bir alana bakacaÄŸÄ± anlamÄ±na gelir. Ã‡ekirdek ne kadar kÃ¼Ã§Ã¼kse, o kadar ince taneli Ã¶zellikler Ã§Ä±karacaktÄ±r.
- **stride**<br> 
Bir filtrenin gÃ¶rÃ¼ntÃ¼yÃ¼ kaplarken Ã¼zerinde hareket edeceÄŸi piksel sayÄ±sÄ±. 1'lik bir adÄ±m, filtrenin her piksel boyunca 1'er 1 hareket ettiÄŸi anlamÄ±na gelir. 2'lik bir adÄ±m, bir seferde 2 piksel hareket ettiÄŸi anlamÄ±na gelir.
- **padding**<br> 
Bu 'same' veya 'valid' olabilir, 'same' gÃ¶rÃ¼ntÃ¼nÃ¼n dÄ±ÅŸÄ±na sÄ±fÄ±rlar ekler, bÃ¶ylece evriÅŸim katmanÄ±nÄ±n sonuÃ§taki Ã§Ä±ktÄ±sÄ± giriÅŸle aynÄ±dÄ±r, burada 'valid' (varsayÄ±lan) keser filtrenin sÄ±ÄŸmadÄ±ÄŸÄ± fazla piksel (Ã¶rneÄŸin, 224 piksel geniÅŸliÄŸinin 3'lÃ¼k bir Ã§ekirdek boyutuna bÃ¶lÃ¼nmesi (224/3 = 74.6)), tek bir pikselin uÃ§tan kesileceÄŸi anlamÄ±na gelir.

**"feature" nedir?**

Bir Ã¶zellik, bir gÃ¶rÃ¼ntÃ¼nÃ¼n Ã¶nemli herhangi bir parÃ§asÄ± olarak kabul edilebilir. Ã–rneÄŸin, bizim durumumuzda bir Ã¶zellik pizzanÄ±n dairesel ÅŸekli olabilir. Veya bir bifteÄŸin dÄ±ÅŸ tarafÄ±ndaki pÃ¼rÃ¼zlÃ¼ kenarlar.

Bu Ã¶zelliklerin bizim tarafÄ±mÄ±zdan tanÄ±mlanmadÄ±ÄŸÄ±nÄ±, bunun yerine modelin gÃ¶rÃ¼ntÃ¼ Ã¼zerinde farklÄ± filtreler uyguladÄ±ÄŸÄ± iÃ§in bunlarÄ± Ã¶ÄŸrendiÄŸini belirtmek Ã¶nemlidir.

ArtÄ±k modelimiz hazÄ±r, derleyelim.


```python
model_4.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])
```

Ä°kili bir sÄ±nÄ±flandÄ±rma problemi (pizza vs. biftek) Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, kullandÄ±ÄŸÄ±mÄ±z kayÄ±p fonksiyonu 'binary_crossentropy'dir, eÄŸer Ã§ok sÄ±nÄ±flÄ±ysa, 'categorical_crossentropy' gibi bir ÅŸey kullanabiliriz.

TÃ¼m varsayÄ±lan ayarlarla Adam, optimize edicimizdir ve deÄŸerlendirme metriÄŸimiz accuracy'dir.

### 4.Modeli Fit Edin

Modelimiz derlendi, fit etme zamanÄ±. Burada iki yeni parametre fark edeceksiniz:

- **step_per_epoch**<br>
Bu, bir modelin epoch baÅŸÄ±na geÃ§eceÄŸi batch sayÄ±sÄ±dÄ±r, bizim durumumuzda, modelimizin tÃ¼m batchi geÃ§mesini istiyoruz, bÃ¶ylece train_data uzunluÄŸuna eÅŸittir (32'lik gruplar halinde 1500 gÃ¶rÃ¼ntÃ¼ = 1500/32 = ~ 47 adÄ±m)
- **validation_steps**<br>
Validation_data parametresi dÄ±ÅŸÄ±nda yukarÄ±dakiyle aynÄ± (32 = 500/32 = ~16 adÄ±mlÄ±k gruplar halinde 500 test gÃ¶rÃ¼ntÃ¼sÃ¼)


```python
# train ve test verilerinin uzunluklarÄ±nÄ± gÃ¶rÃ¼ntÃ¼leme
print("train_data len: ", len(train_data))
print("test_data len : ", len(test_data))

# modeli fit etme
history_4 = model_4.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))
```

    train_data len:  47
    test_data len :  16
    Epoch 1/5
    47/47 [==============================] - 10s 203ms/step - loss: 1.4260 - accuracy: 0.6487 - val_loss: 0.4715 - val_accuracy: 0.7740
    Epoch 2/5
    47/47 [==============================] - 10s 203ms/step - loss: 0.4645 - accuracy: 0.7880 - val_loss: 0.4084 - val_accuracy: 0.8200
    Epoch 3/5
    47/47 [==============================] - 10s 204ms/step - loss: 0.3711 - accuracy: 0.8480 - val_loss: 0.4260 - val_accuracy: 0.8040
    Epoch 4/5
    47/47 [==============================] - 9s 199ms/step - loss: 0.2413 - accuracy: 0.9180 - val_loss: 0.4248 - val_accuracy: 0.8140
    Epoch 5/5
    47/47 [==============================] - 9s 191ms/step - loss: 0.1162 - accuracy: 0.9660 - val_loss: 0.5601 - val_accuracy: 0.7780


### 5.Modeli DeÄŸerlendirin

Ah evet! GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz bir ÅŸeyler Ã¶ÄŸreniyor. EÄŸitim eÄŸrilerini kontrol edelim.


```python
import pandas as pd
pd.DataFrame(history_4.history).plot(figsize=(10, 7));
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_63_0.png)
    


Hmm, kayÄ±p eÄŸrilerimize bakÄ±lÄ±rsa, modelimiz eÄŸitim veri setine fazla uyuyor gibi gÃ¶rÃ¼nÃ¼yor.

> ğŸ”‘ Not: Bir modelin doÄŸrulama kaybÄ± artmaya baÅŸladÄ±ÄŸÄ±nda, bÃ¼yÃ¼k olasÄ±lÄ±kla eÄŸitim veri kÃ¼mesine gereÄŸinden fazla uyuyordur (overfitting). Bu, eÄŸitim veri setindeki kalÄ±plarÄ± Ã§ok iyi Ã¶ÄŸrendiÄŸi ve bÃ¶ylece gÃ¶rÃ¼nmeyen verilere genelleme yapma yeteneÄŸinin azalacaÄŸÄ± anlamÄ±na gelir.

Modelimizin eÄŸitim performansÄ±nÄ± daha fazla incelemek iÃ§in doÄŸruluk ve kayÄ±p eÄŸrilerini ayÄ±ralÄ±m.


```python
# DoÄŸrulama ve eÄŸitim verilerini ayrÄ± ayrÄ± Ã§izme
def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  """ 
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']

  epochs = range(len(history.history['loss']))

  # loss (kayÄ±p) eÄŸriler
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # accuracy(doÄŸruluk) eÄŸrileri
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();

plot_loss_curves(history_4)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_65_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_65_1.png)
    


Bu iki eÄŸri iÃ§in ideal pozisyon birbirini takip etmektir. Herhangi bir ÅŸey varsa, doÄŸrulama eÄŸrisi eÄŸitim eÄŸrisinin biraz altÄ±nda olmalÄ±dÄ±r. EÄŸitim eÄŸrisi ile doÄŸrulama eÄŸrisi arasÄ±nda bÃ¼yÃ¼k bir boÅŸluk varsa, modeliniz muhtemelen fazla uyuyor demektir.


```python
model_4.summary()
```

    Model: "sequential_3"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_4 (Conv2D)            (None, 222, 222, 10)      280       
    _________________________________________________________________
    conv2d_5 (Conv2D)            (None, 220, 220, 10)      910       
    _________________________________________________________________
    conv2d_6 (Conv2D)            (None, 218, 218, 10)      910       
    _________________________________________________________________
    flatten_3 (Flatten)          (None, 475240)            0         
    _________________________________________________________________
    dense_8 (Dense)              (None, 1)                 475241    
    =================================================================
    Total params: 477,341
    Trainable params: 477,341
    Non-trainable params: 0
    _________________________________________________________________


### 6.Model Parametrelerini AyarlayÄ±n

Bir makine Ã¶ÄŸrenimi modelinin takÄ±lmasÄ± 3 adÄ±mda gerÃ§ekleÅŸir:

0. Bir temel oluÅŸturun.
1. Daha bÃ¼yÃ¼k bir modele overfitting taban Ã§izgisini geÃ§in.
2. overfitting azaltÄ±n.

Åimdiye kadar 0 ve 1 adÄ±mlarÄ±ndan geÃ§tik.

Ve modelimize daha fazla uydurmaya Ã§alÄ±ÅŸabileceÄŸimiz birkaÃ§ ÅŸey daha var:

- EvriÅŸim katmanlarÄ±nÄ±n sayÄ±sÄ±nÄ± artÄ±rÄ±n.
- EvriÅŸimli filtrelerin sayÄ±sÄ±nÄ± artÄ±rÄ±n.
- DÃ¼zleÅŸtirilmiÅŸ katmanÄ±mÄ±zÄ±n Ã§Ä±ktÄ±sÄ±na baÅŸka bir yoÄŸun katman ekleyin.

Ama bunun yerine yapacaÄŸÄ±mÄ±z ÅŸey, modelimizin eÄŸitim eÄŸrilerini birbiriyle daha iyi hizalamaya odaklanmak, baÅŸka bir deyiÅŸle 2. adÄ±mÄ± atacaÄŸÄ±z.


**Overfitting'i azaltmak neden Ã¶nemlidir?**

Bir model, eÄŸitim verileri Ã¼zerinde Ã§ok iyi ve gÃ¶rÃ¼nmeyen veriler Ã¼zerinde zayÄ±f performans gÃ¶sterdiÄŸinde, onu gerÃ§ek dÃ¼nyada kullanmak istiyorsak, bize pek faydasÄ± olmaz.

Diyelim ki bir pizza ve biftek yemek sÄ±nÄ±flandÄ±rÄ±cÄ± uygulamasÄ± oluÅŸturuyorduk ve modelimiz eÄŸitim verilerimiz Ã¼zerinde Ã§ok iyi performans gÃ¶steriyor ancak kullanÄ±cÄ±lar bunu denediÄŸinde kendi yemek gÃ¶rÃ¼ntÃ¼lerinde Ã§ok iyi sonuÃ§lar alamadÄ±lar, bu iyi bir deneyim mi?

Tam olarak deÄŸil...

DolayÄ±sÄ±yla, inÅŸa edeceÄŸimiz sonraki birkaÃ§ model iÃ§in bir dizi parametreyi ayarlayacaÄŸÄ±z ve yol boyunca eÄŸitim eÄŸrilerini inceleyeceÄŸiz.

Yani, 2 model daha inÅŸa edeceÄŸiz:

- Maksimum pooling'e sahip bir ConvNet
- Maksimum pooling'e ve veri artÄ±rma Ã¶zelliÄŸine sahip bir ConvNet

Ä°lk model iÃ§in bu yapÄ±yÄ± takip edeceÄŸiz:
```
Input -> Conv layers + ReLU layers (non-linearities) + Max Pooling layers -> Fully connected (dense layer) as Output
```
Hadi inÅŸa edelim. model_4 ile aynÄ± yapÄ±ya sahip olacak, ancak her evriÅŸim katmanÄ±ndan sonra bir MaxPool2D() katmanÄ± olacak.


```python
model_5 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(pool_size=2),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])
```

Vayy, daha Ã¶nce gÃ¶rmediÄŸimiz baÅŸka bir katman tipimiz var.

EvriÅŸimli katmanlar bir gÃ¶rÃ¼ntÃ¼nÃ¼n Ã¶zelliklerini Ã¶ÄŸrenirse, bu Ã¶zelliklerden en Ã¶nemlilerini bulmak olarak bir Max Pooling katmanÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz. Bunun bir Ã¶rneÄŸini birazdan gÃ¶receÄŸiz.



```python
# modeli derleme (model_4 gibi)
model_5.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

# modeli fit etme
history_5 = model_5.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))
```

    Epoch 1/5
    47/47 [==============================] - 9s 182ms/step - loss: 0.5979 - accuracy: 0.7020 - val_loss: 0.4990 - val_accuracy: 0.7500
    Epoch 2/5
    47/47 [==============================] - 8s 179ms/step - loss: 0.4841 - accuracy: 0.7800 - val_loss: 0.4151 - val_accuracy: 0.8040
    Epoch 3/5
    47/47 [==============================] - 8s 179ms/step - loss: 0.4310 - accuracy: 0.8147 - val_loss: 0.3557 - val_accuracy: 0.8560
    Epoch 4/5
    47/47 [==============================] - 9s 190ms/step - loss: 0.4023 - accuracy: 0.8233 - val_loss: 0.3635 - val_accuracy: 0.8360
    Epoch 5/5
    47/47 [==============================] - 9s 190ms/step - loss: 0.3845 - accuracy: 0.8347 - val_loss: 0.3171 - val_accuracy: 0.8820


Tamam, maxPooling'li modelimiz (model_5) eÄŸitim setinde daha kÃ¶tÃ¼ ama doÄŸrulama setinde daha iyi performans gÃ¶steriyor gibi gÃ¶rÃ¼nÃ¼yor.

EÄŸitim eÄŸrilerini kontrol etmeden Ã¶nce mimarisini kontrol edelim.



```python
model_5.summary()
```

    Model: "sequential_4"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_7 (Conv2D)            (None, 222, 222, 10)      280       
    _________________________________________________________________
    max_pooling2d_2 (MaxPooling2 (None, 111, 111, 10)      0         
    _________________________________________________________________
    conv2d_8 (Conv2D)            (None, 109, 109, 10)      910       
    _________________________________________________________________
    max_pooling2d_3 (MaxPooling2 (None, 54, 54, 10)        0         
    _________________________________________________________________
    conv2d_9 (Conv2D)            (None, 52, 52, 10)        910       
    _________________________________________________________________
    max_pooling2d_4 (MaxPooling2 (None, 26, 26, 10)        0         
    _________________________________________________________________
    flatten_4 (Flatten)          (None, 6760)              0         
    _________________________________________________________________
    dense_9 (Dense)              (None, 1)                 6761      
    =================================================================
    Total params: 8,861
    Trainable params: 8,861
    Non-trainable params: 0
    _________________________________________________________________


Her MaxPooling2D katmanÄ±ndaki Ã§Ä±ktÄ± ÅŸekliyle burada neler olduÄŸunu fark ettiniz mi?

Her seferinde yarÄ± yarÄ±ya dÃ¼ÅŸÃ¼yor. Bu MaxPooling2D katmanÄ±nÄ±n her Conv2D katmanÄ±nÄ±n Ã§Ä±ktÄ±larÄ±nÄ± almasÄ± ve "Ben sadece en Ã¶nemli Ã¶zellikleri istiyorum, geri kalanlardan kurtulun" demesidir.

pool_size parametresi ne kadar bÃ¼yÃ¼k olursa, maksimum havuzlama katmanÄ± o kadar fazla Ã¶zellikleri gÃ¶rÃ¼ntÃ¼den Ã§Ä±karÄ±r. Ancak, Ã§ok bÃ¼yÃ¼k ve model hiÃ§bir ÅŸey Ã¶ÄŸrenemeyebilir.

Bu havuzlamanÄ±n sonuÃ§larÄ±, toplam eÄŸitilebilir parametrelerde (model_5'te 8.861 ve model_4'te 477.431) bÃ¼yÃ¼k bir azalma olarak gÃ¶rÃ¼lmektedir.

KayÄ±p eÄŸrilerini kontrol etme zamanÄ±.



```python
plot_loss_curves(history_5)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_75_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_75_1.png)
    


GÃ¼zel! EÄŸrilerin birbirine Ã§ok daha yakÄ±nlaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rebiliriz. Bununla birlikte, doÄŸrulama kaybÄ±mÄ±z sona doÄŸru artmaya baÅŸlÄ±yor ve potansiyel olarak fazla uydurmaya yol aÃ§Ä±yor.

Hile Ã§antamÄ±za girme ve overfitting'i Ã¶nlemenin baÅŸka bir yÃ¶ntemini, veri artÄ±rmayÄ± denemenin zamanÄ± geldi.

Ä°lk olarak, kodla nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶receÄŸiz, sonra ne yaptÄ±ÄŸÄ±nÄ± tartÄ±ÅŸacaÄŸÄ±z.

Veri bÃ¼yÃ¼tmeyi uygulamak iÃ§in ImageDataGenerator Ã¶rneklerimizi yeniden baÅŸlatmamÄ±z gerekecek.



```python
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                          rotation_range=0.2,# resmi biraz dÃ¶ndÃ¼r
                          shear_range=0.2, # gÃ¶rÃ¼ntÃ¼yÃ¼ kÄ±rp
                          zoom_range=0.2,# resmi yakÄ±nlaÅŸtÄ±r
                          width_shift_range=0.2, # gÃ¶rÃ¼ntÃ¼ geniÅŸliÄŸi yollarÄ±nÄ± kaydÄ±r
                          height_shift_range=0.2, # gÃ¶rÃ¼ntÃ¼ yÃ¼ksekliÄŸi yollarÄ±nÄ± kaydÄ±r
                          horizontal_flip=True) # gÃ¶rÃ¼ntÃ¼yÃ¼ yatay eksende Ã§evir

train_datagen = ImageDataGenerator(rescale=1/255.) 
test_datagen = ImageDataGenerator(rescale=1/255.)
```

> ğŸ¤” Soru: Veri bÃ¼yÃ¼tme nedir?

**Veri bÃ¼yÃ¼tme**, eÄŸitim verilerimizi deÄŸiÅŸtirme, daha fazla Ã§eÅŸitliliÄŸe sahip olmasÄ±na ve dolayÄ±sÄ±yla modellerimizin daha genelleÅŸtirilebilir kalÄ±plarÄ± Ã¶ÄŸrenmesine izin verme sÃ¼recidir. DeÄŸiÅŸtirmek, bir gÃ¶rÃ¼ntÃ¼nÃ¼n dÃ¶nÃ¼ÅŸÃ¼nÃ¼ ayarlamak, Ã§evirmek, kÄ±rpmak veya benzeri bir ÅŸey anlamÄ±na gelebilir.

Bunu yapmak, bir modelin gerÃ§ek dÃ¼nyada kullanÄ±labileceÄŸi veri tÃ¼rÃ¼nÃ¼ simÃ¼le eder.

Bir pizza ve biftek uygulamasÄ± oluÅŸturuyorsak, kullanÄ±cÄ±larÄ±mÄ±zÄ±n Ã§ektiÄŸi resimlerin tÃ¼mÃ¼ eÄŸitim verilerimize benzer kurulumlarda olmayabilir. Veri bÃ¼yÃ¼tmeyi kullanmak, overfitting'i Ã¶nlemenin ve dolayÄ±sÄ±yla modelimizi daha genelleÅŸtirilebilir hale getirmenin baÅŸka bir yolunu sunar.

> ğŸ”‘ Not: Veri bÃ¼yÃ¼tme genellikle yalnÄ±zca eÄŸitim verileri Ã¼zerinde gerÃ§ekleÅŸtirilir. ImageDataGenerator yerleÅŸik veri bÃ¼yÃ¼tme parametrelerini kullanarak, gÃ¶rÃ¼ntÃ¼lerimiz dizinlerde olduÄŸu gibi bÄ±rakÄ±lÄ±r, ancak modele yÃ¼klendiÄŸinde rastgele manipÃ¼le edilir.


```python
print("Augmented training images:")
train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                      target_size=(224, 224),
                      batch_size=32,
                      class_mode='binary',
                      shuffle=False)

print("Non-augmented training images:")
train_data = train_datagen.flow_from_directory(train_dir,
                      target_size=(224, 224),
                      batch_size=32,
                      class_mode='binary',
                      shuffle=False)

print("Unchanged test images:")
test_data = test_datagen.flow_from_directory(test_dir,
                      target_size=(224, 224),
                      batch_size=32,
                      class_mode='binary')
```

    Augmented training images:
    Found 1500 images belonging to 2 classes.
    Non-augmented training images:
    Found 1500 images belonging to 2 classes.
    Unchanged test images:
    Found 500 images belonging to 2 classes.


Veri bÃ¼yÃ¼tme hakkÄ±nda konuÅŸmaktan daha iyi, onu gÃ¶rmeye ne dersiniz?

(mottomuzu hatÄ±rlÄ±yor musun? gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir...)



```python
images, labels = train_data.next()
augmented_images, augmented_labels = train_data_augmented.next() 

# orjinal ile tahmin edilen gÃ¶rseli karÅŸÄ±laÅŸtÄ±rma
random_number = random.randint(0, 32)
plt.imshow(images[random_number])
plt.title(f"Original image")
plt.axis(False)
plt.figure()
plt.imshow(augmented_images[random_number])
plt.title(f"Augmented image")
plt.axis(False);
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_81_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_81_1.png)
    


Orjinal ve artÄ±rÄ±lmÄ±ÅŸ gÃ¶rsellerin bir Ã¶rneÄŸini inceledikten sonra, eÄŸitim gÃ¶rselleri Ã¼zerinde bazÄ± Ã¶rnek dÃ¶nÃ¼ÅŸÃ¼mleri gÃ¶rmeye baÅŸlayabilirsiniz.

BazÄ± artÄ±rÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼lerin orijinal gÃ¶rÃ¼ntÃ¼nÃ¼n hafifÃ§e Ã§arpÄ±k sÃ¼rÃ¼mleri gibi gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ne dikkat edin. Bu, modelimizin, gerÃ§ek dÃ¼nya gÃ¶rÃ¼ntÃ¼lerini kullanÄ±rken genellikle olduÄŸu gibi, mÃ¼kemmel olmayan gÃ¶rÃ¼ntÃ¼lerdeki kalÄ±plarÄ± denemek ve Ã¶ÄŸrenmek zorunda kalacaÄŸÄ± anlamÄ±na gelir.

> ğŸ¤” Soru: Veri bÃ¼yÃ¼tmeyi kullanmalÄ± mÄ±yÄ±m? Ve ne kadar arttÄ±rmalÄ±yÄ±m?

Veri bÃ¼yÃ¼tme, bir modelin overfitting olmasÄ±nÄ± Ã¶nlemenin bir yoludur. Modeliniz gereÄŸinden fazla overfitting oluyorsa (Ã¶rneÄŸin, doÄŸrulama kaybÄ± artmaya devam ediyorsa), veri bÃ¼yÃ¼tmeyi kullanmayÄ± denemek isteyebilirsiniz.

Ne kadar veri artÄ±rÄ±lacaÄŸÄ±na gelince, bunun iÃ§in belirlenmiÅŸ bir uygulama yok. ImageDataGenerator sÄ±nÄ±fÄ±ndaki seÃ§eneklere gÃ¶z atmak ve kullanÄ±m durumunuzdaki bir modelin bazÄ± veri artÄ±rmalarÄ±ndan nasÄ±l yararlanabileceÄŸini dÃ¼ÅŸÃ¼nmek en iyisidir.

Åimdi artÄ±rÄ±lmÄ±ÅŸ veriye sahibiz, Ã¼zerine bir model yerleÅŸtirmeye Ã§alÄ±ÅŸalÄ±m ve eÄŸitimi nasÄ±l etkilediÄŸini gÃ¶relim.

Model_5 ile aynÄ± modeli kullanacaÄŸÄ±z.


```python
# bir model oluÅŸturma (model_5 gibi)
model_6 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(pool_size=2), 
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

# modeli derleme
model_6.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

# modeli fit etme
history_6 = model_6.fit(train_data_augmented, # artÄ±rÄ±lmÄ±ÅŸ eÄŸitim verilerine deÄŸiÅŸtirildi
                        epochs=5,
                        steps_per_epoch=len(train_data_augmented),
                        validation_data=test_data,
                        validation_steps=len(test_data))
```

    Epoch 1/5
    47/47 [==============================] - 22s 463ms/step - loss: 0.7099 - accuracy: 0.4740 - val_loss: 0.6818 - val_accuracy: 0.7340
    Epoch 2/5
    47/47 [==============================] - 21s 452ms/step - loss: 0.6873 - accuracy: 0.5573 - val_loss: 0.6559 - val_accuracy: 0.7740
    Epoch 3/5
    47/47 [==============================] - 23s 487ms/step - loss: 0.6991 - accuracy: 0.6120 - val_loss: 0.6396 - val_accuracy: 0.6780
    Epoch 4/5
    47/47 [==============================] - 21s 457ms/step - loss: 0.6720 - accuracy: 0.6027 - val_loss: 0.6064 - val_accuracy: 0.8240
    Epoch 5/5
    47/47 [==============================] - 21s 450ms/step - loss: 0.6666 - accuracy: 0.6153 - val_loss: 0.5807 - val_accuracy: 0.7080


> ğŸ¤” Soru: Modelimiz baÅŸlangÄ±Ã§ta eÄŸitim setinde neden Ã§ok iyi sonuÃ§lar alamadÄ±?

Bunun nedeni, train_data_augmented'i oluÅŸturduÄŸumuzda, shuffle=False kullanarak veri karÄ±ÅŸtÄ±rmayÄ± kapatmÄ±ÅŸ olmamÄ±zdÄ±r; bu, modelimizin bir seferde yalnÄ±zca tek bir tÃ¼r gÃ¶rÃ¼ntÃ¼den oluÅŸan bir toplu iÅŸ gÃ¶rdÃ¼ÄŸÃ¼ anlamÄ±na gelir.

Ã–rneÄŸin, pizza sÄ±nÄ±fÄ± birinci sÄ±nÄ±f olduÄŸu iÃ§in ilk yÃ¼klenir. BÃ¶ylece performansÄ± her iki sÄ±nÄ±ftan ziyade sadece tek bir sÄ±nÄ±fta Ã¶lÃ§Ã¼lÃ¼r. DoÄŸrulama verileri performansÄ±, karÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ veriler iÃ§erdiÄŸinden sÃ¼rekli olarak iyileÅŸir.

GÃ¶steri amacÄ±yla yalnÄ±zca shuffle=False ayarladÄ±ÄŸÄ±mÄ±zdan (bÃ¶ylece aynÄ± artÄ±rÄ±lmÄ±ÅŸ ve bÃ¼yÃ¼tÃ¼lmemiÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§izebiliriz), gelecekteki veri oluÅŸturucularda shuffle=True ayarÄ±nÄ± yaparak bunu dÃ¼zeltebiliriz.

AyrÄ±ca, artÄ±rÄ±lmÄ±ÅŸ verilerle eÄŸitim alÄ±rken her bir dÃ¶nemin, artÄ±rÄ±lmamÄ±ÅŸ verilerle eÄŸitime kÄ±yasla daha uzun sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ fark etmiÅŸ olabilirsiniz (dÃ¶nem baÅŸÄ±na ~25sn ve dÃ¶nem baÅŸÄ±na ~10sn).

Bunun nedeni, ImageDataGenerator Ã¶rneÄŸinin, modele yÃ¼klenirken verileri bÃ¼yÃ¼tmesidir. Bunun yararÄ±, orijinal gÃ¶rÃ¼ntÃ¼leri deÄŸiÅŸtirmeden bÄ±rakmasÄ±dÄ±r. DezavantajÄ±, onlarÄ± yÃ¼klemenin daha uzun sÃ¼rmesidir.

> ğŸ”‘ Not: Veri kÃ¼mesi manipÃ¼lasyonunu hÄ±zlandÄ±rmanÄ±n olasÄ± bir yÃ¶ntemi,[ TensorFlow'un paralel okumalarÄ±na ve arabelleÄŸe alÄ±nmÄ±ÅŸ Ã¶nceliklendirme](https://www.tensorflow.org/tutorials/images/data_augmentation) seÃ§eneklerine bakmak olabilir.


```python
plot_loss_curves(history_6)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_85_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_85_1.png)
    


DoÄŸrulama kaybÄ± eÄŸrimiz doÄŸru yÃ¶nde ilerliyor gibi gÃ¶rÃ¼nÃ¼yor, ancak biraz Ã¼rkek (en ideal kayÄ±p eÄŸrisi Ã§ok keskin deÄŸil, yumuÅŸak bir iniÅŸ, ancak tamamen pÃ¼rÃ¼zsÃ¼z bir kayÄ±p eÄŸrisi bir peri masalÄ±na eÅŸdeÄŸerdir).

ArttÄ±rÄ±lmÄ±ÅŸ verileri karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±zda ne olacaÄŸÄ±nÄ± gÃ¶relim.


```python
train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,
                                                        target_size=(224, 224),
                                                        batch_size=32,
                                                        class_mode='binary',
                                                        shuffle=True)
```

    Found 1500 images belonging to 2 classes.



```python
model_7 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

model_7.compile(loss='binary_crossentropy',
                optimizer=Adam(),
                metrics=['accuracy'])

history_7 = model_7.fit(train_data_augmented_shuffled,
                        epochs=5,
                        steps_per_epoch=len(train_data_augmented_shuffled),
                        validation_data=test_data,
                        validation_steps=len(test_data),
                        verbose=0)

plot_loss_curves(history_7)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_88_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_88_1.png)
    


model_7 ile eÄŸitim veri kÃ¼mesindeki performansÄ±n model_6 ile karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda neredeyse anÄ±nda nasÄ±l arttÄ±ÄŸÄ±na dikkat edin. Bunun nedeni, eÄŸitim verilerini, flow_from_directory yÃ¶nteminde shuffle=True parametresini kullanarak modele geÃ§irirken karÄ±ÅŸtÄ±rmÄ±ÅŸ olmamÄ±zdÄ±r.

Bu, modelin her partide hem pizza hem de biftek gÃ¶rÃ¼ntÃ¼lerinin Ã¶rneklerini gÃ¶rebildiÄŸi ve sÄ±rayla tek tÃ¼rden deÄŸil, her iki gÃ¶rÃ¼ntÃ¼den Ã¶ÄŸrendiklerini deÄŸerlendirebildiÄŸi anlamÄ±na gelir.

AyrÄ±ca, kayÄ±p eÄŸrilerimiz karÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ verilerle biraz daha pÃ¼rÃ¼zsÃ¼z gÃ¶rÃ¼nÃ¼yor (history_6 ile history_7'yi karÅŸÄ±laÅŸtÄ±rarak).

### 7.Tatmin Olana Kadar TekrarlayÄ±n

Veri kÃ¼memizde zaten birkaÃ§ model eÄŸittik ve ÅŸu ana kadar oldukÃ§a iyi performans gÃ¶steriyorlar.

Temel Ã§izgimizi Ã§oktan aÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in modelimizi geliÅŸtirmeye devam etmek iÃ§in deneyebileceÄŸimiz birkaÃ§ ÅŸey var:

- Model katmanlarÄ±nÄ±n sayÄ±sÄ±nÄ± artÄ±rÄ±n (Ã¶rneÄŸin, daha fazla evriÅŸim katmanÄ± ekleyin).
- Her evriÅŸim katmanÄ±ndaki filtre sayÄ±sÄ±nÄ± artÄ±rÄ±n (Ã¶rn. 10'dan 32'ye, 64'e veya 128'e, bu sayÄ±lar da sabit deÄŸildir, genellikle deneme yanÄ±lma yoluyla bulunurlar).
- Daha uzun sÃ¼re training yapÄ±n (daha fazla dÃ¶nem).
- Ä°deal bir Ã¶ÄŸrenme oranÄ± (learning_rate) bulma.
- Daha fazla veri alÄ±n (modele Ã¶ÄŸrenmesi iÃ§in daha fazla fÄ±rsat verin).
- BaÅŸka bir gÃ¶rÃ¼ntÃ¼ modelinin Ã¶ÄŸrendiklerinden yararlanmak iÃ§in aktarÄ±m Ã¶ÄŸrenimini kullanÄ±n ve bunu kendi kullanÄ±m durumumuza gÃ¶re ayarlayÄ±n.

Model geliÅŸtirme sÄ±rasÄ±nda bu ayarlarÄ±n her birinin (son ikisi hariÃ§) ayarlanmasÄ± genellikle hiperparametre ayarÄ± olarak adlandÄ±rÄ±lÄ±r.

Hiperparametre ayarÄ±nÄ±, en sevdiÄŸiniz yemeÄŸi piÅŸirmek iÃ§in fÄ±rÄ±nÄ±nÄ±zdaki ayarlarÄ± yapmaya benzetebilirsiniz. FÄ±rÄ±nÄ±nÄ±z sizin iÃ§in piÅŸirmenin Ã§oÄŸunu yapsa da, Ä±sÄ±yÄ± ayarlayarak buna yardÄ±mcÄ± olabilirsiniz.

BaÅŸladÄ±ÄŸÄ±mÄ±z yere geri dÃ¶nelim ve orijinal modelimizi deneyelim:


```python
model_8 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)), 
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(1, activation='sigmoid')
])

model_8.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

history_8 = model_8.fit(train_data_augmented_shuffled,
                        epochs=5,
                        steps_per_epoch=len(train_data_augmented_shuffled),
                        validation_data=test_data,
                        validation_steps=len(test_data))
```

    Epoch 1/5
    47/47 [==============================] - 23s 473ms/step - loss: 0.6579 - accuracy: 0.6087 - val_loss: 0.5885 - val_accuracy: 0.6440
    Epoch 2/5
    47/47 [==============================] - 24s 502ms/step - loss: 0.5509 - accuracy: 0.7293 - val_loss: 0.4329 - val_accuracy: 0.8140
    Epoch 3/5
    47/47 [==============================] - 22s 473ms/step - loss: 0.5493 - accuracy: 0.7320 - val_loss: 0.5195 - val_accuracy: 0.7300
    Epoch 4/5
    47/47 [==============================] - 22s 478ms/step - loss: 0.5418 - accuracy: 0.7367 - val_loss: 0.4005 - val_accuracy: 0.8380
    Epoch 5/5
    47/47 [==============================] - 24s 501ms/step - loss: 0.5206 - accuracy: 0.7667 - val_loss: 0.3967 - val_accuracy: 0.8340


> ğŸ”‘ Not: Model_8'i oluÅŸturmak iÃ§in model_1 ile karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda biraz farklÄ± kodlar kullandÄ±ÄŸÄ±mÄ±zÄ± fark etmiÅŸ olabilirsiniz. Bunun nedeni, daha Ã¶nce yaptÄ±ÄŸÄ±mÄ±z iÃ§e aktarmalar, Ã¶rneÄŸin tensorflow.keras.layers'dan iÃ§e aktarma Conv2D, yazmamÄ±z gereken kod miktarÄ±nÄ± azaltÄ±r. Kodlar farklÄ± olsa da mimariler aynÄ±.


```python
model_1.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d (Conv2D)              (None, 222, 222, 10)      280       
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 220, 220, 10)      910       
    _________________________________________________________________
    max_pooling2d (MaxPooling2D) (None, 110, 110, 10)      0         
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 108, 108, 10)      910       
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 106, 106, 10)      910       
    _________________________________________________________________
    max_pooling2d_1 (MaxPooling2 (None, 53, 53, 10)        0         
    _________________________________________________________________
    flatten (Flatten)            (None, 28090)             0         
    _________________________________________________________________
    dense (Dense)                (None, 1)                 28091     
    =================================================================
    Total params: 31,101
    Trainable params: 31,101
    Non-trainable params: 0
    _________________________________________________________________



```python
model_8.summary()
```

    Model: "sequential_8"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_20 (Conv2D)           (None, 222, 222, 10)      280       
    _________________________________________________________________
    conv2d_21 (Conv2D)           (None, 220, 220, 10)      910       
    _________________________________________________________________
    max_pooling2d_13 (MaxPooling (None, 110, 110, 10)      0         
    _________________________________________________________________
    conv2d_22 (Conv2D)           (None, 108, 108, 10)      910       
    _________________________________________________________________
    conv2d_23 (Conv2D)           (None, 106, 106, 10)      910       
    _________________________________________________________________
    max_pooling2d_14 (MaxPooling (None, 53, 53, 10)        0         
    _________________________________________________________________
    flatten_8 (Flatten)          (None, 28090)             0         
    _________________________________________________________________
    dense_13 (Dense)             (None, 1)                 28091     
    =================================================================
    Total params: 31,101
    Trainable params: 31,101
    Non-trainable params: 0
    _________________________________________________________________


Åimdi TinyVGG modelimizin performansÄ±nÄ± kontrol edelim.


```python
# TinyVGG model performansÄ±na gÃ¶z atÄ±n
plot_loss_curves(history_8)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_96_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_96_1.png)
    



```python
# Bu eÄŸitim eÄŸrisi yukarÄ±dakine kÄ±yasla nasÄ±l gÃ¶rÃ¼nÃ¼yor?
plot_loss_curves(history_1)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_97_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_97_1.png)
    


Hmm, eÄŸitim eÄŸrilerimiz iyi gÃ¶rÃ¼nÃ¼yor, ancak modelimizin eÄŸitim ve test setlerindeki performansÄ± Ã¶nceki modele gÃ¶re pek geliÅŸmedi.

EÄŸitim eÄŸrilerine bir kez daha baktÄ±ÄŸÄ±mÄ±zda, biraz daha uzun sÃ¼re (daha fazla dÃ¶nem) eÄŸitirsek modelimizin performansÄ± artabilir gibi gÃ¶rÃ¼nÃ¼yor.


### EÄŸitimli Modelimiz ile Tahmin Yapmak

Onunla tahmin yapamÄ±yorsanÄ±z, eÄŸitimli bir model ne iÅŸe yarar? GerÃ§ekten test etmek iÃ§in kendi resimlerimizden birkaÃ§Ä±nÄ± yÃ¼kleyeceÄŸiz ve modelin nasÄ±l gittiÄŸini gÃ¶receÄŸiz. Ã–ncelikle kendimize sÄ±nÄ±f isimlerini hatÄ±rlatalÄ±m ve Ã¼zerinde test edeceÄŸimiz gÃ¶rsele bakalÄ±m.


```python
# Ã‡alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z SÄ±nÄ±flar
print(class_names)
```

    ['.DS_Store' 'pizza' 'steak']



```python
!wget "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/steak_2.jpg"
steak = mpimg.imread("steak_2.jpg")
plt.imshow(steak)
plt.axis(False);
```

    --2021-07-17 13:06:45--  https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/steak_2.jpg
    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 300203 (293K) [image/jpeg]
    Saving to: â€˜steak_2.jpg.2â€™
    
    steak_2.jpg.2       100%[===================>] 293.17K  --.-KB/s    in 0.02s   
    
    2021-07-17 13:06:45 (15.7 MB/s) - â€˜steak_2.jpg.2â€™ saved [300203/300203]
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_101_1.png)
    



```python
# shape deÄŸerini kontrol edelim
steak.shape
```




    (1310, 1258, 3)



Modelimiz ÅŸekillerin (224, 224, 3) gÃ¶rÃ¼ntÃ¼lerini aldÄ±ÄŸÄ±ndan, kendi modelimiz ile kullanmak iÃ§in Ã¶zel imajÄ±mÄ±zÄ± yeniden ÅŸekillendirmemiz gerekiyor.

Bunu yapmak iÃ§in, tf.io.read_file (dosyalarÄ± okumak iÃ§in) ve tf.image (imajÄ±mÄ±zÄ± yeniden boyutlandÄ±rmak ve bir tensÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in) kullanarak imajÄ±mÄ±zÄ± iÃ§e aktarabilir ve kodunu Ã§Ã¶zebiliriz.

> ğŸ”‘ Not: Modelinizin, Ã¶rneÄŸin kendi Ã¶zel resimleriniz gibi gÃ¶rÃ¼nmeyen verilerle ilgili tahminlerde bulunabilmesi iÃ§in, Ã¶zel gÃ¶rÃ¼ntÃ¼nÃ¼n, modelinizin eÄŸitildiÄŸi ÅŸekilde olmasÄ± gerekir. Daha genel bir ifadeyle, Ã¶zel veriler Ã¼zerinde tahminlerde bulunmak iÃ§in modelinizin eÄŸitildiÄŸi formda olmasÄ± gerekir.




```python
# Bir gÃ¶rÃ¼ntÃ¼yÃ¼ iÃ§e aktarmak ve modelimiz ile kullanÄ±labilecek ÅŸekilde 
# yeniden boyutlandÄ±rmak iÃ§in bir iÅŸlev oluÅŸturalÄ±m
def load_and_prep_image(filename, img_shape=224):
  # resmi okuma
  img = tf.io.read_file(filename)
  # Bir tensÃ¶re decode etme
  img = tf.image.decode_jpeg(img)
  # yeniden boyutlandÄ±rma
  img = tf.image.resize(img, [img_shape, img_shape])
  # normalize
  img = img/255.
  return img
```

Åimdi Ã¶zel imajÄ±mÄ±zÄ± yÃ¼klemek iÃ§in bir fonksiyonumuz var, onu yÃ¼kleyelim.


```python
steak = load_and_prep_image("steak_2.jpg")
steak
```




    <tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=
    array([[[0.26381305, 0.24028361, 0.19322479],
            [0.26572865, 0.24219921, 0.19514039],
            [0.2708914 , 0.24736199, 0.20030317],
            ...,
            [0.2650035 , 0.24931723, 0.20225841],
            [0.26321357, 0.2475273 , 0.20046848],
            [0.28401613, 0.26832986, 0.22127101]],
    
           [[0.28641456, 0.26288515, 0.21582633],
            [0.2924    , 0.2688706 , 0.22181177],
            [0.2810408 , 0.25751138, 0.21045254],
            ...,
            [0.24492297, 0.22923669, 0.18609944],
            [0.24658544, 0.23089917, 0.18384035],
            [0.28021708, 0.2645308 , 0.21747199]],
    
           [[0.28692865, 0.2627451 , 0.21601336],
            [0.29481623, 0.2704132 , 0.22379117],
            [0.2961762 , 0.27213612, 0.22533265],
            ...,
            [0.23741287, 0.2217266 , 0.18643248],
            [0.23338516, 0.21421418, 0.1893742 ],
            [0.2734472 , 0.2541664 , 0.22965583]],
    
           ...,
    
           [[0.55565476, 0.5125175 , 0.4310156 ],
            [0.56367356, 0.5205363 , 0.44063556],
            [0.5681545 , 0.52501726, 0.44246843],
            ...,
            [0.6766286 , 0.6413344 , 0.57466775],
            [0.65775603, 0.6224619 , 0.55579525],
            [0.6625994 , 0.62730527, 0.5606386 ]],
    
           [[0.5369749 , 0.50560236, 0.43109256],
            [0.535942  , 0.5045695 , 0.43005973],
            [0.5529945 , 0.52162194, 0.44711217],
            ...,
            [0.6752446 , 0.6438721 , 0.5693623 ],
            [0.67058825, 0.6392157 , 0.5647059 ],
            [0.67270285, 0.6413303 , 0.5668205 ]],
    
           [[0.50416195, 0.47278938, 0.39827958],
            [0.5234028 , 0.49203026, 0.41752046],
            [0.5509676 , 0.519595  , 0.44508523],
            ...,
            [0.6779879 , 0.6466153 , 0.5721055 ],
            [0.6653004 , 0.6339279 , 0.5594181 ],
            [0.6922957 , 0.6609231 , 0.5864133 ]]], dtype=float32)>



Harika, imajÄ±mÄ±z tensÃ¶r formatÄ±nda, modelimiz ile deneme zamanÄ±!


```python
model_8.predict(steak)
```


    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-98-f52a71fd4ea7> in <module>()
    ----> 1 model_8.predict(steak)
    

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
       1725           for step in data_handler.steps():
       1726             callbacks.on_predict_batch_begin(step)
    -> 1727             tmp_batch_outputs = self.predict_function(iterator)
       1728             if data_handler.should_sync:
       1729               context.async_wait()


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
        887 
        888       with OptionalXlaContext(self._jit_compile):
    --> 889         result = self._call(*args, **kwds)
        890 
        891       new_tracing_count = self.experimental_get_tracing_count()


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
        922       # In this case we have not created variables on the first call. So we can
        923       # run the first trace but we should fail if variables are created.
    --> 924       results = self._stateful_fn(*args, **kwds)
        925       if self._created_variables:
        926         raise ValueError("Creating variables on a non-first call to a function"


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
       3020     with self._lock:
       3021       (graph_function,
    -> 3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)
       3023     return graph_function._call_flat(
       3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
       3439               call_context_key in self._function_cache.missed):
       3440             return self._define_function_with_shape_relaxation(
    -> 3441                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)
       3442 
       3443           self._function_cache.missed.add(call_context_key)


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _define_function_with_shape_relaxation(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)
       3361 
       3362     graph_function = self._create_graph_function(
    -> 3363         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
       3364     self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function
       3365 


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
       3287             arg_names=arg_names,
       3288             override_flat_arg_shapes=override_flat_arg_shapes,
    -> 3289             capture_by_value=self._capture_by_value),
       3290         self._function_attributes,
       3291         function_spec=self.function_spec,


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
        997         _, original_func = tf_decorator.unwrap(python_func)
        998 
    --> 999       func_outputs = python_func(*func_args, **func_kwargs)
       1000 
       1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
        670         # the function a weak reference to itself to avoid a reference cycle.
        671         with OptionalXlaContext(compile_with_xla):
    --> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
        673         return out
        674 


    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
        984           except Exception as e:  # pylint:disable=broad-except
        985             if hasattr(e, "ag_error_metadata"):
    --> 986               raise e.ag_error_metadata.to_exception(e)
        987             else:
        988               raise


    ValueError: in user code:
    
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *
            return step_function(self, iterator)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **
            outputs = model.distribute_strategy.run(run_step, args=(data,))
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
            return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
            return self._call_for_each_replica(fn, args, kwargs)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
            return fn(*args, **kwargs)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **
            outputs = model.predict_step(data)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1525 predict_step
            return self(x, training=False)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__
            input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)
        /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:235 assert_input_compatibility
            str(tuple(shape)))
    
        ValueError: Input 0 of layer sequential_8 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 224, 3)



Bir sorun daha var...

GÃ¶rselimiz, modelimizin eÄŸitildiÄŸi gÃ¶rÃ¼ntÃ¼lerle aynÄ± ÅŸekilde olmasÄ±na raÄŸmen, hala bir boyutu kaÃ§Ä±rÄ±yoruz.

Modelimizin gruplar halinde nasÄ±l eÄŸitildiÄŸini hatÄ±rlÄ±yor musunuz? batch boyutu ilk boyut olur. Yani gerÃ§ekte, modelimiz (batch_size, 224, 224, 3) ÅŸeklindeki veriler Ã¼zerinde eÄŸitildi.

Bunu, `tf.expand_dims` kullanarak Ã¶zel gÃ¶rÃ¼ntÃ¼ tensÃ¶rÃ¼mÃ¼ze fazladan ekleyerek dÃ¼zeltebiliriz.


```python
print(f"Shape before new dimension: {steak.shape}")
steak = tf.expand_dims(steak, axis=0)
print(f"Shape after new dimension: {steak.shape}")
steak
```

    Shape before new dimension: (224, 224, 3)
    Shape after new dimension: (1, 224, 224, 3)





    <tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=
    array([[[[0.26381305, 0.24028361, 0.19322479],
             [0.26572865, 0.24219921, 0.19514039],
             [0.2708914 , 0.24736199, 0.20030317],
             ...,
             [0.2650035 , 0.24931723, 0.20225841],
             [0.26321357, 0.2475273 , 0.20046848],
             [0.28401613, 0.26832986, 0.22127101]],
    
            [[0.28641456, 0.26288515, 0.21582633],
             [0.2924    , 0.2688706 , 0.22181177],
             [0.2810408 , 0.25751138, 0.21045254],
             ...,
             [0.24492297, 0.22923669, 0.18609944],
             [0.24658544, 0.23089917, 0.18384035],
             [0.28021708, 0.2645308 , 0.21747199]],
    
            [[0.28692865, 0.2627451 , 0.21601336],
             [0.29481623, 0.2704132 , 0.22379117],
             [0.2961762 , 0.27213612, 0.22533265],
             ...,
             [0.23741287, 0.2217266 , 0.18643248],
             [0.23338516, 0.21421418, 0.1893742 ],
             [0.2734472 , 0.2541664 , 0.22965583]],
    
            ...,
    
            [[0.55565476, 0.5125175 , 0.4310156 ],
             [0.56367356, 0.5205363 , 0.44063556],
             [0.5681545 , 0.52501726, 0.44246843],
             ...,
             [0.6766286 , 0.6413344 , 0.57466775],
             [0.65775603, 0.6224619 , 0.55579525],
             [0.6625994 , 0.62730527, 0.5606386 ]],
    
            [[0.5369749 , 0.50560236, 0.43109256],
             [0.535942  , 0.5045695 , 0.43005973],
             [0.5529945 , 0.52162194, 0.44711217],
             ...,
             [0.6752446 , 0.6438721 , 0.5693623 ],
             [0.67058825, 0.6392157 , 0.5647059 ],
             [0.67270285, 0.6413303 , 0.5668205 ]],
    
            [[0.50416195, 0.47278938, 0.39827958],
             [0.5234028 , 0.49203026, 0.41752046],
             [0.5509676 , 0.519595  , 0.44508523],
             ...,
             [0.6779879 , 0.6466153 , 0.5721055 ],
             [0.6653004 , 0.6339279 , 0.5594181 ],
             [0.6922957 , 0.6609231 , 0.5864133 ]]]], dtype=float32)>



Ã–zel gÃ¶rselimizin toplu iÅŸ boyutu 1'dir! Ona gÃ¶re bir tahmin yapalÄ±m.


```python
pred = model_8.predict(steak)
pred
```




    array([[0.3949119]], dtype=float32)



Ahh, tahminler olasÄ±lÄ±k ÅŸeklinde Ã§Ä±kÄ±yor. BaÅŸka bir deyiÅŸle, bu, gÃ¶rÃ¼ntÃ¼nÃ¼n bir sÄ±nÄ±f veya baÅŸka bir sÄ±nÄ±f olma olasÄ±lÄ±ÄŸÄ±nÄ±n ne kadar olduÄŸu anlamÄ±na gelir.

Ä°kili bir sÄ±nÄ±flandÄ±rma problemi ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, tahmin olasÄ±lÄ±ÄŸÄ± modele gÃ¶re 0,5'in Ã¼zerindeyse, tahmin bÃ¼yÃ¼k olasÄ±lÄ±kla pozitif sÄ±nÄ±f olacaktÄ±r (sÄ±nÄ±f 1).

Ve tahmin olasÄ±lÄ±ÄŸÄ± 0,5'in altÄ±ndaysa, modele gÃ¶re, tahmin edilen sÄ±nÄ±f bÃ¼yÃ¼k olasÄ±lÄ±kla negatif sÄ±nÄ±ftÄ±r (sÄ±nÄ±f 0).

> ğŸ”‘ Not: 0,5 kesme beÄŸeninize gÃ¶re ayarlanabilir. Ã–rneÄŸin, pozitif sÄ±nÄ±f iÃ§in limiti 0,8 ve Ã¼zeri ve negatif sÄ±nÄ±f iÃ§in 0,2 olarak ayarlayabilirsiniz. Ancak, bunu yapmak neredeyse her zaman modelinizin performans Ã¶lÃ§Ã¼mlerini deÄŸiÅŸtirecektir, bu nedenle doÄŸru yÃ¶nde deÄŸiÅŸtiklerinden emin olun.

Ama pizza ğŸ• ve biftek ğŸ¥© ile Ã§alÄ±ÅŸÄ±rken pozitif ve negatif sÄ±nÄ±f demek pek mantÄ±klÄ± gelmiyor...

Ã–yleyse, tahminleri sÄ±nÄ±f adlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kÃ¼Ã§Ã¼k bir fonksiyon yazalÄ±m ve ardÄ±ndan hedef gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§izelim.


```python
class_names
```




    array(['.DS_Store', 'pizza', 'steak'], dtype='<U9')




```python
class_names = class_names[1:]
class_names
```




    array(['pizza', 'steak'], dtype='<U9')




```python
# Tahmin olasÄ±lÄ±ÄŸÄ±nÄ± yuvarlayarak tahmin edilen sÄ±nÄ±fÄ± indeksleyebiliriz
pred_class = class_names[int(tf.round(pred)[0][0])]
pred_class
```




    'pizza'




```python
def pred_and_plot(model, filename, class_names):
  # Hedef gÃ¶rÃ¼ntÃ¼yÃ¼ iÃ§e aktarma ve Ã¶niÅŸleme
  img = load_and_prep_image(filename)

  # tahmin yapma
  pred = model.predict(tf.expand_dims(img, axis=0))

  # tahmin yapma (sÄ±nÄ±f)
  pred_class = class_names[int(tf.round(pred)[0][0])]

  plt.imshow(img)
  plt.title(f"Prediction: {pred_class}")
  plt.axis(False);


pred_and_plot(model_8, "steak_2.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_117_0.png)
    


GÃ¼zel! Modelimiz tahmini doÄŸru yaptÄ±. Yemekle Ã§alÄ±ÅŸmanÄ±n tek dezavantajÄ± bu beni acÄ±ktÄ±rÄ±yor. Bir resim daha deneyelim.



```python
# Download another test image and make a prediction on it
!wget "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/pizza_1.jpg" 
pred_and_plot(model_8, "pizza_1.jpg", class_names)
```

    --2021-07-17 13:07:52--  https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/pizza_1.jpg
    Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...
    Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 285436 (279K) [image/jpeg]
    Saving to: â€˜pizza_1.jpgâ€™
    
    pizza_1.jpg         100%[===================>] 278.75K  --.-KB/s    in 0.02s   
    
    2021-07-17 13:07:53 (13.2 MB/s) - â€˜pizza_1.jpgâ€™ saved [285436/285436]
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_119_1.png)
    


## Ã‡ok SÄ±nÄ±flÄ± SÄ±nÄ±flandÄ±rma

Bu defter aracÄ±lÄ±ÄŸÄ±yla CNN AÃ§Ä±klayÄ±cÄ± web sitesindeki TinyVGG mimarisine birÃ§ok kez atÄ±fta bulunduk, ancak CNN AÃ§Ä±klayÄ±cÄ± web sitesi 10 farklÄ± gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±fÄ±yla Ã§alÄ±ÅŸÄ±yor, ÅŸu anki modelimiz yalnÄ±zca iki sÄ±nÄ±fla (pizza ve biftek) Ã§alÄ±ÅŸÄ±yor.

> ğŸ›  AlÄ±ÅŸtÄ±rma: AÅŸaÄŸÄ± kaydÄ±rmadan Ã¶nce, aynÄ± tÃ¼rden gÃ¶rÃ¼ntÃ¼lerden oluÅŸan 10 sÄ±nÄ±fla Ã§alÄ±ÅŸmak iÃ§in modelimizi nasÄ±l deÄŸiÅŸtirebileceÄŸimizi dÃ¼ÅŸÃ¼nÃ¼yorsunuz? Verilerin iki sÄ±nÄ±f problemimizle aynÄ± tarzda olduÄŸunu varsayalÄ±m.

Pizza ğŸ• ve biftek ğŸ¥© sÄ±nÄ±flandÄ±rÄ±cÄ±mÄ±zÄ± oluÅŸturmak iÃ§in daha Ã¶nce attÄ±ÄŸÄ±mÄ±z adÄ±mlarÄ± hatÄ±rlÄ±yor musunuz?

O aÅŸamalarÄ± bir kez daha gÃ¶zden geÃ§irmeye ne dersiniz, ama bu sefer 10 farklÄ± yiyecek tÃ¼rÃ¼yle Ã§alÄ±ÅŸacaÄŸÄ±z.

1. Verilerle bÃ¼tÃ¼nleÅŸin (gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin, gÃ¶rselleÅŸtirin...)
2. Verileri Ã¶nceden iÅŸleyin (bir model iÃ§in hazÄ±rlayÄ±n)
3. Bir model oluÅŸturun (bir temel ile baÅŸlayÄ±n)
4. Modeli fit edin
5. Modeli deÄŸerlendirin
6. FarklÄ± parametreleri ayarlayÄ±n ve modeli iyileÅŸtirin (temel Ã§izginizi geÃ§meye Ã§alÄ±ÅŸÄ±n)
7. Memnun kalana kadar tekrarlayÄ±n

<img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2020/05/13/sagemaker-tensorflow.png" />

### 1.Verileri Ä°Ã§e AktarÄ±n ve Verilerle BÃ¼tÃ¼nleÅŸin

Yine, Food101 veri kÃ¼mesinin bir alt kÃ¼mesine sahibiz. Pizza ve biftek resimlerine ek olarak, sekiz sÄ±nÄ±f daha Ã§Ä±kardÄ±k.


```python
import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip 

zip_ref = zipfile.ZipFile("10_food_classes_all_data.zip", "r")
zip_ref.extractall()
zip_ref.close()
```

    --2021-07-17 13:07:57--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip
    Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 142.251.2.128, 2607:f8b0:4023:c06::80, ...
    Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 519183241 (495M) [application/zip]
    Saving to: â€˜10_food_classes_all_data.zipâ€™
    
    10_food_classes_all 100%[===================>] 495.13M   246MB/s    in 2.0s    
    
    2021-07-17 13:07:59 (246 MB/s) - â€˜10_food_classes_all_data.zipâ€™ saved [519183241/519183241]
    


Åimdi 10_food_classes dosyasÄ±ndaki tÃ¼m farklÄ± dizinleri ve alt dizinleri kontrol edelim.


```python
import os

for dirpath, dirnames, filenames in os.walk("10_food_classes_all_data"):
  print(f"'{dirpath}' klasÃ¶rÃ¼nde {len(filenames)} veri var.")
```

    '10_food_classes_all_data' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_all_data/test' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_all_data/test/hamburger' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/grilled_salmon' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/pizza' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/chicken_curry' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/sushi' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/ice_cream' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/fried_rice' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/chicken_wings' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/steak' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/test/ramen' klasÃ¶rÃ¼nde 250 veri var.
    '10_food_classes_all_data/train' klasÃ¶rÃ¼nde 0 veri var.
    '10_food_classes_all_data/train/hamburger' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/grilled_salmon' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/pizza' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/chicken_curry' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/sushi' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/ice_cream' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/fried_rice' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/chicken_wings' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/steak' klasÃ¶rÃ¼nde 750 veri var.
    '10_food_classes_all_data/train/ramen' klasÃ¶rÃ¼nde 750 veri var.


Ä°yi gÃ¶rÃ¼nÃ¼yor! Åimdi eÄŸitim ve test dizini yollarÄ±nÄ± ayarlayacaÄŸÄ±z.


```python
# Ã‡ok sÄ±nÄ±flÄ± veri kÃ¼memiz iÃ§in sÄ±nÄ±f adlarÄ±nÄ± alma
import pathlib
import numpy as np

train_dir = "10_food_classes_all_data/train/"
test_dir = "10_food_classes_all_data/test/"

data_dir = pathlib.Path(train_dir)
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)
```

    ['chicken_curry' 'chicken_wings' 'fried_rice' 'grilled_salmon' 'hamburger'
     'ice_cream' 'pizza' 'ramen' 'steak' 'sushi']


EÄŸitim setinden bir gÃ¶rseli gÃ¶rselleÅŸtirmeye ne dersiniz?


```python
import random
img = view_random_image(target_dir=train_dir,
                        target_class=random.choice(class_names)) # get a random class name
```

    Image shape: (512, 384, 3)



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_128_1.png)
    


### 2.Verileri Ã–nceden Ä°ÅŸleyin

BirkaÃ§ resimden geÃ§tikten sonra (en az 10-100 farklÄ± Ã¶rneÄŸi gÃ¶rselleÅŸtirmek iyidir), veri dizinlerimiz doÄŸru ÅŸekilde ayarlanmÄ±ÅŸ gibi gÃ¶rÃ¼nÃ¼yor.

Verileri Ã¶nceden iÅŸleme zamanÄ±.


```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Verileri yeniden Ã¶lÃ§eklendirme
train_datagen = ImageDataGenerator(rescale=1/255.)
test_datagen = ImageDataGenerator(rescale=1/255.)

# Dizinlerden veri yÃ¼kleme ve yÄ±ÄŸÄ±nlara dÃ¶nÃ¼ÅŸtÃ¼rme
train_data = train_datagen.flow_from_directory(train_dir,
                                               target_size=(224, 224),
                                               batch_size=32,
                                               class_mode='categorical') 

test_data = train_datagen.flow_from_directory(test_dir,
                                              target_size=(224, 224),
                                              batch_size=32,
                                              class_mode='categorical')
```

    Found 7500 images belonging to 10 classes.
    Found 2500 images belonging to 10 classes.


Ä°kili sÄ±nÄ±flandÄ±rmada olduÄŸu gibi, gÃ¶rÃ¼ntÃ¼ oluÅŸturucularÄ±mÄ±z var. Bu seferki ana deÄŸiÅŸiklik, class_mode parametresini 'categorical' olarak deÄŸiÅŸtirmemizdir Ã§Ã¼nkÃ¼ 10 sÄ±nÄ±f yiyecek gÃ¶rÃ¼ntÃ¼sÃ¼ ile uÄŸraÅŸÄ±yoruz.

GÃ¶rÃ¼ntÃ¼leri yeniden Ã¶lÃ§eklendirmek, toplu iÅŸ boyutunu ve hedef gÃ¶rÃ¼ntÃ¼ boyutunu oluÅŸturmak gibi diÄŸer her ÅŸey aynÄ± kalÄ±r.

> ğŸ¤” Soru: Resmin boyutu neden 224x224? Bu aslÄ±nda istediÄŸimiz herhangi bir boyut olabilir, ancak 224x224, gÃ¶rÃ¼ntÃ¼lerin Ã¶n iÅŸlemesi iÃ§in Ã§ok yaygÄ±n bir boyuttur. Sorununuza baÄŸlÄ± olarak daha bÃ¼yÃ¼k veya daha kÃ¼Ã§Ã¼k resimler kullanmak isteyebilirsiniz.

### 3.Bir Model OluÅŸturma

Ä°kili sÄ±nÄ±flandÄ±rma problemi iÃ§in kullandÄ±ÄŸÄ±mÄ±z aynÄ± modeli (TinyVGG) Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemimiz iÃ§in birkaÃ§ kÃ¼Ã§Ã¼k ince ayar ile kullanabiliriz.

Yani:

- KullanÄ±lacak Ã§Ä±ktÄ± katmanÄ±nÄ± deÄŸiÅŸtirmek, 10 Ã§Ä±ktÄ± nÃ¶ronuna sahiptir (sahip olduÄŸumuz sÄ±nÄ±f sayÄ±sÄ±yla aynÄ± sayÄ±).
- Ã‡Ä±ktÄ± katmanÄ±nÄ± 'sigmoid' aktivasyonu yerine 'softmax' aktivasyonunu kullanacak ÅŸekilde deÄŸiÅŸtirme.
- KayÄ±p iÅŸlevinin 'binary_crossentropy' yerine 'categorical_crossentropy' olarak deÄŸiÅŸtirilmesi.


```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense

model_9 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(10, activation='softmax') 
])

model_9.compile(loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])
```

### 4.Modeli Fit Edin

Åimdi birden fazla sÄ±nÄ±fla Ã§alÄ±ÅŸmaya uygun bir modelimiz var, onu verilerimizle fit edelim.


```python
history_9 = model_9.fit(train_data, # 10 farklÄ± sÄ±nÄ±f
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))
```

    Epoch 1/5
    235/235 [==============================] - 46s 194ms/step - loss: 2.1381 - accuracy: 0.2271 - val_loss: 2.0048 - val_accuracy: 0.2716
    Epoch 2/5
    235/235 [==============================] - 44s 188ms/step - loss: 1.8894 - accuracy: 0.3475 - val_loss: 1.8485 - val_accuracy: 0.3668
    Epoch 3/5
    235/235 [==============================] - 44s 188ms/step - loss: 1.6009 - accuracy: 0.4596 - val_loss: 1.8771 - val_accuracy: 0.3644
    Epoch 4/5
    235/235 [==============================] - 45s 191ms/step - loss: 1.0496 - accuracy: 0.6556 - val_loss: 2.1192 - val_accuracy: 0.3332
    Epoch 5/5
    235/235 [==============================] - 44s 189ms/step - loss: 0.4512 - accuracy: 0.8572 - val_loss: 2.9371 - val_accuracy: 0.2972


Neden her epoch yalnÄ±zca iki gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±fÄ±yla Ã§alÄ±ÅŸÄ±rken olduÄŸundan daha uzun sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ dÃ¼ÅŸÃ¼nÃ¼yorsunuz?

Ã‡Ã¼nkÃ¼ artÄ±k eskisinden daha fazla gÃ¶rÃ¼ntÃ¼yle uÄŸraÅŸÄ±yoruz. 750 eÄŸitim gÃ¶rÃ¼ntÃ¼sÃ¼ ve her biri toplam 10.000 gÃ¶rÃ¼ntÃ¼ olan 250 doÄŸrulama gÃ¶rÃ¼ntÃ¼sÃ¼ iÃ§eren 10 sÄ±nÄ±fÄ±mÄ±z var. Ä°ki sÄ±nÄ±fÄ±mÄ±z olduÄŸu zaman, toplam 2000 olmak Ã¼zere 1500 eÄŸitim gÃ¶rselimiz ve 500 doÄŸrulama gÃ¶rselimiz vardÄ±.

Buradaki sezgisel akÄ±l yÃ¼rÃ¼tme, ne kadar fazla veriye sahip olursanÄ±z, bir modelin kalÄ±plarÄ± bulmasÄ± o kadar uzun sÃ¼rer.

### 5.Modeli DeÄŸerlendirin

Woohoo! Az Ã¶nce bir modeli 10 farklÄ± yiyecek gÃ¶rÃ¼ntÃ¼sÃ¼ sÄ±nÄ±fÄ±nda eÄŸittik, bakalÄ±m nasÄ±lmÄ±ÅŸ.


```python
model_9.evaluate(test_data)
```

    79/79 [==============================] - 10s 131ms/step - loss: 2.9371 - accuracy: 0.2972





    [2.9370851516723633, 0.2971999943256378]




```python
plot_loss_curves(history_9)
```

Woah, eÄŸitim ve doÄŸrulama kaybÄ± eÄŸrileri arasÄ±ndaki boÅŸluk Ã§oook fazla.

Bu bize ne anlatÄ±yor?

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re modelimiz eÄŸitim setine oldukÃ§a overfitting olmuÅŸ. BaÅŸka bir deyiÅŸle, eÄŸitim verilerinde harika sonuÃ§lar alÄ±yor ancak gÃ¶rÃ¼nmeyen verilere genelleme yapamÄ±yor ve test verilerinde dÃ¼ÅŸÃ¼k performans gÃ¶steriyor.


### 6.Model Parametrelini AyarlarÄ±n (Fine-Tuning)

EÄŸitim verileri Ã¼zerindeki performansÄ± nedeniyle, modelimizin bir ÅŸeyler Ã¶ÄŸrendiÄŸi aÃ§Ä±ktÄ±r. Bununla birlikte, eÄŸitim verileri Ã¼zerinde iyi performans sergilemek, sÄ±nÄ±fta iyi gidiyor ancak becerilerinizi gerÃ§ek hayatta kullanamamak gibidir.

Ä°deal olarak, modelimizin eÄŸitim verilerinde olduÄŸu gibi test verilerinde de performans gÃ¶stermesini isteriz.

Bu yÃ¼zden sonraki adÄ±mlarÄ±mÄ±z, modelimizin fazla takÄ±lmasÄ±nÄ± Ã¶nlemek olacaktÄ±r. Overfitting Ã¶nlemenin birkaÃ§ yolu ÅŸunlarÄ± iÃ§erir:

- **Daha fazla veri elde edin**<br> 
Daha fazla veriye sahip olmak, modele yeni Ã¶rneklere daha genelleÅŸtirilebilecek kalÄ±plarÄ±, kalÄ±plarÄ± Ã¶ÄŸrenmek iÃ§in daha fazla fÄ±rsat verir.
- **Modeli basitleÅŸtirin**<br> 
Mevcut model zaten eÄŸitim verilerine fazla uyuyorsa, bir model iÃ§in Ã§ok karmaÅŸÄ±k olabilir. Bu, veri kalÄ±plarÄ±nÄ± Ã§ok iyi Ã¶ÄŸrendiÄŸi ve gÃ¶rÃ¼nmeyen verilere iyi genelleme yapamadÄ±ÄŸÄ± anlamÄ±na gelir. Bir modeli basitleÅŸtirmenin bir yolu, kullandÄ±ÄŸÄ± katman sayÄ±sÄ±nÄ± azaltmak veya her katmandaki gizli birimlerin sayÄ±sÄ±nÄ± azaltmaktÄ±r.
- **Veri bÃ¼yÃ¼tmeyi kullan**<br> 
Veri bÃ¼yÃ¼tme, eÄŸitim verilerini bir ÅŸekilde manipÃ¼le eder, bÃ¶ylece verilere yapay olarak daha fazla Ã§eÅŸitlilik eklediÄŸinden modelin Ã¶ÄŸrenmesi daha zordur. Bir model artÄ±rÄ±lmÄ±ÅŸ verilerdeki kalÄ±plarÄ± Ã¶ÄŸrenebiliyorsa, model gÃ¶rÃ¼nmeyen verilere daha iyi genelleme yapabilir.
- **Transfer Ã¶ÄŸrenimini kullanÄ±n**<br> 
Transfer Ã¶ÄŸrenimi, bir modelin kendi gÃ¶reviniz iÃ§in temel olarak kullanmayÄ± Ã¶ÄŸrendiÄŸi kalÄ±plardan (Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar olarak da adlandÄ±rÄ±lÄ±r) yararlanmayÄ± iÃ§erir. Bizim durumumuzda, Ã§ok Ã§eÅŸitli gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ bir bilgisayarlÄ± gÃ¶rÃ¼ modelini kullanabilir ve ardÄ±ndan yiyecek gÃ¶rÃ¼ntÃ¼leri iÃ§in daha Ã¶zel olmasÄ± iÃ§in biraz ince ayar yapabilirdik.

HalihazÄ±rda mevcut bir veri kÃ¼meniz varsa, muhtemelen ilk Ã¶nce yukarÄ±daki son Ã¼Ã§ seÃ§enekten birini veya bunlarÄ±n bir kombinasyonunu denemeniz olasÄ±dÄ±r.

Daha fazla veri toplamak, elle daha fazla yiyecek gÃ¶rÃ¼ntÃ¼sÃ¼ almamÄ±zÄ± gerektireceÄŸinden, yapabileceklerimizi doÄŸrudan not defterinden deneyelim.

Ã–nce modelimizi sadeleÅŸtirmeye ne dersiniz?

Bunu yapmak iÃ§in, toplam evriÅŸim katmanÄ± sayÄ±sÄ±nÄ± dÃ¶rtten ikiye alarak iki kat evriÅŸim katmanÄ±nÄ± kaldÄ±racaÄŸÄ±z.


```python
model_10 = Sequential([
  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),
  MaxPool2D(),
  Conv2D(10, 3, activation='relu'),
  MaxPool2D(),
  Flatten(),
  Dense(10, activation='softmax')
])

model_10.compile(loss='categorical_crossentropy',
                 optimizer=tf.keras.optimizers.Adam(),
                 metrics=['accuracy'])

history_10 = model_10.fit(train_data,
                          epochs=5,
                          steps_per_epoch=len(train_data),
                          validation_data=test_data,
                          validation_steps=len(test_data))
```

    Epoch 1/5
    235/235 [==============================] - 44s 185ms/step - loss: 2.2136 - accuracy: 0.2260 - val_loss: 1.9535 - val_accuracy: 0.3224
    Epoch 2/5
    235/235 [==============================] - 42s 177ms/step - loss: 1.7867 - accuracy: 0.3912 - val_loss: 1.9660 - val_accuracy: 0.3044
    Epoch 3/5
    235/235 [==============================] - 43s 183ms/step - loss: 1.4147 - accuracy: 0.5403 - val_loss: 1.9701 - val_accuracy: 0.3280
    Epoch 4/5
    235/235 [==============================] - 43s 184ms/step - loss: 0.9434 - accuracy: 0.7045 - val_loss: 2.2627 - val_accuracy: 0.2972
    Epoch 5/5
    235/235 [==============================] - 42s 178ms/step - loss: 0.5380 - accuracy: 0.8457 - val_loss: 2.6522 - val_accuracy: 0.3004



```python
# model_10'un kayÄ±p eÄŸrilerine gÃ¶z atalÄ±m
plot_loss_curves(history_10)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_143_0.png)
    



    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_143_1.png)
    


Hmm... basitleÅŸtirilmiÅŸ bir modelle bile, modelimiz hala eÄŸitim verilerine Ã¶nemli Ã¶lÃ§Ã¼de uyuyor gibi gÃ¶rÃ¼nÃ¼yor.

BaÅŸka ne deneyebiliriz? Veri artÄ±rmaya ne dersiniz?

Veri bÃ¼yÃ¼tme, modelin eÄŸitim verileri Ã¼zerinde Ã¶ÄŸrenmesini zorlaÅŸtÄ±rÄ±r ve bunun sonucunda Ã¶ÄŸrendiÄŸi kalÄ±plarÄ± gÃ¶rÃ¼nmeyen verilere daha genelleÅŸtirilebilir hale getirmeyi umar.

ArtÄ±rÄ±lmÄ±ÅŸ veri oluÅŸturmak iÃ§in, yeni bir ImageDataGenerator Ã¶rneÄŸini yeniden oluÅŸturacaÄŸÄ±z, bu sefer resimlerimizi iÅŸlemek iÃ§in rotation_range ve horizontal_flip gibi bazÄ± parametreler ekleyeceÄŸiz.



```python
train_datagen_augmented = ImageDataGenerator(rescale=1/255.,
                                             rotation_range=0.2,
                                             width_shift_range=0.2,
                                             height_shift_range=0.2,
                                             zoom_range=0.2,
                                             horizontal_flip=True)

train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,
                                                                  target_size=(224, 224),
                                                                  batch_size=32,
                                                                  class_mode='categorical')
```

    Found 7500 images belonging to 10 classes.


Åimdi artÄ±rÄ±lmÄ±ÅŸ veriye sahibiz, eskisi gibi aynÄ± modelle (model_10) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶relim.

Modeli sÄ±fÄ±rdan yeniden yazmak yerine, mevcut bir modeli alÄ±p aynÄ± biÃ§imde yeniden oluÅŸturabilen clon_model adlÄ± TensorFlow'daki kullanÄ±ÅŸlÄ± bir iÅŸlevi kullanarak onu klonlayabiliriz.

KlonlanmÄ±ÅŸ sÃ¼rÃ¼m, orijinal modelin Ã¶ÄŸrendiÄŸi aÄŸÄ±rlÄ±klarÄ±n (kalÄ±plarÄ±n) hiÃ§birini iÃ§ermeyecektir. Yani onu eÄŸittiÄŸimizde, sÄ±fÄ±rdan bir modeli eÄŸitmek gibi olacak.

> ğŸ”‘ Not: Derin Ã¶ÄŸrenme ve genel olarak makine Ã¶ÄŸrenimindeki temel uygulamalardan biri seri deneyci olmaktÄ±r. Burada yaptÄ±ÄŸÄ±mÄ±z ÅŸey bu. Bir ÅŸey denemek, iÅŸe yarayÄ±p yaramadÄ±ÄŸÄ±nÄ± gÃ¶rmek, sonra baÅŸka bir ÅŸey denemek. Ä°yi bir deneme kurulumu, deÄŸiÅŸtirdiÄŸiniz ÅŸeyleri de takip eder. Bu nedenle Ã¶ncekiyle aynÄ± modeli ancak farklÄ± verilerle kullanÄ±yoruz. Model aynÄ± kalÄ±r, ancak veriler deÄŸiÅŸir, bu, artÄ±rÄ±lmÄ±ÅŸ eÄŸitim verilerinin performans Ã¼zerinde herhangi bir etkisi olup olmadÄ±ÄŸÄ±nÄ± bize bildirir.


```python
model_11 = tf.keras.models.clone_model(model_10)

model_11.compile(loss="categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

history_11 = model_11.fit(train_data_augmented,
                          epochs=5,
                          steps_per_epoch=len(train_data_augmented),
                          validation_data=test_data,
                          validation_steps=len(test_data))
```

    Epoch 1/5
    235/235 [==============================] - 109s 464ms/step - loss: 2.2901 - accuracy: 0.1651 - val_loss: 2.0693 - val_accuracy: 0.2508
    Epoch 2/5
    235/235 [==============================] - 108s 462ms/step - loss: 2.1009 - accuracy: 0.2405 - val_loss: 1.9395 - val_accuracy: 0.3140
    Epoch 3/5
    235/235 [==============================] - 107s 455ms/step - loss: 2.0259 - accuracy: 0.2909 - val_loss: 1.8651 - val_accuracy: 0.3428
    Epoch 4/5
    235/235 [==============================] - 110s 469ms/step - loss: 1.9746 - accuracy: 0.3056 - val_loss: 1.8180 - val_accuracy: 0.3588
    Epoch 5/5
    235/235 [==============================] - 109s 462ms/step - loss: 1.9305 - accuracy: 0.3273 - val_loss: 1.7820 - val_accuracy: 0.3896


Her epoch bir Ã¶nceki modelden daha uzun sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶rebilirsiniz. Bunun nedeni, verilerimizin GPU'ya yÃ¼klendikÃ§e CPU'da anÄ±nda geniÅŸletilmesi ve her dÃ¶nem arasÄ±ndaki sÃ¼renin artmasÄ±dÄ±r.

Modelimizin eÄŸitim eÄŸrileri nasÄ±l gÃ¶rÃ¼nÃ¼yor?



```python
plot_loss_curves(history_11)
```

Vay! Bu Ã§ok daha iyi gÃ¶rÃ¼nÃ¼yor, kayÄ±p eÄŸrileri birbirine Ã§ok daha yakÄ±n. Modelimiz artÄ±rÄ±lmÄ±ÅŸ eÄŸitim setinde iyi performans gÃ¶stermese de doÄŸrulama veri setinde Ã§ok daha iyi performans gÃ¶sterdi.

Hatta eÄŸitimini daha uzun sÃ¼re (daha fazla epoch) sÃ¼rdÃ¼rÃ¼rsek, deÄŸerlendirme metrikleri geliÅŸmeye devam edebilir gibi gÃ¶rÃ¼nÃ¼yor.


### 7.Memnun kalana kadar tekrarlayÄ±n

Burada devam edebilirdik. Modelimizin mimarisini yeniden yapÄ±landÄ±rmak, daha fazla katman eklemek, denemek, Ã¶ÄŸrenme oranÄ±nÄ± ayarlamak, denemek, farklÄ± veri bÃ¼yÃ¼tme yÃ¶ntemlerini denemek, daha uzun sÃ¼re eÄŸitim. Ancak, hayal edebileceÄŸiniz gibi, bu oldukÃ§a uzun zaman alabilir.

Ä°yi ki henÃ¼z denemediÄŸimiz bir numara var ve o da transfer Ã¶ÄŸrenme.

Bununla birlikte, kendi modellerimizi sÄ±fÄ±rdan tasarlamak yerine baÅŸka bir modelin Ã¶ÄŸrendiÄŸi kalÄ±plardan kendi gÃ¶revimiz iÃ§in nasÄ±l yararlandÄ±ÄŸÄ±mÄ±zÄ± gÃ¶receÄŸiniz (bir sonraki eÄŸitim yazÄ±sÄ±nda).

Bu arada eÄŸitimli Ã§ok sÄ±nÄ±flÄ± modelimiz ile bir tahminde bulunalÄ±m.

### EÄŸitim Modelimiz ile Tahmin Yapmak

Onunla tahmin yapamayacaksanÄ±z bir model ne iÅŸe yarar?

Ã–nce kendimize Ã§ok sÄ±nÄ±flÄ± modelimizin Ã¼zerinde eÄŸitim aldÄ±ÄŸÄ± sÄ±nÄ±flarÄ± hatÄ±rlatalÄ±m ve sonra Ã§alÄ±ÅŸmak iÃ§in kendi Ã¶zel gÃ¶rÃ¼ntÃ¼lerinden bazÄ±larÄ±nÄ± indireceÄŸiz.


```python
class_names
```




    array(['chicken_curry', 'chicken_wings', 'fried_rice', 'grilled_salmon',
           'hamburger', 'ice_cream', 'pizza', 'ramen', 'steak', 'sushi'],
          dtype='<U14')



GÃ¼zel, ÅŸimdi Ã¶zel resimlerimizden bazÄ±larÄ±nÄ± alalÄ±m.

Google Colab kullanÄ±yorsanÄ±z, dosyalar sekmesi aracÄ±lÄ±ÄŸÄ±yla kendi resimlerinizden bazÄ±larÄ±nÄ± da yÃ¼kleyebilirsiniz.


```python
# gÃ¶rÃ¼tÃ¼leri colab'e indirme

!wget -q "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/pizza_1.jpg"
!wget -q "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/pizza_2.jpg"
!wget -q "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/steak_1.jpeg"
!wget -q "https://raw.githubusercontent.com/Furkan-Gulsen/TensorFlow-ile-Yapay-Zeka-Gelistirme/main/3-Evri%C5%9Fimsel%20Sinir%20A%C4%9Flar%C4%B1%20(CNN)/images/steak_2.jpg"
```

Tamam, deneyecek bazÄ± Ã¶zel resimlerimiz var, hadi resimlerden birinde model_11 ile bir tahmin yapmak iÃ§in pred_and_plot iÅŸlevini kullanalÄ±m ve onu Ã§izelim.


```python
pred_and_plot(model=model_11, 
              filename="steak_1.jpeg", 
              class_names=class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_157_0.png)
    



```python
pred_and_plot(model_11, "pizza_1.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_158_0.png)
    



```python
pred_and_plot(model_11, "pizza_2.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_159_0.png)
    



```python
pred_and_plot(model_11, "steak_2.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_160_0.png)
    


Hespi yanlÄ±ÅŸ Ã§Ä±ktÄ±. Pred_and_plot iÅŸlevimizle ilgili olabileceÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.


```python
img = load_and_prep_image("steak_1.jpeg")

pred = model_11.predict(tf.expand_dims(img, axis=0))

pred_class = class_names[pred.argmax()]
plt.imshow(img)
plt.title(pred_class)
plt.axis(False);
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_162_0.png)
    


Ã‡ok daha iyi! pred_and_plot iÅŸlevimizde bir ÅŸeyler olmalÄ±.

Ve sanÄ±rÄ±m ne olduÄŸunu biliyorum.

pred_and_plot iÅŸlevi, mevcut modelimizin Ã§ok sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma modeli olduÄŸu ikili sÄ±nÄ±flandÄ±rma modelleriyle kullanÄ±lmak Ã¼zere tasarlanmÄ±ÅŸtÄ±r.

Ana fark, tahmin fonksiyonunun Ã§Ä±ktÄ±sÄ±nda yatmaktadÄ±r.



```python
# Tahmin fonksiyonunun Ã§Ä±ktÄ±sÄ±nÄ± kontrol edelim
pred = model_11.predict(tf.expand_dims(img, axis=0))
pred
```




    array([[0.03432237, 0.02044422, 0.05089506, 0.16825534, 0.06048798,
            0.04497578, 0.00705055, 0.10628431, 0.44707397, 0.06021047]],
          dtype=float32)



Modelimiz bir 'softmax' aktivasyon fonksiyonuna ve 10 Ã§Ä±kÄ±ÅŸ nÃ¶ronuna sahip olduÄŸundan, modelimizde her sÄ±nÄ±f iÃ§in bir tahmin olasÄ±lÄ±ÄŸÄ± verir.

En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f, modelin gÃ¶rÃ¼ntÃ¼nÃ¼n iÃ§erdiÄŸine inandÄ±ÄŸÄ± sÄ±nÄ±ftÄ±r.

argmax kullanarak maksimum deÄŸer indeksini bulabilir ve ardÄ±ndan bunu, tahmin edilen sÄ±nÄ±fÄ±n Ã§Ä±ktÄ±sÄ±nÄ± almak iÃ§in class_names listemizi indekslemek iÃ§in kullanabiliriz.



```python
class_names[pred.argmax()]
```




    'steak'



pred_and_plot iÅŸlevimizi ikili sÄ±nÄ±flarÄ±n yanÄ± sÄ±ra birden Ã§ok sÄ±nÄ±fla Ã§alÄ±ÅŸacak ÅŸekilde yeniden ayarlayabiliriz.


```python
def pred_and_plot(model, filename, class_names):
  img = load_and_prep_image(filename)
  
  pred = model.predict(tf.expand_dims(img, axis=0))

  if len(pred[0]) > 1: # ikili - Ã§oklu kontrol
    pred_class = class_names[pred.argmax()] 
  else:
    pred_class = class_names[int(tf.round(pred)[0][0])]

  plt.imshow(img)
  plt.title(f"Tahmin: {pred_class}")
  plt.axis(False);
```

Deneyelim. DoÄŸru yaptÄ±ysak, farklÄ± gÃ¶rÃ¼ntÃ¼ler kullanmak farklÄ± Ã§Ä±ktÄ±lara yol aÃ§malÄ±dÄ±r (her seferinde Chicken_curry yerine).


```python
pred_and_plot(model_11, "steak_2.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_170_0.png)
    



```python
pred_and_plot(model_11, "pizza_1.jpg", class_names)
```


    
![png](TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_files/TensorFlow_ile_Evri%C5%9Fimli_Sinir_A%C4%9Flar_%28CNN%29_171_0.png)
    


Modelimizin tahminleri Ã§ok iyi deÄŸil, bunun nedeni test veri setinde yalnÄ±zca ~%35 doÄŸrulukta performans gÃ¶stermesidir.

## Modelimizi Kaydetme ve YÃ¼kleme

Bir modeli eÄŸittikten sonra, muhtemelen onu kaydedip baÅŸka bir yere yÃ¼klemek istersiniz.

Bunun iÃ§in save ve load_model fonksiyonlarÄ±nÄ± kullanabiliriz.


```python
# bir modeli kaydetmek
model_11.save("saved_trained_model")
```

    INFO:tensorflow:Assets written to: saved_trained_model/assets



```python
# modeli yÃ¼kleme ve deÄŸerlendirme
loaded_model_11 = tf.keras.models.load_model("saved_trained_model")
loaded_model_11.evaluate(test_data)
```

    79/79 [==============================] - 10s 130ms/step - loss: 1.7820 - accuracy: 0.3896





    [1.7820457220077515, 0.38960000872612]


